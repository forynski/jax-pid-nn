{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Section 1: Setup & Configuration","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# DEPENDENCIES INSTALLATION\n# ============================================================================\n\n!pip install jax jaxlib optax flax pandas numpy matplotlib seaborn scikit-learn -q\n\nprint(\"✓ JAX dependencies installed\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# IMPORTS\n# ============================================================================\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport json\nimport os\nfrom tqdm import tqdm\n\n# JAX ecosystem\nimport jax\nimport jax.numpy as jnp\nfrom jax import random, grad, jit, vmap\nimport optax  # Optimisation library\nfrom flax import linen as nn  # Neural network library\nfrom flax.training import train_state\n\n# Scikit-learn utilities\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    confusion_matrix, \n    roc_curve, \n    auc, \n    roc_auc_score,\n    classification_report\n)\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Check JAX device\nprint(f\"JAX version: {jax.__version__}\")\nprint(f\"Available devices: {jax.devices()}\")\nprint(f\"Default backend: {jax.default_backend()}\")\n\n# Configuration\nRANDOM_SEED = 42\nMOMENTUM_RANGE = {'min': 1.0, 'max': 2.0, 'name': '1-2 GeV/c'}\nPARTICLE_NAMES = ['Pion', 'Kaon', 'Proton', 'Electron']\nNUM_CLASSES = len(PARTICLE_NAMES)\n\nBASE_DIR = '/kaggle/working'\nSAVE_DIR = os.path.join(BASE_DIR, 'JAX_Models')\nos.makedirs(SAVE_DIR, exist_ok=True)\n\nprint(f\"✓ Configuration loaded\")\nprint(f\"  Momentum range: {MOMENTUM_RANGE['name']}\")\nprint(f\"  Target classes: {NUM_CLASSES}\")\nprint(f\"  Random seed: {RANDOM_SEED}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 2: Data Loading & Preprocessing","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# LOAD DATA\n# ============================================================================\n\nCSV_PATH = '/kaggle/input/pid-features/pid_features_large.csv'\n\nprint(\"Loading data...\")\ndf_iter = pd.read_csv(CSV_PATH, dtype='float32', chunksize=500_000, low_memory=False)\ndf = pd.concat(df_iter, ignore_index=True)\nprint(f\"✓ Loaded: {df.shape}\")\n\n# ============================================================================\n# MOMENTUM RANGE SELECTION (1-2 GeV/c)\n# ============================================================================\n\nprint(f\"\\nFiltering momentum range: {MOMENTUM_RANGE['name']}\")\ndf_range = df[(df['pt'] >= MOMENTUM_RANGE['min']) & \n              (df['pt'] < MOMENTUM_RANGE['max'])].copy()\nprint(f\"✓ Selected {len(df_range):,} tracks in range\")\n\n# ============================================================================\n# HANDLE MISSING VALUES\n# ============================================================================\n\n# Replace sentinel values with NaN\ndf_range.replace(-999, np.nan, inplace=True)\n\n# Identify feature groups\ntof_features = [col for col in df_range.columns if 'tof' in col.lower()]\ntpc_features = [col for col in df_range.columns if 'tpc' in col.lower()]\nbayes_features = [col for col in df_range.columns if 'bayes_prob' in col.lower()]\n\nprint(\"\\nHandling missing values:\")\nprint(f\"  TOF features: {len(tof_features)}\")\nprint(f\"  TPC features: {len(tpc_features)}\")\nprint(f\"  Bayesian features: {len(bayes_features)}\")\n\n# Fill missing values with 0 (detector not hit)\ndf_range[tof_features] = df_range[tof_features].fillna(0)\ndf_range[tpc_features] = df_range[tpc_features].fillna(0)\ndf_range[bayes_features] = df_range[bayes_features].fillna(0)\n\n# Create indicator features for missing data\ndf_range['has_tof'] = (df_range[tof_features].abs().sum(axis=1) > 0).astype(int)\ndf_range['has_tpc'] = (df_range[tpc_features].abs().sum(axis=1) > 0).astype(int)\n\nprint(f\"  ✓ Missing values handled\")\nprint(f\"  Tracks with TOF: {df_range['has_tof'].sum():,} ({df_range['has_tof'].mean()*100:.1f}%)\")\nprint(f\"  Tracks with TPC: {df_range['has_tpc'].sum():,} ({df_range['has_tpc'].mean()*100:.1f}%)\")\n\n# ============================================================================\n# MAP PDG CODES TO PARTICLE SPECIES\n# ============================================================================\n\ndef pdg_to_species(pdg):\n    ap = abs(int(pdg))\n    if ap == 211:\n        return 0  # Pion\n    elif ap == 321:\n        return 1  # Kaon\n    elif ap == 2212:\n        return 2  # Proton\n    elif ap == 11:\n        return 3  # Electron\n    else:\n        return -1  # Unknown\n\ndf_range['particle_species'] = df_range['mc_pdg'].apply(pdg_to_species)\n\n# Keep only valid particles\ndf_range = df_range[df_range['particle_species'] >= 0].reset_index(drop=True)\nprint(f\"✓ Valid particles: {len(df_range):,}\")\n\n# ============================================================================\n# CLASS DISTRIBUTION\n# ============================================================================\n\nprint(\"\\nClass distribution:\")\nclass_counts = df_range['particle_species'].value_counts().sort_index()\nfor idx, count in class_counts.items():\n    print(f\"  {PARTICLE_NAMES[idx]:10s}: {count:7,} ({count/len(df_range)*100:5.2f}%)\")\n\n# ============================================================================\n# FEATURE ENGINEERING\n# ============================================================================\n\n# Log-transform momentum-related features\nfor feature in ['pt', 'p', 'tpc_signal', 'tof_beta']:\n    if feature in df_range.columns:\n        df_range[feature] = np.log1p(df_range[feature].abs())\n\n# Define training features\ntraining_features = [\n    'pt', 'eta', 'phi', 'tpc_signal',\n    'tpc_nsigma_pi', 'tpc_nsigma_ka', 'tpc_nsigma_pr', 'tpc_nsigma_el',\n    'tof_beta',\n    'tof_nsigma_pi', 'tof_nsigma_ka', 'tof_nsigma_pr', 'tof_nsigma_el',\n    'bayes_prob_pi', 'bayes_prob_ka', 'bayes_prob_pr', 'bayes_prob_el',\n    'dca_xy', 'dca_z',\n    'has_tpc', 'has_tof'\n]\n\navailable_features = [f for f in training_features if f in df_range.columns]\nprint(f\"\\n✓ Available features: {len(available_features)}\")\n\n# Drop any remaining NaNs in features\ndf_range = df_range.dropna(subset=available_features)\nprint(f\"✓ Final dataset: {df_range.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 3: Background Cleaning","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# BACKGROUND CLEANING\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"BACKGROUND CLEANING\")\nprint(\"=\"*80)\n\ninitial_count = len(df_range)\n\n# 1. Remove tracks with unrealistic momenta\ndf_range = df_range[(df_range['pt'] > np.log1p(0.05)) & \n                    (df_range['pt'] < np.log1p(20))].copy()\nprint(f\"✓ Momentum cut: {initial_count - len(df_range):,} tracks removed\")\n\n# 2. Remove tracks with poor DCA (distance of closest approach)\ndca_cut = 3.0  # cm\ndf_range = df_range[(df_range['dca_xy'].abs() < dca_cut) & \n                    (df_range['dca_z'].abs() < dca_cut)].copy()\nprint(f\"✓ DCA cut: {initial_count - len(df_range):,} tracks removed\")\n\n# 3. Remove tracks with inconsistent PID signals\n# (High n-sigma in both TPC and TOF suggests misidentification)\nnsigma_threshold = 5.0\nfor particle in ['pi', 'ka', 'pr', 'el']:\n    tpc_col = f'tpc_nsigma_{particle}'\n    tof_col = f'tof_nsigma_{particle}'\n    if tpc_col in df_range.columns and tof_col in df_range.columns:\n        df_range = df_range[\n            ~((df_range[tpc_col].abs() > nsigma_threshold) & \n              (df_range[tof_col].abs() > nsigma_threshold))\n        ].copy()\n\nprint(f\"✓ PID consistency cut: {initial_count - len(df_range):,} tracks removed\")\nprint(f\"✓ Clean dataset: {len(df_range):,} tracks ({len(df_range)/initial_count*100:.1f}% retained)\")\n\n# Update class distribution after cleaning\nprint(\"\\nClass distribution after cleaning:\")\nclass_counts_clean = df_range['particle_species'].value_counts().sort_index()\nfor idx, count in class_counts_clean.items():\n    print(f\"  {PARTICLE_NAMES[idx]:10s}: {count:7,} ({count/len(df_range)*100:5.2f}%)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 4: Train/Test Split & Scaling","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# PREPARE TRAINING DATA\n# ============================================================================\n\nX = df_range[available_features].astype('float32')\ny = df_range['particle_species'].values.astype('int32')\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=RANDOM_SEED, stratify=y\n)\n\nprint(f\"\\n✓ Train samples: {len(X_train):,}\")\nprint(f\"✓ Test samples: {len(X_test):,}\")\n\n# Standardize features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.values)\nX_test_scaled = scaler.transform(X_test.values)\n\nprint(f\"✓ Features standardized (mean=0, std=1)\")\n\n# Compute class weights for imbalanced data\nclass_weights = compute_class_weight(\n    'balanced',\n    classes=np.unique(y_train),\n    y=y_train\n)\nclass_weights_dict = dict(enumerate(class_weights))\nprint(f\"\\n✓ Class weights computed:\")\nfor idx, weight in class_weights_dict.items():\n    print(f\"  {PARTICLE_NAMES[idx]:10s}: {weight:.4f}\")\n\n# Convert to JAX arrays\nX_train_jax = jnp.array(X_train_scaled, dtype=jnp.float32)\nX_test_jax = jnp.array(X_test_scaled, dtype=jnp.float32)\ny_train_jax = jnp.array(y_train, dtype=jnp.int32)\ny_test_jax = jnp.array(y_test, dtype=jnp.int32)\nclass_weights_jax = jnp.array(list(class_weights_dict.values()), dtype=jnp.float32)\n\nprint(f\"\\n✓ Data converted to JAX arrays\")\nprint(f\"  X_train shape: {X_train_jax.shape}\")\nprint(f\"  y_train shape: {y_train_jax.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 5: JAX Neural Network Definition","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# DEFINE NEURAL NETWORK WITH FLAX\n# ============================================================================\n\nclass PIDNeuralNetwork(nn.Module):\n    \"\"\"\n    Neural network for particle identification with:\n    - Batch normalization\n    - Dropout for regularization\n    - Skip connections\n    \"\"\"\n    hidden_dims: list\n    num_classes: int\n    dropout_rate: float = 0.3\n    \n    @nn.compact\n    def __call__(self, x, training: bool = False):\n        # Input layer\n        z = x\n        \n        # Hidden layers with batch norm and dropout\n        for i, dim in enumerate(self.hidden_dims):\n            z = nn.Dense(dim, name=f'dense_{i}')(z)\n            z = nn.BatchNorm(use_running_average=not training, name=f'bn_{i}')(z)\n            z = nn.relu(z)\n            z = nn.Dropout(rate=self.dropout_rate, deterministic=not training)(z)\n        \n        # Output layer\n        logits = nn.Dense(self.num_classes, name='output')(z)\n        return logits\n\n# Initialize model\nkey = random.PRNGKey(RANDOM_SEED)\nmodel = PIDNeuralNetwork(\n    hidden_dims=[256, 128, 64],\n    num_classes=NUM_CLASSES,\n    dropout_rate=0.3\n)\n\n# Initialize parameters\ndummy_input = jnp.ones((1, X_train_jax.shape))\nparams = model.init(key, dummy_input, training=False)\n\nprint(\"✓ Model architecture:\")\nprint(f\"  Input features: {X_train_jax.shape}\")\nprint(f\"  Hidden layers: {[256, 128, 64]}\")\nprint(f\"  Output classes: {NUM_CLASSES}\")\nprint(f\"  Dropout rate: 0.3\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 6: Training Setup","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# DEFINE LOSS FUNCTION WITH CLASS WEIGHTS\n# ============================================================================\n\ndef weighted_cross_entropy_loss(logits, labels, class_weights):\n    \"\"\"Cross-entropy loss with class weighting\"\"\"\n    # One-hot encode labels\n    one_hot_labels = jax.nn.one_hot(labels, NUM_CLASSES)\n    \n    # Compute log softmax\n    log_softmax = jax.nn.log_softmax(logits, axis=-1)\n    \n    # Apply class weights\n    sample_weights = class_weights[labels]\n    \n    # Compute weighted loss\n    loss = -jnp.sum(one_hot_labels * log_softmax, axis=-1)\n    weighted_loss = loss * sample_weights\n    \n    return jnp.mean(weighted_loss)\n\n@jit\ndef train_step(state, batch_x, batch_y, class_weights):\n    \"\"\"Single training step\"\"\"\n    def loss_fn(params):\n        logits = state.apply_fn({'params': params}, batch_x, training=True, \n                                rngs={'dropout': state.step})\n        loss = weighted_cross_entropy_loss(logits, batch_y, class_weights)\n        return loss\n    \n    loss, grads = jax.value_and_grad(loss_fn)(state.params)\n    state = state.apply_gradients(grads=grads)\n    return state, loss\n\n@jit\ndef eval_step(state, batch_x, batch_y):\n    \"\"\"Single evaluation step\"\"\"\n    logits = state.apply_fn({'params': state.params}, batch_x, training=False)\n    predictions = jnp.argmax(logits, axis=-1)\n    accuracy = jnp.mean(predictions == batch_y)\n    return accuracy, logits\n\n# ============================================================================\n# INITIALIZE TRAINING STATE\n# ============================================================================\n\nlearning_rate = 1e-3\ntx = optax.adam(learning_rate)\n\nstate = train_state.TrainState.create(\n    apply_fn=model.apply,\n    params=params['params'],\n    tx=tx\n)\n\nprint(\"✓ Training state initialized\")\nprint(f\"  Optimiser: Adam\")\nprint(f\"  Learning rate: {learning_rate}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 7: Training Loop","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# TRAIN MODEL\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"TRAINING NEURAL NETWORK\")\nprint(\"=\"*80)\n\nBATCH_SIZE = 256\nNUM_EPOCHS = 50\nPATIENCE = 10\n\n# Create batches\nnum_batches = len(X_train_jax) // BATCH_SIZE\nbest_val_acc = 0.0\npatience_counter = 0\n\ntrain_losses = []\nval_accuracies = []\n\nfor epoch in range(NUM_EPOCHS):\n    # Shuffle training data\n    key, subkey = random.split(key)\n    perm = random.permutation(subkey, len(X_train_jax))\n    X_train_shuffled = X_train_jax[perm]\n    y_train_shuffled = y_train_jax[perm]\n    \n    # Training\n    epoch_losses = []\n    for batch_idx in range(num_batches):\n        start_idx = batch_idx * BATCH_SIZE\n        end_idx = start_idx + BATCH_SIZE\n        \n        batch_x = X_train_shuffled[start_idx:end_idx]\n        batch_y = y_train_shuffled[start_idx:end_idx]\n        \n        state, loss = train_step(state, batch_x, batch_y, class_weights_jax)\n        epoch_losses.append(loss)\n    \n    avg_train_loss = np.mean(epoch_losses)\n    train_losses.append(avg_train_loss)\n    \n    # Validation\n    val_acc, _ = eval_step(state, X_test_jax, y_test_jax)\n    val_accuracies.append(float(val_acc))\n    \n    # Print progress\n    if (epoch + 1) % 5 == 0:\n        print(f\"Epoch {epoch+1:3d}/{NUM_EPOCHS} | \"\n              f\"Loss: {avg_train_loss:.4f} | \"\n              f\"Val Acc: {val_acc:.4f}\")\n    \n    # Early stopping\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        patience_counter = 0\n        best_params = state.params\n    else:\n        patience_counter += 1\n        if patience_counter >= PATIENCE:\n            print(f\"\\n✓ Early stopping at epoch {epoch+1}\")\n            break\n\n# Restore best parameters\nstate = state.replace(params=best_params)\n\nprint(f\"\\n✓ Training complete!\")\nprint(f\"  Best validation accuracy: {best_val_acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 8: Evaluation","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# EVALUATE MODEL\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"MODEL EVALUATION\")\nprint(\"=\"*80)\n\n# Predictions\ntrain_acc, train_logits = eval_step(state, X_train_jax, y_train_jax)\ntest_acc, test_logits = eval_step(state, X_test_jax, y_test_jax)\n\nprint(f\"Train Accuracy: {train_acc:.4f}\")\nprint(f\"Test Accuracy:  {test_acc:.4f}\")\n\n# Convert logits to probabilities\ntrain_probs = jax.nn.softmax(train_logits, axis=-1)\ntest_probs = jax.nn.softmax(test_logits, axis=-1)\n\n# Predictions\ny_pred_test = jnp.argmax(test_logits, axis=-1)\n\n# Classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(\n    y_test, \n    np.array(y_pred_test), \n    target_names=PARTICLE_NAMES,\n    digits=4\n))\n\n# Save model and results\nmodel_save_path = os.path.join(SAVE_DIR, 'pid_model_jax_1-2gev.pkl')\nwith open(model_save_path, 'wb') as f:\n    pickle.dump({\n        'params': state.params,\n        'scaler': scaler,\n        'features': available_features,\n        'train_acc': float(train_acc),\n        'test_acc': float(test_acc),\n        'class_weights': class_weights_dict,\n        'config': {\n            'hidden_dims': [256, 128, 64],\n            'dropout_rate': 0.3,\n            'learning_rate': learning_rate,\n            'num_epochs': epoch + 1\n        }\n    }, f)\n\nprint(f\"\\n✓ Model saved to: {model_save_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 9: Visualizations","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# TRAINING HISTORY\n# ============================================================================\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Loss curve\naxes.plot(train_losses, linewidth=2, color='#3B82F6', label='Training Loss')\naxes.set_xlabel('Epoch', fontsize=12, fontweight='bold')\naxes.set_ylabel('Loss', fontsize=12, fontweight='bold')\naxes.set_title('Training Loss', fontsize=14, fontweight='bold')\naxes.grid(alpha=0.3)\naxes.legend(fontsize=11)\n\n# Validation accuracy\naxes.plot(val_accuracies, linewidth=2, color='#22C55E', label='Validation Accuracy')\naxes.axhline(y=best_val_acc, color='r', linestyle='--', alpha=0.7, \n                label=f'Best: {best_val_acc:.4f}')\naxes.set_xlabel('Epoch', fontsize=12, fontweight='bold')\naxes.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\naxes.set_title('Validation Accuracy', fontsize=14, fontweight='bold')\naxes.grid(alpha=0.3)\naxes.legend(fontsize=11)\n\nplt.suptitle(f'Training History - {MOMENTUM_RANGE[\"name\"]}', \n             fontsize=16, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# CONFUSION MATRIX\n# ============================================================================\n\ncm = confusion_matrix(y_test, np.array(y_pred_test), normalize='true')\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues',\n            xticklabels=PARTICLE_NAMES,\n            yticklabels=PARTICLE_NAMES,\n            cbar_kws={'shrink': 0.8})\nplt.xlabel('Predicted', fontsize=13, fontweight='bold')\nplt.ylabel('True', fontsize=13, fontweight='bold')\nplt.title(f'Confusion Matrix - {MOMENTUM_RANGE[\"name\"]}', \n          fontsize=14, fontweight='bold', pad=15)\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# ROC CURVES\n# ============================================================================\n\nfig, ax = plt.subplots(figsize=(10, 8))\ncolors = ['#3B82F6', '#F59E0B', '#22C55E', '#EF4444']\n\nfor i, (particle, color) in enumerate(zip(PARTICLE_NAMES, colors)):\n    y_true_binary = (y_test == i).astype(int)\n    y_score = np.array(test_probs[:, i])\n    \n    fpr, tpr, _ = roc_curve(y_true_binary, y_score)\n    roc_auc = auc(fpr, tpr)\n    \n    ax.plot(fpr, tpr, color=color, lw=2.5, \n            label=f'{particle} (AUC = {roc_auc:.3f})')\n\nax.plot([0, 1], [0, 1], 'k--', lw=2, alpha=0.5)\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.05])\nax.set_xlabel('False Positive Rate', fontsize=13, fontweight='bold')\nax.set_ylabel('True Positive Rate', fontsize=13, fontweight='bold')\nax.set_title(f'ROC Curves - {MOMENTUM_RANGE[\"name\"]}', \n             fontsize=14, fontweight='bold', pad=15)\nax.legend(loc='lower right', fontsize=11)\nax.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# PER-CLASS METRICS\n# ============================================================================\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Compute per-class metrics\nprecisions = []\nrecalls = []\nfor i in range(NUM_CLASSES):\n    y_true_binary = (y_test == i).astype(int)\n    y_pred_binary = (np.array(y_pred_test) == i).astype(int)\n    \n    tp = np.sum((y_true_binary == 1) & (y_pred_binary == 1))\n    fp = np.sum((y_true_binary == 0) & (y_pred_binary == 1))\n    fn = np.sum((y_true_binary == 1) & (y_pred_binary == 0))\n    \n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    \n    precisions.append(precision)\n    recalls.append(recall)\n\n# Precision bar chart\nbars1 = axes.bar(PARTICLE_NAMES, precisions, color=colors, alpha=0.8, \n                     edgecolor='black', linewidth=1.5)\nfor bar, val in zip(bars1, precisions):\n    axes.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n                 f'{val:.3f}', ha='center', va='bottom', \n                 fontsize=11, fontweight='bold')\naxes.set_ylabel('Precision', fontsize=12, fontweight='bold')\naxes.set_title('Precision by Particle Type', fontsize=13, fontweight='bold')\naxes.set_ylim(0, 1.1)\naxes.grid(axis='y', alpha=0.3)\n\n# Recall bar chart\nbars2 = axes.bar(PARTICLE_NAMES, recalls, color=colors, alpha=0.8, \n                     edgecolor='black', linewidth=1.5)\nfor bar, val in zip(bars2, recalls):\n    axes.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n                 f'{val:.3f}', ha='center', va='bottom', \n                 fontsize=11, fontweight='bold')\naxes.set_ylabel('Recall (Efficiency)', fontsize=12, fontweight='bold')\naxes.set_title('Recall by Particle Type', fontsize=13, fontweight='bold')\naxes.set_ylim(0, 1.1)\naxes.grid(axis='y', alpha=0.3)\n\nplt.suptitle(f'Per-Class Performance - {MOMENTUM_RANGE[\"name\"]}', \n             fontsize=14, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ANALYSIS COMPLETE\")\nprint(\"=\"*80)\nprint(f\"✓ Model trained on {len(X_train):,} samples\")\nprint(f\"✓ Tested on {len(X_test):,} samples\")\nprint(f\"✓ Best validation accuracy: {best_val_acc:.4f}\")\nprint(f\"✓ Test accuracy: {test_acc:.4f}\")\nprint(f\"✓ Momentum range: {MOMENTUM_RANGE['name']} (challenging region)\")\nprint(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}