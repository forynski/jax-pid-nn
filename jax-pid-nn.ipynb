{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13627701,"sourceType":"datasetVersion","datasetId":8661436},{"sourceId":13706414,"sourceType":"datasetVersion","datasetId":8671034},{"sourceId":13994113,"sourceType":"datasetVersion","datasetId":8778945},{"sourceId":14487839,"sourceType":"datasetVersion","datasetId":9253567}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Section 1: Configuration & imports","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# REFACTORED CODE STRUCTURE - SOFTWARE ENGINEERING BEST PRACTICES\n# ============================================================================\n\n\"\"\"\nThis refactored notebook structure follows these principles:\n1. DRY (Don't Repeat Yourself) - Shared code in reusable functions\n2. Separation of Concerns - Each section has a clear responsibility\n3. Single Source of Truth - Configuration defined once\n4. Modular Design - Easy to test and maintain\n\"\"\"\n\n# ============================================================================\n# SECTION 0: CONFIGURATION & CONSTANTS (FIXED)\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"SECTION 0: CONFIGURATION\")\nprint(f\"{'#'*80}\\n\")\n\n# Random seed\nSEED = 231\n\n# ============================================================================\n# BAYESIAN FIX: Token constant for 0.25 filled values\n# ============================================================================\nBAYES_MISSING_TOKEN = -0.25  # Use token instead of 0.25 to fix noise issue\n\n# Particle configuration\nNUM_CLASSES = 4\nPARTICLE_NAMES = ['Pion', 'Kaon', 'Proton', 'Electron']\nPDG_TO_SPECIES = {\n    211: 0,   # Pion\n    321: 1,   # Kaon\n    2212: 2,  # Proton\n    11: 3     # Electron\n}\n\n# ============================================================================\n# DPG-RECOMMENDED TRACK SELECTIONS (Nov 2025)\n# NOTE: pT ranges applied separately via MOMENTUM_RANGES\n# ============================================================================\nTRACK_SELECTIONS = {\n    'event': {'vz_max': 10.0},\n    'kinematics': {'eta_min': -0.8, 'eta_max': 0.8},\n    'dca': {'dca_xy_max': 0.105, 'dca_z_max': 0.12},\n    'tpc': {'tpc_clusters_min': 70},\n    'its': {'its_clusters_min': 3}\n}\n\nprint(\"✓ TRACK SELECTIONS (DPG-RECOMMENDED, Nov 2025):\")\nprint(f\"  • vZ < {TRACK_SELECTIONS['event']['vz_max']} cm\")\nprint(f\"  • η: {TRACK_SELECTIONS['kinematics']['eta_min']}-{TRACK_SELECTIONS['kinematics']['eta_max']}\")\nprint(f\"  • DCA_xy < {TRACK_SELECTIONS['dca']['dca_xy_max']} cm, DCA_z < {TRACK_SELECTIONS['dca']['dca_z_max']} cm\")\nprint(f\"  • TPC clusters > {TRACK_SELECTIONS['tpc']['tpc_clusters_min']}\")\nprint(f\"  • ITS clusters > {TRACK_SELECTIONS['its']['its_clusters_min']}\")\n\n# Momentum ranges\nMOMENTUM_RANGES = {\n    \"full\": {\"name\": \"Full Spectrum (0.1+ GeV/c)\", \"min\": 0.1, \"max\": float('inf')},\n    \"0.7-1.5\": {\"name\": \"0.7-1.5 GeV/c (Critical)\", \"min\": 0.7, \"max\": 1.5},\n    \"1-3\": {\"name\": \"1-3 GeV/c (Intermediate)\", \"min\": 1.0, \"max\": 3.0},\n}\n\n# Data path\nCSV_PATH = '/kaggle/input/new-ao2d-lhc25f60544122/pid_features.csv'\n\n# ============================================================================\n# BAYESIAN FIX: Add 'bayes_available' to TRAINING_FEATURES\n# ============================================================================\nTRAINING_FEATURES = [\n    'pt', 'eta', 'phi',\n    'tpc_signal', 'tpc_nsigma_pi', 'tpc_nsigma_ka', 'tpc_nsigma_pr', 'tpc_nsigma_el',\n    'tof_beta', 'tof_nsigma_pi', 'tof_nsigma_ka', 'tof_nsigma_pr', 'tof_nsigma_el',\n    'bayes_prob_pi', 'bayes_prob_ka', 'bayes_prob_pr', 'bayes_prob_el',\n    'bayes_available',  # NEW: Binary indicator (1=real Bayes, 0=token/missing)\n    'dca_xy', 'dca_z',\n    'has_tpc', 'has_tof'\n]\n\n# Detector groups for FSE\nDETECTOR_GROUPS = {\n    'tpc': ['tpc_signal', 'tpc_nsigma_pi', 'tpc_nsigma_ka', 'tpc_nsigma_pr', 'tpc_nsigma_el'],\n    'tof': ['tof_beta', 'tof_nsigma_pi', 'tof_nsigma_ka', 'tof_nsigma_pr', 'tof_nsigma_el'],\n    'bayes': ['bayes_prob_pi', 'bayes_prob_ka', 'bayes_prob_pr', 'bayes_prob_el'],\n    'kinematics': ['pt', 'eta', 'phi', 'dca_xy', 'dca_z']\n}\n\n# Model types\nMODEL_TYPES = ['JAX_SimpleNN', 'JAX_DNN', 'JAX_FSE_Attention', 'JAX_FSE_Attention_DetectorAware', 'SkLearn_RandomForest', 'XGBoost']\n\n# Hyperparameters\nHYPERPARAMETERS = {\n    'JAX_SimpleNN': {\n        'hidden_dims': [512, 256, 128, 64],\n        'dropout_rate': 0.5,\n        'learning_rate': 0.0001,\n        'batch_size': 256,\n        'num_epochs': 100,\n        'patience': 30\n    },\n    'JAX_DNN': {\n        'hidden_dims': [1024, 512, 256, 128, 64],\n        'dropout_rate': 0.5,\n        'learning_rate': 0.00005,\n        'batch_size': 256,\n        'num_epochs': 100,\n        'patience': 30\n    },\n    'JAX_FSE_Attention': {\n        'hidden_dim': 64,\n        'num_heads': 4,\n        'dropout_rate': 0.5,\n        'learning_rate': 0.0001,\n        'batch_size': 256,\n        'num_epochs': 100,\n        'patience': 30\n    },\n    'JAX_FSE_Attention_DetectorAware': {\n        'hidden_dim': 64,\n        'num_heads': 4,\n        'dropout_rate': 0.5,\n        'learning_rate': 0.0001,\n        'batch_size': 256,\n        'num_epochs': 100,\n        'patience': 30,\n        'detector_embed_dim': 8\n    },\n    'SkLearn_RandomForest': {\n        'n_estimators': 500,\n        'max_depth': 25,\n        'min_samples_split': 10,\n        'min_samples_leaf': 5,\n        'max_features': 'sqrt',\n        'class_weight': 'balanced',\n        'n_jobs': -1,\n        'random_state': 231,\n        'bootstrap': True,\n        'oob_score': True\n    },\n    'XGBoost': {\n    'n_estimators': 500,\n    'max_depth': 7,\n    'learning_rate': 0.1,\n    'subsample': 0.8,\n    'colsample_bytree': 0.8,\n    'min_child_weight': 1,\n    'gamma': 0,\n    'objective': 'multi:softmax',\n    'num_class': 4,\n    'random_state': 231,\n    'n_jobs': -1,\n    'eval_metric': 'mlogloss',\n    'tree_method': 'hist',\n    'device': 'cpu'\n    }\n}\n\n# ============================================================================\n# FORCE_TRAINING \n# ============================================================================\nFORCE_TRAINING = {\n    'JAX_SimpleNN': {'full': False, '0.7-1.5': False, '1-3': False},      \n    'JAX_DNN': {'full': False, '0.7-1.5': False, '1-3': False},              \n    'JAX_FSE_Attention': {'full': False, '0.7-1.5': False, '1-3': False},     \n    'JAX_FSE_Attention_DetectorAware': {'full': True, '0.7-1.5': True, '1-3': True},\n    'SkLearn_RandomForest': {'full': False, '0.7-1.5': False, '1-3': False},\n    'XGBoost': {'full': False, '0.7-1.5': False, '1-3': False}\n}\n\nprint(\"\\n✓ Configuration loaded (Bayesian 0.25 NOISE FIX APPLIED)\")\nprint(f\"  Token value: {BAYES_MISSING_TOKEN} (replaces 0.25 noise)\")\nprint(f\"  Momentum ranges: {len(MOMENTUM_RANGES)}\")\nprint(f\"  Model types: {len(MODEL_TYPES)}\")\nprint(f\"  Particle classes: {NUM_CLASSES}\")\nprint(f\"  Training features: {len(TRAINING_FEATURES)} (includes bayes_available)\")\nprint(f\"  Track selections: Integrated in preprocessing\")\n\n# ============================================================================\n# SECTION 1: IMPORTS\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"SECTION 1: IMPORTS\")\nprint(f\"{'#'*80}\\n\")\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport json\nimport os\nimport time\nimport warnings\nfrom tqdm import tqdm\nwarnings.filterwarnings('ignore')\n\nimport jax\nimport jax.numpy as jnp\nfrom jax import random, grad, jit, vmap\nimport optax\nfrom flax import linen as nn\nfrom flax.training import train_state\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, label_binarize\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score, classification_report, accuracy_score, precision_recall_curve\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport time\n\nimport xgboost as xgb\n\nprint(f\"✓ JAX version: {jax.__version__}\")\nprint(f\"✓ Available devices: {jax.devices()}\")\nprint(f\"✓ All libraries imported\\n\")\n\nprint(f\"{'='*80}\")\nprint(\"✓ SECTIONS 0-1 COMPLETE\")\nprint(f\"{'='*80}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:23.145827Z","iopub.execute_input":"2026-01-20T14:34:23.146124Z","iopub.status.idle":"2026-01-20T14:34:23.164109Z","shell.execute_reply.started":"2026-01-20T14:34:23.146103Z","shell.execute_reply":"2026-01-20T14:34:23.163499Z"}},"outputs":[{"name":"stdout","text":"\n################################################################################\nSECTION 0: CONFIGURATION\n################################################################################\n\n✓ TRACK SELECTIONS (DPG-RECOMMENDED, Nov 2025):\n  • vZ < 10.0 cm\n  • η: -0.8-0.8\n  • DCA_xy < 0.105 cm, DCA_z < 0.12 cm\n  • TPC clusters > 70\n  • ITS clusters > 3\n\n✓ Configuration loaded (Bayesian 0.25 NOISE FIX APPLIED)\n  Token value: -0.25 (replaces 0.25 noise)\n  Momentum ranges: 3\n  Model types: 6\n  Particle classes: 4\n  Training features: 22 (includes bayes_available)\n  Track selections: Integrated in preprocessing\n\n################################################################################\nSECTION 1: IMPORTS\n################################################################################\n\n✓ JAX version: 0.5.2\n✓ Available devices: [CudaDevice(id=0), CudaDevice(id=1)]\n✓ All libraries imported\n\n================================================================================\n✓ SECTIONS 0-1 COMPLETE\n================================================================================\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Section 2: Data Loading and Preprocessing Utilities","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 2: DATA LOADING & PREPROCESSING UTILITIES (BAYESIAN TOKEN FILLING)\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"SECTION 2: UTILITY FUNCTIONS\")\nprint(f\"{'#'*80}\\n\")\n\nprintf80 = lambda: print(f\"{'='*80}\")\n\ndef load_data(csv_path):\n    \"\"\"Load CSV data in chunks for memory efficiency.\"\"\"\n    print(f\"Loading data from {csv_path}...\")\n    df_iter = pd.read_csv(csv_path, dtype='float32', chunksize=500000, low_memory=False)\n    df = pd.concat(df_iter, ignore_index=True)\n    print(f\"✓ Loaded: {df.shape[0]:,} rows × {df.shape[1]} columns\\n\")\n    return df\n\n\ndef pdg_to_species(pdg):\n    \"\"\"Convert PDG code to species index.\"\"\"\n    ap = abs(int(pdg))\n    return PDG_TO_SPECIES.get(ap, -1)\n\n\ndef preprocess_momentum_range(df, momentum_range, bayes_token=-0.25):\n    \"\"\"\n    Preprocess data for a specific momentum range with stratified split.\n    UPDATED: All tracks now included (NONE detector tracks NOT removed in STEP 3)\n    FIXED: Calculates detector modes BEFORE standardization.\n    ✓ NEW: Weighted sampling for real Bayesian data (3x weight)\n    ✓ NEW: Configurable Bayesian fill token\n    \"\"\"\n    printf80()\n    print(f\"Preprocessing {momentum_range['name']}\")\n    printf80()\n    \n    # Filter by momentum\n    df_filtered = df[(df['p'] >= momentum_range['min']) & \n                     (df['p'] < momentum_range['max'])].copy()\n    print(f\"\\nSTEP 1: After momentum filter: {len(df_filtered):,} tracks\")\n    \n    # Apply DPG track selections\n    print(f\"STEP 2: Applying DPG-recommended track selections...\")\n    \n    eta_min = TRACK_SELECTIONS['kinematics']['eta_min']\n    eta_max = TRACK_SELECTIONS['kinematics']['eta_max']\n    df_filtered = df_filtered[(df_filtered['eta'] >= eta_min) & \n                             (df_filtered['eta'] <= eta_max)]\n    print(f\"  After eta cut ({eta_min} to {eta_max}): {len(df_filtered):,} tracks\")\n    \n    dca_xy_max = TRACK_SELECTIONS['dca']['dca_xy_max']\n    dca_z_max = TRACK_SELECTIONS['dca']['dca_z_max']\n    df_filtered = df_filtered[(df_filtered['dca_xy'].abs() <= dca_xy_max) & \n                             (df_filtered['dca_z'].abs() <= dca_z_max)]\n    print(f\"  After DCA cuts: {len(df_filtered):,} tracks\")\n    \n    # ========================================================================\n    # ✓ STEP 3 UPDATED: KEEP ALL TRACKS (NO REMOVAL OF NONE DETECTOR)\n    # ========================================================================\n    print(f\"\\nSTEP 3: Detector configuration overview (NO REMOVAL)...\")\n    has_none = (df_filtered['has_tpc'] == 0) & (df_filtered['has_tof'] == 0)\n    n_none = has_none.sum()\n    print(f\"  Tracks with NONE (has_tpc=0 & has_tof=0): {n_none:,} \"\n          f\"({100.0 * n_none / max(len(df_filtered), 1):.2f}% of sample)\")\n    print(f\"  Total tracks kept (including NONE): {len(df_filtered):,}\")\n    \n    # Handle missing values\n    print(f\"\\nSTEP 4: Handling missing values...\")\n    for feat in DETECTOR_GROUPS['tof']:\n        if feat in df_filtered.columns:\n            fill_val = 0.0 if feat == 'tof_beta' else 999.0\n            df_filtered[feat].fillna(fill_val, inplace=True)\n    \n    for feat in DETECTOR_GROUPS['tpc']:\n        if feat in df_filtered.columns:\n            fill_val = 0.0 if feat == 'tpc_signal' else 999.0\n            df_filtered[feat].fillna(fill_val, inplace=True)\n    \n    # Remove features that don't exist in the dataframe\n    available_features = [f for f in TRAINING_FEATURES if f in df_filtered.columns]\n    \n    # Prepare features and labels\n    X_preprocessed = df_filtered[available_features].values.astype('float32')\n    y_preprocessed = df_filtered['mc_pdg'].values.astype('int32')\n    \n    # Convert PDG codes to species indices (0=pion, 1=kaon, 2=proton, 3=electron)\n    y_preprocessed = np.array([pdg_to_species(pdg) for pdg in y_preprocessed], dtype='int32')\n    \n    # Remove samples with invalid species (-1)\n    valid_mask = y_preprocessed != -1\n    X_preprocessed = X_preprocessed[valid_mask]\n    y_preprocessed = y_preprocessed[valid_mask]\n    \n    print(f\"After PDG conversion and removing invalid species: {len(y_preprocessed):,} tracks\")\n    \n    # ========================================================================\n    # STRATIFIED TRAIN/TEST SPLIT\n    # ========================================================================\n    print(f\"\\nSTEP 5: Stratified train/test split...\")\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X_preprocessed,\n        y_preprocessed,\n        test_size=0.2,\n        random_state=SEED,\n        stratify=y_preprocessed\n    )\n    \n    # Verification: Print class distribution\n    print(f\"\\n{'─'*80}\")\n    print(\"CLASS DISTRIBUTION VERIFICATION (Stratified Split):\")\n    print(f\"{'─'*80}\\n\")\n    \n    print(f\"{'Particle':<12} {'Train Count':<15} {'Train %':<12} {'Test Count':<15} {'Test %':<12}\")\n    print(f\"{'-'*80}\")\n    \n    for i, particle_name in enumerate(PARTICLE_NAMES):\n        train_count = np.sum(y_train == i)\n        train_pct = 100 * train_count / len(y_train)\n        test_count = np.sum(y_test == i)\n        test_pct = 100 * test_count / len(y_test)\n        \n        match = \"PASS\" if abs(train_pct - test_pct) < 1.0 else \"FAIL\"\n        print(f\"{particle_name:<12} {train_count:<15,} {train_pct:<12.2f}% {test_count:<15,} {test_pct:<12.2f}% {match}\")\n    \n    print(f\"\\nTrain/Test class distributions match (stratified split successful)!\")\n    \n    # ========================================================================\n    # DETERMINE DETECTOR MODES BEFORE STANDARDIZATION\n    # ========================================================================\n    print(f\"\\nSTEP 6: Calculating detector modes from UNSCALED data...\")\n    \n    if 'has_tpc' in available_features and 'has_tof' in available_features:\n        has_tpc_idx = available_features.index('has_tpc')\n        has_tof_idx = available_features.index('has_tof')\n        \n        has_tpc_train = (X_train[:, has_tpc_idx] > 0).astype('int32')\n        has_tof_train = (X_train[:, has_tof_idx] > 0).astype('int32')\n        detector_modes_train = has_tpc_train * 1 + has_tof_train * 2\n        \n        has_tpc_test = (X_test[:, has_tpc_idx] > 0).astype('int32')\n        has_tof_test = (X_test[:, has_tof_idx] > 0).astype('int32')\n        detector_modes_test = has_tpc_test * 1 + has_tof_test * 2\n        \n        # ====================================================================\n        # ✓ STEP 6 UPDATED: KEEP ALL DETECTOR MODES INCLUDING NONE (MODE 0)\n        # ====================================================================\n        print(f\"  Keeping ALL detector modes (including NONE=0)\")\n        \n        print(f\"\\n  Detector mode distribution (Train):\")\n        mode_counts_train = np.bincount(detector_modes_train, minlength=4)\n        print(f\"    NONE:     {mode_counts_train[0]:,} \"\n              f\"({100.0 * mode_counts_train[0] / max(len(detector_modes_train), 1):.1f}%)\")\n        print(f\"    TPC only: {mode_counts_train[1]:,} \"\n              f\"({100.0 * mode_counts_train[1] / max(len(detector_modes_train), 1):.1f}%)\")\n        print(f\"    TOF only: {mode_counts_train[2]:,} \"\n              f\"({100.0 * mode_counts_train[2] / max(len(detector_modes_train), 1):.1f}%)\")\n        print(f\"    BOTH:     {mode_counts_train[3]:,} \"\n              f\"({100.0 * mode_counts_train[3] / max(len(detector_modes_train), 1):.1f}%)\")\n        \n        print(f\"\\n  Detector mode distribution (Test):\")\n        mode_counts_test = np.bincount(detector_modes_test, minlength=4)\n        print(f\"    NONE:     {mode_counts_test[0]:,} \"\n              f\"({100.0 * mode_counts_test[0] / max(len(detector_modes_test), 1):.1f}%)\")\n        print(f\"    TPC only: {mode_counts_test[1]:,} \"\n              f\"({100.0 * mode_counts_test[1] / max(len(detector_modes_test), 1):.1f}%)\")\n        print(f\"    TOF only: {mode_counts_test[2]:,} \"\n              f\"({100.0 * mode_counts_test[2] / max(len(detector_modes_test), 1):.1f}%)\")\n        print(f\"    BOTH:     {mode_counts_test[3]:,} \"\n              f\"({100.0 * mode_counts_test[3] / max(len(detector_modes_test), 1):.1f}%)\")\n        \n        # X_train, X_test, y_*, and detector_modes_* are ALL UNCHANGED\n        # All \"NONE\" tracks are included and encoded as detector mode 0\n        \n    else:\n        detector_modes_train = np.zeros(len(X_train), dtype='int32')\n        detector_modes_test = np.zeros(len(X_test), dtype='int32')\n    \n    # ========================================================================\n    # STANDARDISE FEATURES\n    # ========================================================================\n    print(f\"\\nSTEP 7: Standardising features...\")\n    \n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Create detector masks using ORIGINAL unscaled data\n    masks_train = []\n    masks_test = []\n    \n    for group_name in DETECTOR_GROUPS:\n        mask_train = np.zeros(len(X_train), dtype='float32')\n        mask_test = np.zeros(len(X_test), dtype='float32')\n        \n        for feat in DETECTOR_GROUPS[group_name]:\n            if feat in available_features:\n                feat_idx = available_features.index(feat)\n                # Use ORIGINAL unscaled data\n                mask_train += (X_train[:, feat_idx] != 0).astype('float32')\n                mask_test += (X_test[:, feat_idx] != 0).astype('float32')\n        \n        mask_train = (mask_train > 0).astype('float32')\n        mask_test = (mask_test > 0).astype('float32')\n        \n        masks_train.append(mask_train)\n        masks_test.append(mask_test)\n    \n    masks_train = np.column_stack(masks_train) if masks_train else np.zeros((len(X_train), len(DETECTOR_GROUPS)), dtype='float32')\n    masks_test = np.column_stack(masks_test) if masks_test else np.zeros((len(X_test), len(DETECTOR_GROUPS)), dtype='float32')\n    \n    # ========================================================================\n    # ✓ STEP 8 UPDATED: BAYESIAN HANDLING WITH CONFIGURABLE TOKEN\n    # ========================================================================\n    print(f\"\\nSTEP 8: Bayesian data handling with configurable fill token...\")\n    \n    bayes_features = ['bayes_prob_pi', 'bayes_prob_ka', 'bayes_prob_pr', 'bayes_prob_el']\n    bayes_indices = [available_features.index(f) for f in bayes_features if f in available_features]\n    \n    print(f\"  Using fill token: {bayes_token}\")\n    \n    if bayes_indices:\n        # Track which samples have REAL Bayesian data BEFORE filling\n        bayes_real_train = np.zeros(len(X_train), dtype=bool)\n        bayes_real_test = np.zeros(len(X_test), dtype=bool)\n        \n        for bayes_idx in bayes_indices:\n            bayes_real_train |= (X_train[:, bayes_idx] != 0)\n            bayes_real_test |= (X_test[:, bayes_idx] != 0)\n        \n        bayes_real_train = bayes_real_train.astype('float32')\n        bayes_real_test = bayes_real_test.astype('float32')\n        \n        # GET BAYESIAN PREDICTIONS FROM UNSCALED DATA BEFORE FILLING\n        bayes_probs_train = X_train[:, bayes_indices]\n        bayes_probs_test = X_test[:, bayes_indices]\n        bayes_pred_train = np.argmax(bayes_probs_train, axis=1).astype('int32')\n        bayes_pred_test = np.argmax(bayes_probs_test, axis=1).astype('int32')\n        \n        # NOW fill missing Bayesian values with token in SCALED data\n        for bayes_idx in bayes_indices:\n            X_train_scaled[X_train_scaled[:, bayes_idx] == 0, bayes_idx] = bayes_token\n            X_test_scaled[X_test_scaled[:, bayes_idx] == 0, bayes_idx] = bayes_token\n        \n        # Track which have real data (from unscaled)\n        bayes_real_train = bayes_real_train.astype('float32')\n        bayes_real_test = bayes_real_test.astype('float32')\n    else:\n        bayes_real_train = np.zeros(len(X_train_scaled), dtype='float32')\n        bayes_real_test = np.zeros(len(X_test_scaled), dtype='float32')\n        bayes_pred_train = np.zeros(len(X_train), dtype='int32')\n        bayes_pred_test = np.zeros(len(X_test), dtype='int32')\n    \n    n_real_train = np.sum(bayes_real_train > 0)\n    n_real_test = np.sum(bayes_real_test > 0)\n    n_filled_train = len(X_train) - n_real_train\n    n_filled_test = len(X_test) - n_real_test\n    \n    print(f\"  Train - Real Bayesian: {n_real_train:,} ({100*n_real_train/len(X_train):.1f}%) | Filled: {n_filled_train:,} ({100*n_filled_train/len(X_train):.1f}%)\")\n    print(f\"  Test  - Real Bayesian: {n_real_test:,} ({100*n_real_test/len(X_test):.1f}%) | Filled: {n_filled_test:,} ({100*n_filled_test/len(X_test):.1f}%)\")\n    print(f\"  ✓ Missing values filled with token: {bayes_token}\")\n\n    # ========================================================================\n    # ✓ STEP 9 ADDED: WEIGHTED SAMPLING - UPWEIGHT REAL BAYESIAN DATA 3X\n    # ========================================================================\n    print(f\"\\nSTEP 9: Computing sample weights for training...\")\n    \n    # Create weights: real Bayesian = 3.0, filled Bayesian = 1.0\n    sample_weights_train = np.where(bayes_real_train > 0, 3.0, 1.0).astype('float32')\n    sample_weights_test = np.where(bayes_real_test > 0, 3.0, 1.0).astype('float32')\n    \n    # Normalise weights so mean = 1.0\n    sample_weights_train = sample_weights_train / np.mean(sample_weights_train)\n    sample_weights_test = sample_weights_test / np.mean(sample_weights_test)\n    \n    n_weighted_train = np.sum(sample_weights_train)\n    effective_size_train = np.sum(sample_weights_train) / np.mean(sample_weights_train)\n    \n    print(f\"  Real Bayesian weight: 3.0x\")\n    print(f\"  Filled Bayesian weight: 1.0x (baseline)\")\n    print(f\"  Total effective sample size: {effective_size_train:,.0f} (was {len(X_train):,})\")\n    print(f\"  Weighted sum: {n_weighted_train:.1f}\")\n    \n    return {\n        'X_train_scaled': X_train_scaled,\n        'X_test_scaled': X_test_scaled,\n        'y_train': y_train,\n        'y_test': y_test,\n        'masks_train': masks_train,\n        'masks_test': masks_test,\n        'detector_modes_train': detector_modes_train,\n        'detector_modes_test': detector_modes_test,\n        'bayes_availability_train': bayes_real_train,\n        'bayes_availability_test': bayes_real_test,\n        'bayes_pred_original_train': bayes_pred_train,\n        'bayes_pred_original_test': bayes_pred_test,\n        'scaler': scaler,\n        'training_features': available_features,\n        'sample_weights_train': sample_weights_train,\n        'sample_weights_test': sample_weights_test,\n    }\n\n\ndef get_model_path(momentum_range_key, model_type, mode='save'):\n    \"\"\"Get file path for model save/load.\"\"\"\n    model_subdir = \"trained_models\"\n    working_path = f\"/kaggle/working/{model_subdir}/{momentum_range_key}_{model_type}.pkl\"\n    input_path = f\"/kaggle/input/jax-models/jax-models/{momentum_range_key}_{model_type}.pkl\"\n    \n    if mode == \"save\":\n        return working_path\n    else:\n        return working_path if os.path.exists(working_path) else input_path\n\n\ndef load_single_model(momentum_range_key, model_type):\n    \"\"\"Load a single model from disk.\"\"\"\n    path = get_model_path(momentum_range_key, model_type, mode=\"load\")\n    \n    if os.path.exists(path):\n        try:\n            with open(path, 'rb') as f:\n                results = pickle.load(f)\n            print(f\"✓ Loaded from: {path}\")\n            return results, path\n        except Exception as e:\n            print(f\"Error loading {path}: {e}\")\n    \n    return None, path\n\n\ndef save_single_model(momentum_range_key, model_type, results):\n    \"\"\"Save a single model to disk.\"\"\"\n    path = get_model_path(momentum_range_key, model_type, mode=\"save\")\n    \n    os.makedirs(os.path.dirname(path), exist_ok=True)\n    \n    try:\n        with open(path, 'wb') as f:\n            pickle.dump(results, f)\n        print(f\"✓ Saved to: {path}\")\n    except Exception as e:\n        print(f\"Error saving to {path}: {e}\")\n\n\nprint(\"✓ Preprocessing utilities defined (Bayesian token filling + ALL TRACKS INCLUDED)\")\nprint(\"✓ Track selections integrated (DPG-recommended cuts applied)\")\nprint(\"✓ Model persistence utilities defined\")\nprint(f\"\\n{'='*80}\")\nprint(\"✓ SECTION 2 COMPLETE\")\nprint(\"✓ Detector modes calculated BEFORE standardization!\")\nprint(\"✓ ALL detector modes kept (including NONE=0)!\")\nprint(\"✓ Bayesian missing values filled with -0.25 token!\")\nprint(\"✓ Real vs filled Bayesian data properly tracked!\")\nprint(\"✓ DPG track selections (η, DCA) integrated in preprocessing!\")\nprint(\"✓ PDG codes converted to species indices (0=π, 1=K, 2=p, 3=e)!\")\nprint(\"✓ ALL TRACKS INCLUDED (no exclusion of NONE detector or missing Bayes)!\")\nprint(f\"{'='*80}\\n\")\n\n# ============================================================================\n# GLOBAL DATA STORAGE (For sharing between sections)\n# ============================================================================\nall_results_by_model_and_range = {}\n\nprint(f\"✓ Global storage initialised\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:23.249222Z","iopub.execute_input":"2026-01-20T14:34:23.249918Z","iopub.status.idle":"2026-01-20T14:34:23.283884Z","shell.execute_reply.started":"2026-01-20T14:34:23.249893Z","shell.execute_reply":"2026-01-20T14:34:23.283146Z"}},"outputs":[{"name":"stdout","text":"\n################################################################################\nSECTION 2: UTILITY FUNCTIONS\n################################################################################\n\n✓ Preprocessing utilities defined (Bayesian token filling + ALL TRACKS INCLUDED)\n✓ Track selections integrated (DPG-recommended cuts applied)\n✓ Model persistence utilities defined\n\n================================================================================\n✓ SECTION 2 COMPLETE\n✓ Detector modes calculated BEFORE standardization!\n✓ ALL detector modes kept (including NONE=0)!\n✓ Bayesian missing values filled with -0.25 token!\n✓ Real vs filled Bayesian data properly tracked!\n✓ DPG track selections (η, DCA) integrated in preprocessing!\n✓ PDG codes converted to species indices (0=π, 1=K, 2=p, 3=e)!\n✓ ALL TRACKS INCLUDED (no exclusion of NONE detector or missing Bayes)!\n================================================================================\n\n✓ Global storage initialised\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# ============================================================================\n# HELPER FUNCTION: MASK AUGMENTATION FOR FSE TRAINING\n# ============================================================================\n\ndef augment_detector_mask(mask, drop_prob=0.15, rng=None):\n    \"\"\"\n    Randomly drop detector groups during training to prevent overfitting.\n    \n    Args:\n        mask: (batch_size, num_groups) detector availability mask\n        drop_prob: Probability to drop each detector group (default: 0.15)\n        rng: JAX random key for reproducibility\n    \n    Returns:\n        mask_aug: Augmented mask with some detectors randomly zeroed\n    \n    Why: FSE models can overfit to detector-group patterns in filled data.\n    Mask augmentation teaches model to be robust to detector availability\n    variations during inference.\n    \n    Example:\n        Original mask (first 3 samples):\n          [[1. 1. 1. 1.]\n           [1. 0. 1. 1.]\n           [0. 1. 1. 1.]]\n        \n        After augmentation (drop_prob=0.15):\n          [[1. 1. 0. 1.]\n           [1. 0. 1. 1.]\n           [0. 1. 1. 1.]]\n    \"\"\"\n    if rng is None:\n        rng = random.PRNGKey(np.random.randint(0, 2**31))\n    \n    # Generate random keep probabilities per detector group\n    keep_prob = 1.0 - drop_prob\n    dropout_mask = random.bernoulli(rng, keep_prob, shape=mask.shape)\n    \n    # Apply to mask (preserve 0s, potentially zero out 1s)\n    mask_aug = mask * dropout_mask.astype(mask.dtype)\n    \n    return mask_aug\n\n\n# ========================================================================\n# TEST MASK AUGMENTATION\n# ========================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"MASK AUGMENTATION TEST\")\nprint(\"=\"*80)\ntest_mask = np.ones((5, 4), dtype='float32')  # 5 samples, 4 detector groups\ntest_mask[1, 1] = 0  # Sample 1 missing detector group 1\ntest_mask[2, 0] = 0  # Sample 2 missing detector group 0\n\nprint(f\"Original mask:\")\nprint(test_mask)\n\ntest_rng = random.PRNGKey(42)\ntest_aug = augment_detector_mask(test_mask, drop_prob=0.15, rng=test_rng)\nprint(f\"\\nAfter augmentation (drop_prob=0.15):\")\nprint(test_aug)\nprint(f\"Augmentation drop rate: {100 * (1 - np.mean(test_aug)):.1f}%\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:23.285305Z","iopub.execute_input":"2026-01-20T14:34:23.285570Z","iopub.status.idle":"2026-01-20T14:34:23.305335Z","shell.execute_reply.started":"2026-01-20T14:34:23.285547Z","shell.execute_reply":"2026-01-20T14:34:23.304697Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nMASK AUGMENTATION TEST\n================================================================================\nOriginal mask:\n[[1. 1. 1. 1.]\n [1. 0. 1. 1.]\n [0. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]]\n\nAfter augmentation (drop_prob=0.15):\n[[1. 1. 1. 1.]\n [1. 0. 1. 1.]\n [0. 1. 1. 0.]\n [0. 0. 1. 1.]\n [1. 1. 1. 1.]]\nAugmentation drop rate: 25.0%\n================================================================================\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Section 3: Model definitions & training functions","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 3: MODEL DEFINITIONS & TRAINING UTILITIES (SHARED + PHASE 1)\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"SECTION 3: MODEL DEFINITIONS & TRAINING\")\nprint(f\"{'#'*80}\\n\")\n\n# ============================================================================\n# 3.1: LOSS FUNCTION\n# ============================================================================\n\ndef focal_loss(logits, labels, class_weights=None, alpha=0.5, gamma=2.5):\n    \"\"\"\n    Improved Focal Loss with tuned parameters for particle identification.\n    \n    Why these parameters?\n    - alpha=0.5 (up from 0.25): Increases weighting of rare classes (kaon, electron)\n    - gamma=2.5 (up from 2.0): Increases focus on hard-to-classify examples\n    \n    Focal Loss formula: FL(pt) = -alpha * (1 - pt)^gamma * log(pt)\n    - When model is uncertain (pt ≈ 0.5): high loss (wants to learn)\n    - When model is confident (pt ≈ 1.0): low loss (already learned)\n    \"\"\"\n    probs = jax.nn.softmax(logits, axis=-1)\n    batch_size = labels.shape[0]\n    pt = probs[jnp.arange(batch_size), labels]\n    \n    ce_loss = -jnp.log(pt + 1e-7)\n    w = class_weights[labels] if class_weights is not None else 1.0\n    focal_weight = alpha * (1.0 - pt) ** gamma  # ← TUNED PARAMETERS\n    loss = jnp.mean(w * focal_weight * ce_loss)\n    \n    return loss\n\nprint(f\"\\n{'='*80}\")\nprint(\"FOCAL LOSS PARAMETERS (TUNED FOR PARTICLE PHYSICS)\")\nprint(f\"  alpha=0.5 (rare class weighting)\")\nprint(f\"  gamma=2.5 (hard example focusing)\")\nprint(f\"{'='*80}\\n\")\n\n# ============================================================================\n# 3.2: MASK AUGMENTATION HELPER (NEW - Phase 1)\n# ============================================================================\n\ndef augment_detector_mask(mask, drop_prob=0.15, rng=None):\n    \"\"\"\n    Randomly drop detector groups during training to prevent overfitting.\n    \n    Args:\n        mask: (batch_size, num_groups) detector availability mask\n        drop_prob: Probability to drop each detector group (default: 0.15)\n        rng: JAX random key for reproducibility\n    \n    Returns:\n        mask_aug: Augmented mask with some detectors randomly zeroed\n    \n    Why: FSE models can overfit to detector-group patterns in filled data.\n    Mask augmentation teaches model to be robust to detector availability\n    variations during inference.\n    \"\"\"\n    if rng is None:\n        rng = random.PRNGKey(np.random.randint(0, 2**31))\n    \n    # Generate random keep probabilities per detector group\n    keep_prob = 1.0 - drop_prob\n    dropout_mask = random.bernoulli(rng, keep_prob, shape=mask.shape)\n    \n    # Apply to mask (preserve 0s, potentially zero out 1s)\n    mask_aug = mask * dropout_mask.astype(mask.dtype)\n    \n    return mask_aug\n\n\n# ============================================================================\n# 3.3: MODEL ARCHITECTURES\n# ============================================================================\n\nclass JAX_SimpleNN(nn.Module):\n    \"\"\"Simple feedforward neural network.\"\"\"\n    hidden_dims: list\n    num_classes: int\n    dropout_rate: float = 0.3\n    \n    @nn.compact\n    def __call__(self, x, training: bool = False):\n        for dim in self.hidden_dims:\n            x = nn.Dense(dim)(x)\n            x = nn.relu(x)\n            x = nn.Dropout(rate=self.dropout_rate, deterministic=not training)(x)\n        x = nn.Dense(self.num_classes)(x)\n        return x\n\n\nclass JAX_DNN(nn.Module):\n    \"\"\"Deeper neural network with batch normalisation.\"\"\"\n    hidden_dims: list\n    num_classes: int\n    dropout_rate: float = 0.3\n    \n    @nn.compact\n    def __call__(self, x, training: bool = False):\n        for dim in self.hidden_dims:\n            x = nn.Dense(dim)(x)\n            x = nn.BatchNorm(use_running_average=not training)(x)\n            x = nn.relu(x)\n            x = nn.Dropout(rate=self.dropout_rate, deterministic=not training)(x)\n        x = nn.Dense(self.num_classes)(x)\n        return x\n\n\nclass JAX_FSE_Attention(nn.Module):\n    \"\"\"\n    Feature Set Embedding with Multi-Head Attention (IMPROVED Phase 1).\n    \n    Key improvements for addressing overfitting:\n    ✓ Attention weight regularization (LayerNorm after attention)\n    ✓ Residual connections to preserve group information\n    ✓ Constrained gating that respects missing detector groups\n    ✓ LayerNorm in classification head for stability\n    ✓ Separate attention dropout for better regularization\n    \n    Expected improvement: +2-3% accuracy (especially on low-data ranges)\n    \"\"\"\n    hidden_dim: int = 64\n    num_heads: int = 4\n    num_classes: int = 4\n    dropout_rate: float = 0.3\n    attention_dropout: float = 0.2  # NEW: Separate dropout for attention\n    use_residual: bool = True  # NEW: Enable residual connections\n    attn_reg_weight: float = 0.01  # NEW: For future regularization\n    \n    @nn.compact\n    def __call__(self, x, group_mask, training: bool = False):\n        batch_size = x.shape[0]\n        num_groups = int(group_mask.shape[1])\n        \n        # ====================================================================\n        # LAYER 1: Project features to per-group embeddings\n        # ====================================================================\n        feat_proj = nn.Dense(self.hidden_dim * num_groups)(x)\n        feat_proj = feat_proj.reshape(batch_size, num_groups, self.hidden_dim)\n        feat_proj = feat_proj * group_mask[:, :, None]\n        \n        # ====================================================================\n        # LAYER 2: IMPROVED Multi-Head Attention\n        # ====================================================================\n        \n        # Create attention mask to prevent attending to missing groups\n        attn_mask = group_mask[:, None, None, :]\n        \n        # Apply multi-head attention with separate dropout\n        # FIX: Pass deterministic parameter (opposite of training)\n        feat_attn = nn.MultiHeadDotProductAttention(\n            num_heads=self.num_heads,\n            dropout_rate=self.attention_dropout\n        )(feat_proj, feat_proj, mask=attn_mask, deterministic=not training)\n        \n        # IMPROVED: LayerNorm after attention for regularization\n        feat_attn = nn.LayerNorm()(feat_attn)\n        \n        # IMPROVED: Add residual connection to preserve original group info\n        if self.use_residual:\n            feat_attn = feat_attn + (feat_proj * 0.5)\n        \n        # ====================================================================\n        # LAYER 3: IMPROVED Constrained Gating\n        # ====================================================================\n        \n        # Learn gating weights for each group\n        gates = nn.Dense(self.hidden_dim)(feat_attn)\n        gates = nn.LayerNorm()(gates)  # Normalize for stability\n        gates = nn.sigmoid(gates)  # Output in [0, 1]\n        \n        # IMPROVED: Enforce that missing groups have gate = 0\n        gates = gates * group_mask[:, :, None]\n        \n        feat_gated = feat_attn * gates\n        \n        # ====================================================================\n        # LAYER 4: IMPROVED Masked Pooling (Group-Normalized)\n        # ====================================================================\n        \n        # Count active groups per sample (to normalize pooling)\n        group_count = jnp.clip(jnp.sum(group_mask, axis=1, keepdims=True), a_min=1.0)\n        \n        # Pool: sum over groups, normalize by number of active groups\n        pooled = jnp.sum(feat_gated * group_mask[:, :, None], axis=1) / group_count\n        \n        # ====================================================================\n        # LAYER 5: Classification Head (Improved with LayerNorm)\n        # ====================================================================\n        \n        # First dense layer\n        x = nn.Dense(128)(pooled)\n        x = nn.relu(x)\n        x = nn.LayerNorm()(x)  # NEW: LayerNorm for stability\n        x = nn.Dropout(rate=self.dropout_rate, deterministic=not training)(x)\n        \n        # Second dense layer\n        x = nn.Dense(64)(x)\n        x = nn.relu(x)\n        x = nn.LayerNorm()(x)  # NEW: LayerNorm for stability\n        x = nn.Dropout(rate=self.dropout_rate, deterministic=not training)(x)\n        \n        # Output logits (4 classes)\n        x = nn.Dense(self.num_classes)(x)\n        \n        return x\n\nclass JAX_FSE_Attention_DetectorAware(nn.Module):\n    \"\"\"\n    Feature Set Embedding + Detector-Aware Classification (IMPROVED Phase 1++).\n    \n    Solves the problem of TPC-only vs TPC+TOF dominance in 0.7-1.5 GeV/c.\n    \n    Key improvements:\n    ✓ Detector-aware feature transformation (learned gating)\n    ✓ Mode-specific affine transformations (scale + shift per mode)\n    ✓ Increased detector embedding dimension (8 → 24)\n    ✓ Enhanced classification head for combined input\n    ✓ Better focal loss tuning (α: 0.25 → 0.4)\n    \n    Expected improvement: +3-5% accuracy on critical 0.7-1.5 GeV/c\n    \"\"\"\n    hidden_dim: int = 64\n    num_heads: int = 4\n    num_classes: int = 4\n    dropout_rate: float = 0.3\n    attention_dropout: float = 0.2\n    detector_embed_dim: int = 24  # IMPROVED: Increased from 8 to 24\n    use_residual: bool = True\n    attn_reg_weight: float = 0.01\n    \n    @nn.compact\n    def __call__(self, x, group_mask, detector_mode, training: bool = False):\n        \"\"\"\n        Args:\n            x: (batch, num_features) - standardized features\n            group_mask: (batch, num_groups) - detector availability mask\n            detector_mode: (batch,) - int32 array\n                0 = NONE (no detectors)\n                1 = TPC_ONLY (dominant in 0.7-1.5)\n                2 = TOF_ONLY (rare)\n                3 = TPC_TOF (best separation)\n            training: bool for dropout\n        \"\"\"\n        batch_size = x.shape[0]\n        num_groups = int(group_mask.shape[1])\n        \n        # ====================================================================\n        # BRANCH A: Feature Extraction (Same as improved FSE)\n        # ====================================================================\n        \n        # Project to per-group embeddings\n        feat_proj = nn.Dense(self.hidden_dim * num_groups)(x)\n        feat_proj = feat_proj.reshape(batch_size, num_groups, self.hidden_dim)\n        feat_proj = feat_proj * group_mask[:, :, None]\n        \n        # Multi-head attention\n        attn_mask = group_mask[:, None, None, :]\n        feat_attn = nn.MultiHeadDotProductAttention(\n            num_heads=self.num_heads,\n            dropout_rate=self.attention_dropout\n        )(feat_proj, feat_proj, mask=attn_mask, deterministic=not training)\n        \n        feat_attn = nn.LayerNorm()(feat_attn)\n        \n        # Residual connection\n        if self.use_residual:\n            feat_attn = feat_attn + (feat_proj * 0.5)\n        \n        # Constrained gating\n        gates = nn.Dense(self.hidden_dim)(feat_attn)\n        gates = nn.LayerNorm()(gates)\n        gates = nn.sigmoid(gates) * group_mask[:, :, None]\n        \n        feat_gated = feat_attn * gates\n        \n        # Masked pooling\n        group_count = jnp.clip(jnp.sum(group_mask, axis=1, keepdims=True), a_min=1.0)\n        pooled_features = jnp.sum(feat_gated * group_mask[:, :, None], axis=1) / group_count\n        \n        # ====================================================================\n        # BRANCH B: Detector Mode Embedding (IMPROVED)\n        # ====================================================================\n        \n        # One-hot encode detector mode: (batch, 4)\n        detector_onehot = jax.nn.one_hot(detector_mode, num_classes=4)\n        \n        # Dense embedding: 4 → 24 dimensions (IMPROVED: was 8)\n        detector_emb = nn.Dense(self.detector_embed_dim)(detector_onehot)\n        detector_emb = nn.relu(detector_emb)\n        detector_emb = nn.Dropout(rate=self.dropout_rate, deterministic=not training)(detector_emb)\n        \n        # ====================================================================\n        # FUSION: IMPROVED Detector-Aware Feature Fusion (NEW!)\n        # ====================================================================\n        \n        # Project detector embedding to match feature dimension\n        detector_proj = nn.Dense(self.hidden_dim)(detector_emb)  # (batch, hidden_dim)\n        \n        # Learn gating to blend detector info with pooled features\n        # This learns: when should we trust the detector mode vs features?\n        combined_input = jnp.concatenate([detector_proj, pooled_features], axis=-1)\n        fusion_gate = nn.Dense(1)(combined_input)\n        fusion_gate = nn.sigmoid(fusion_gate)  # (batch, 1) in [0, 1]\n        \n        # Weighted combination: blend pooled features with detector-informed features\n        # When fusion_gate ≈ 0: use pooled_features\n        # When fusion_gate ≈ 1: use detector_proj\n        fusion_attn = pooled_features * (1.0 - fusion_gate) + detector_proj * fusion_gate\n        \n        # ====================================================================\n        # MODE-SPECIFIC AFFINE TRANSFORMATION (NEW!)\n        # ====================================================================\n        \n        # Learn scale and shift for each detector mode\n        mode_scales = nn.Dense(self.hidden_dim)(detector_onehot)\n        mode_scales = nn.sigmoid(mode_scales) * 2.0  # Scale in [0, 2]\n        \n        mode_shifts = nn.Dense(self.hidden_dim)(detector_onehot)\n        mode_shifts = jnp.tanh(mode_shifts) * 0.5  # Shift in [-0.5, 0.5]\n        \n        # Apply affine: y = scale * x + shift\n        pooled_features_transformed = pooled_features * mode_scales + mode_shifts\n        \n        # ====================================================================\n        # COMBINE ALL BRANCHES\n        # ====================================================================\n        \n        # Weighted combination: transformed features + fusion info\n        x_fused = pooled_features_transformed + (fusion_attn * 0.5)\n        \n        # Concatenate: fused features + detector embedding\n        x_combined = jnp.concatenate([x_fused, detector_emb], axis=-1)\n        \n        # ====================================================================\n        # CLASSIFICATION HEAD (Expanded for larger input)\n        # ====================================================================\n        \n        # First layer: expanded size to handle concatenated input (88 dims)\n        x_head = nn.Dense(160)(x_combined)\n        x_head = nn.relu(x_head)\n        x_head = nn.LayerNorm()(x_head)\n        x_head = nn.Dropout(rate=self.dropout_rate, deterministic=not training)(x_head)\n        \n        # Second layer: intermediate dimension\n        x_head = nn.Dense(80)(x_head)\n        x_head = nn.relu(x_head)\n        x_head = nn.LayerNorm()(x_head)\n        x_head = nn.Dropout(rate=self.dropout_rate, deterministic=not training)(x_head)\n        \n        # Output logits (4 classes)\n        logits = nn.Dense(self.num_classes)(x_head)\n        \n        return logits\n\n\n# ============================================================================\n# 3.4: TRAINING STEP FUNCTIONS\n# ============================================================================\n\n@jit\ndef train_step_simple(state, batch_x, batch_y, rng, class_weights):\n    \"\"\"Training step for SimpleNN (no BatchNorm).\"\"\"\n    def loss_fn(params):\n        logits = state.apply_fn({'params': params}, batch_x, training=True, rngs={'dropout': rng})\n        loss = focal_loss(logits, batch_y, class_weights=class_weights)\n        return loss\n    \n    loss, grads = jax.value_and_grad(loss_fn)(state.params)\n    state = state.apply_gradients(grads=grads)\n    return state, loss\n\n\n@jit\ndef train_step_batchnorm(state, batch_x, batch_y, rng, class_weights):\n    \"\"\"Training step for DNN (with BatchNorm).\"\"\"\n    def loss_fn(params):\n        variables = {'params': params, 'batch_stats': state.batch_stats}\n        logits, new_model_state = state.apply_fn(\n            variables, batch_x, training=True, rngs={'dropout': rng}, mutable=['batch_stats']\n        )\n        loss = focal_loss(logits, batch_y, class_weights=class_weights)\n        return loss, new_model_state\n    \n    (loss, new_model_state), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n    state = state.apply_gradients(grads=grads)\n    state = state.replace(batch_stats=new_model_state['batch_stats'])\n    return state, loss\n\n\n@jax.jit\ndef train_step_fse(state, batch_x, batch_mask, batch_y, rng, class_weights):\n    \"\"\"\n    UPDATED Training step for FSE Attention with optimizations.\n    \n    Improvements:\n    ✓ Reduced mask augmentation: drop_prob 0.15 → 0.08\n      Prevents aggressive dropout from destabilizing training\n    ✓ Better RNG key management (separate dropout key from main key)\n    \"\"\"\n    # Split RNG: one for dropout mask, one for model dropout\n    dropout_key, subkey = random.split(rng)\n    \n    # IMPROVED: Reduced drop probability from 0.15 to 0.08\n    batch_mask_aug = augment_detector_mask(batch_mask, drop_prob=0.08, rng=dropout_key)\n    \n    def loss_fn(params):\n        logits = state.apply_fn(\n            {'params': params},\n            batch_x,\n            batch_mask_aug,\n            training=True,\n            rngs={'dropout': subkey}\n        )\n        loss = focal_loss(logits, batch_y, class_weights=class_weights)\n        return loss\n    \n    # Compute loss and gradients\n    loss, grads = jax.value_and_grad(loss_fn)(state.params)\n    \n    # Update model parameters\n    state = state.apply_gradients(grads=grads)\n    \n    return state, loss\n\n\n\n@jax.jit\ndef train_step_fse_aware(state, batch_x, batch_mask, batch_modes, batch_y, rng, class_weights):\n    \"\"\"\n    UPDATED Training step for Detector-Aware FSE with optimizations.\n    \n    Improvements:\n    ✓ Reduced mask augmentation: drop_prob 0.15 → 0.08\n    ✓ Tuned focal loss: alpha 0.25 → 0.4 (stronger rare class weighting)\n    ✓ Better RNG key management\n    \"\"\"\n    # Split RNG\n    dropout_key, subkey = random.split(rng)\n    \n    # IMPROVED: Reduced drop probability (same as base FSE)\n    batch_mask_aug = augment_detector_mask(batch_mask, drop_prob=0.08, rng=dropout_key)\n    \n    def loss_fn(params):\n        logits = state.apply_fn(\n            {'params': params},\n            batch_x,\n            batch_mask_aug,\n            batch_modes,\n            training=True,\n            rngs={'dropout': subkey}\n        )\n        # IMPROVED: Tuned focal loss for detector-aware (alpha=0.4 vs 0.25)\n        loss = focal_loss(logits, batch_y, class_weights=class_weights, alpha=0.4, gamma=2.5)\n        return loss\n    \n    # Compute loss and gradients\n    loss, grads = jax.value_and_grad(loss_fn)(state.params)\n    \n    # Update model parameters\n    state = state.apply_gradients(grads=grads)\n    \n    return state, loss\n\n\n# ============================================================================\n# 3.5: EVALUATION FUNCTIONS\n# ============================================================================\n\n@jit\ndef eval_step_simple(state, batch_x, batch_y):\n    \"\"\"Evaluation step for SimpleNN.\"\"\"\n    logits = state.apply_fn({'params': state.params}, batch_x, training=False)\n    pred = jnp.argmax(logits, axis=-1)\n    accuracy = jnp.mean(pred == batch_y)\n    return accuracy, logits\n\n\n@jit\ndef eval_step_batchnorm(state, batch_x, batch_y):\n    \"\"\"Evaluation step for DNN with BatchNorm.\"\"\"\n    variables = {'params': state.params, 'batch_stats': state.batch_stats}\n    logits = state.apply_fn(variables, batch_x, training=False)\n    pred = jnp.argmax(logits, axis=-1)\n    accuracy = jnp.mean(pred == batch_y)\n    return accuracy, logits\n\n\n@jit\ndef eval_step_fse(state, batch_x, batch_mask, batch_y):\n    \"\"\"Evaluation step for FSE+Attention.\"\"\"\n    logits = state.apply_fn({'params': state.params}, batch_x, batch_mask, training=False)\n    pred = jnp.argmax(logits, axis=-1)\n    accuracy = jnp.mean(pred == batch_y)\n    return accuracy, logits\n\n\n@jit\ndef eval_step_fse_aware(state, batch_x, batch_mask, batch_modes, batch_y):\n    \"\"\"Evaluation step for Detector-Aware FSE+Attention (Phase 1)\"\"\"\n    logits = state.apply_fn(\n        {'params': state.params}, batch_x, batch_mask, batch_modes, training=False\n    )\n    pred = jnp.argmax(logits, axis=-1)\n    accuracy = jnp.mean(pred == batch_y)\n    return accuracy, logits\n\n\ndef batch_evaluate_simple(state, X_data, y_data, batch_size=1024):\n    \"\"\"Batch evaluation for SimpleNN.\"\"\"\n    all_logits, all_accs = [], []\n    num_batches = (len(X_data) + batch_size - 1) // batch_size\n    \n    for batch_idx in range(num_batches):\n        start_idx = batch_idx * batch_size\n        end_idx = min(start_idx + batch_size, len(X_data))\n        batch_x, batch_y = X_data[start_idx:end_idx], y_data[start_idx:end_idx]\n        \n        batch_acc, batch_logits = eval_step_simple(state, batch_x, batch_y)\n        all_logits.append(batch_logits)\n        all_accs.append(batch_acc)\n    \n    return np.mean(all_accs), jnp.concatenate(all_logits, axis=0)\n\n\ndef batch_evaluate_batchnorm(state, X_data, y_data, batch_size=1024):\n    \"\"\"Batch evaluation for DNN with BatchNorm.\"\"\"\n    all_logits, all_accs = [], []\n    num_batches = (len(X_data) + batch_size - 1) // batch_size\n    \n    for batch_idx in range(num_batches):\n        start_idx = batch_idx * batch_size\n        end_idx = min(start_idx + batch_size, len(X_data))\n        batch_x, batch_y = X_data[start_idx:end_idx], y_data[start_idx:end_idx]\n        \n        batch_acc, batch_logits = eval_step_batchnorm(state, batch_x, batch_y)\n        all_logits.append(batch_logits)\n        all_accs.append(batch_acc)\n    \n    return np.mean(all_accs), jnp.concatenate(all_logits, axis=0)\n\n\ndef batch_evaluate_fse(state, X_data, mask_data, y_data, batch_size=1024):\n    \"\"\"Batch evaluation for FSE+Attention.\"\"\"\n    all_logits, all_accs = [], []\n    num_batches = (len(X_data) + batch_size - 1) // batch_size\n    \n    for batch_idx in range(num_batches):\n        start_idx = batch_idx * batch_size\n        end_idx = min(start_idx + batch_size, len(X_data))\n        batch_x = X_data[start_idx:end_idx]\n        batch_mask = mask_data[start_idx:end_idx]\n        batch_y = y_data[start_idx:end_idx]\n        \n        batch_acc, batch_logits = eval_step_fse(state, batch_x, batch_mask, batch_y)\n        all_logits.append(batch_logits)\n        all_accs.append(batch_acc)\n    \n    return np.mean(all_accs), jnp.concatenate(all_logits, axis=0)\n\n\ndef batch_evaluate_fse_aware(state, X_data, mask_data, modes_data, y_data, batch_size=1024):\n    \"\"\"Batch evaluation for Detector-Aware FSE+Attention (Phase 1)\"\"\"\n    all_logits = []\n    all_accs = []\n    \n    num_batches = (len(X_data) + batch_size - 1) // batch_size\n    \n    for batch_idx in range(num_batches):\n        start_idx = batch_idx * batch_size\n        end_idx = min(start_idx + batch_size, len(X_data))\n        \n        batch_x = X_data[start_idx:end_idx]\n        batch_mask = mask_data[start_idx:end_idx]\n        batch_modes = modes_data[start_idx:end_idx]\n        batch_y = y_data[start_idx:end_idx]\n        \n        batch_acc, batch_logits = eval_step_fse_aware(state, batch_x, batch_mask, \n                                                     batch_modes, batch_y)\n        all_logits.append(batch_logits)\n        all_accs.append(batch_acc)\n    \n    all_logits = jnp.concatenate(all_logits, axis=0)\n    avg_acc = np.mean(all_accs)\n    \n    return avg_acc, all_logits\n\n\n# ============================================================================\n# 3.6: EXTENDED TRAINSTATE FOR BATCHNORM\n# ============================================================================\n\nclass TrainStateWithBatchStats(train_state.TrainState):\n    \"\"\"Extended TrainState that includes batch_stats for BatchNorm.\"\"\"\n    batch_stats: any = None\n\n\n# ============================================================================\n# 3.7: UNIFIED TRAINING ORCHESTRATOR\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"SECTION 3.7: UNIFIED TRAINING ORCHESTRATOR\")\nprint(f\"{'#'*80}\\n\")\n\ndef train_model(model_type, momentum_range, preprocessing_data, force_training=False, mr_key=None):\n    \"\"\"\n    Unified training function for all model types.\n    \n    Args:\n        model_type: str - model name (JAX_SimpleNN, JAX_DNN, JAX_FSE_Attention, JAX_FSE_Attention_DetectorAware)\n        momentum_range: dict - momentum range config (from MOMENTUM_RANGES.values())\n        preprocessing_data: dict - preprocessed data from preprocess_momentum_range()\n        force_training: bool - force retraining (skip loading cached models)\n        mr_key: str - momentum range key (from MOMENTUM_RANGES.keys(), passed from SECTION 4)\n    \"\"\"\n    # Use passed mr_key or derive from momentum_range name\n    if mr_key is None:\n        mr_key = momentum_range.get('name', 'unknown').replace(' ', '_').lower()\n    \n    params = HYPERPARAMETERS[model_type]\n    \n    print(f\"\\n{'*'*80}\")\n    print(f\"{model_type} - {momentum_range['name']}\")\n    print(f\"{'*'*80}\")\n    print(f\"✓ DPG Track Selections Applied (Section 2):\")\n    print(f\"  • η ∈ [{TRACK_SELECTIONS['kinematics']['eta_min']}, {TRACK_SELECTIONS['kinematics']['eta_max']}]\")\n    print(f\"  • DCA_xy < {TRACK_SELECTIONS['dca']['dca_xy_max']}, DCA_z < {TRACK_SELECTIONS['dca']['dca_z_max']}\")\n    print(f\"  • TPC clusters > {TRACK_SELECTIONS['tpc']['tpc_clusters_min']}\")\n    print(f\"  • Bayesian mask fixed (token = {BAYES_MISSING_TOKEN})\")\n    print(f\"{'*'*80}\\n\")\n\n    \n    # Try to load existing model\n    if not force_training:\n        loaded, _ = load_single_model(mr_key, model_type)\n        if loaded is not None:\n            print(f\"✓ Loaded existing model (skipped training)\")\n            return loaded\n    \n    print(\"Training from scratch...\")\n    print(f\"✓ Hyperparameters:\")\n    for k, v in params.items():\n        print(f\"    {k:20s}: {v}\")\n    \n    # ========================================================================\n    # STEP 1: GET PREPROCESSED DATA\n    # ========================================================================\n    X_train = preprocessing_data['X_train_scaled']\n    X_test = preprocessing_data['X_test_scaled']\n    y_train = preprocessing_data['y_train']\n    y_test = preprocessing_data['y_test']\n    \n    # ========================================================================\n    # STEP 2: CONVERT TO JAX (do this EARLY)\n    # ========================================================================\n    X_train_jax = jnp.array(X_train, dtype=jnp.float32)\n    X_test_jax = jnp.array(X_test, dtype=jnp.float32)\n    y_train_jax = jnp.array(y_train, dtype=jnp.int32)\n    y_test_jax = jnp.array(y_test, dtype=jnp.int32)\n    \n    # ========================================================================\n    # STEP 3: GET SAMPLE WEIGHTS FROM PREPROCESSING\n    # ========================================================================\n    sample_weights_train = preprocessing_data.get('sample_weights_train', None)\n    bayes_availability_train = preprocessing_data.get('bayes_availability_train', None)\n    \n    print(f\"\\n✓ Sample weights loaded: {'Yes' if sample_weights_train is not None else 'No'}\")\n    if sample_weights_train is not None and bayes_availability_train is not None:\n        print(f\"  Real Bayesian avg weight: {np.mean(sample_weights_train[bayes_availability_train > 0]):.2f}x\")\n        print(f\"  Filled Bayesian avg weight: {np.mean(sample_weights_train[bayes_availability_train == 0]):.2f}x\")\n    \n    # ========================================================================\n    # STEP 4: COMPUTE CLASS WEIGHTS (do this EARLY)\n    # ========================================================================\n    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n    class_weights_jax = jnp.array(list(dict(enumerate(class_weights)).values()), dtype=jnp.float32)\n    \n    print(f\"\\n✓ Class weights (after track selections):\")\n    for i, w in enumerate(class_weights):\n        print(f\"    {PARTICLE_NAMES[i]:10s}: {w:.4f}\")\n    \n    # ========================================================================\n    # STEP 5: INITIALIZE MODEL (do this EARLY)\n    # ========================================================================\n    key = random.PRNGKey(SEED + hash(model_type) % 10000)\n    \n    if model_type == 'JAX_SimpleNN':\n        model = JAX_SimpleNN(\n            hidden_dims=params['hidden_dims'],\n            num_classes=NUM_CLASSES,\n            dropout_rate=params['dropout_rate']\n        )\n        num_features = int(X_train_jax.shape[1])\n        dummy_input = jnp.ones((1, num_features))\n        model_params = model.init(key, dummy_input, training=False)\n        \n        tx = optax.adam(params['learning_rate'])\n        state = train_state.TrainState.create(\n            apply_fn=model.apply,\n            params=model_params['params'],\n            tx=tx\n        )\n        \n        train_fn = train_step_simple\n        eval_fn = batch_evaluate_simple\n        \n    elif model_type == 'JAX_DNN':\n        model = JAX_DNN(\n            hidden_dims=params['hidden_dims'],\n            num_classes=NUM_CLASSES,\n            dropout_rate=params['dropout_rate']\n        )\n        num_features = int(X_train_jax.shape[1])\n        dummy_input = jnp.ones((1, num_features))\n        variables = model.init(key, dummy_input, training=True)\n        \n        model_params = variables['params']\n        batch_stats = variables.get('batch_stats', {})\n        \n        tx = optax.adam(params['learning_rate'])\n        state = TrainStateWithBatchStats.create(\n            apply_fn=model.apply,\n            params=model_params,\n            tx=tx,\n            batch_stats=batch_stats\n        )\n        \n        train_fn = train_step_batchnorm\n        eval_fn = batch_evaluate_batchnorm\n        \n    elif model_type == 'JAX_FSE_Attention':\n        model = JAX_FSE_Attention(\n            hidden_dim=params['hidden_dim'],\n            num_heads=params['num_heads'],\n            num_classes=NUM_CLASSES,\n            dropout_rate=params['dropout_rate']\n        )\n        \n        masks_train_jax = jnp.array(preprocessing_data['masks_train'], dtype=jnp.float32)\n        masks_test_jax = jnp.array(preprocessing_data['masks_test'], dtype=jnp.float32)\n        \n        num_features = int(X_train_jax.shape[1])\n        num_groups = int(masks_train_jax.shape[1])\n        dummy_input = jnp.ones((1, num_features))\n        dummy_mask = jnp.ones((1, num_groups))\n        model_params = model.init(key, dummy_input, dummy_mask, training=False)\n        \n        tx = optax.adam(params['learning_rate'])\n        state = train_state.TrainState.create(\n            apply_fn=model.apply,\n            params=model_params['params'],\n            tx=tx\n        )\n        \n        train_fn = train_step_fse\n        eval_fn = batch_evaluate_fse\n        \n    elif model_type == 'JAX_FSE_Attention_DetectorAware':\n        model = JAX_FSE_Attention_DetectorAware(\n            hidden_dim=params['hidden_dim'],\n            num_heads=params['num_heads'],\n            num_classes=NUM_CLASSES,\n            dropout_rate=params['dropout_rate'],\n            detector_embed_dim=8\n        )\n        \n        masks_train_jax = jnp.array(preprocessing_data['masks_train'], dtype=jnp.float32)\n        masks_test_jax = jnp.array(preprocessing_data['masks_test'], dtype=jnp.float32)\n        detector_modes_train_jax = jnp.array(preprocessing_data['detector_modes_train'], dtype=jnp.int32)\n        detector_modes_test_jax = jnp.array(preprocessing_data['detector_modes_test'], dtype=jnp.int32)\n        \n        num_features = int(X_train_jax.shape[1])\n        num_groups = int(masks_train_jax.shape[1])\n        dummy_input = jnp.ones((1, num_features))\n        dummy_mask = jnp.ones((1, num_groups))\n        dummy_modes = jnp.zeros((1,), dtype=jnp.int32)\n        model_params = model.init(key, dummy_input, dummy_mask, dummy_modes, training=False)\n        \n        tx = optax.adam(params['learning_rate'])\n        state = train_state.TrainState.create(\n            apply_fn=model.apply,\n            params=model_params['params'],\n            tx=tx\n        )\n        \n        train_fn = train_step_fse_aware\n        eval_fn = batch_evaluate_fse_aware\n    \n    print(f\"✓ Model initialised\")\n    \n    # ========================================================================\n    # STEP 6: MAIN TRAINING LOOP (SINGLE LOOP WITH WEIGHTED SAMPLING)\n    # ========================================================================\n    num_batches = len(X_train_jax) // params['batch_size']\n    best_val_acc = 0.0\n    patience_counter = 0\n    train_losses, val_accuracies = [], []\n    main_key = key\n    \n    print(f\"\\nTraining (max {params['num_epochs']} epochs, patience={params['patience']})...\\n\")\n    \n    for epoch in range(params['num_epochs']):\n        main_key, shuffle_key = random.split(main_key)\n\n        perm = random.permutation(shuffle_key, len(X_train_jax))\n        X_train_shuffled = X_train_jax[perm]\n        y_train_shuffled = y_train_jax[perm]\n        \n        if model_type in ['JAX_FSE_Attention', 'JAX_FSE_Attention_DetectorAware']:\n            masks_train_shuffled = masks_train_jax[perm]\n        \n        if model_type == 'JAX_FSE_Attention_DetectorAware':\n            detector_modes_train_shuffled = detector_modes_train_jax[perm]\n        \n        # ✓ Shuffle sample weights with same permutation\n        if sample_weights_train is not None:\n            sample_weights_shuffled = sample_weights_train[perm]\n        else:\n            sample_weights_shuffled = np.ones(len(X_train_jax), dtype='float32')\n        \n        epoch_losses = []\n        epoch_weights = []\n\n        dropout_key = main_key  # ← FRESH RNG key for this epoch's batches\n        \n        for batch_idx in range(num_batches):\n            dropout_key, subkey = random.split(dropout_key)\n            start_idx = batch_idx * params['batch_size']\n            end_idx = min(start_idx + params['batch_size'], len(X_train_jax))\n            batch_x = X_train_shuffled[start_idx:end_idx]\n            batch_y = y_train_shuffled[start_idx:end_idx]\n            \n            # ✓ Extract batch weights\n            batch_weights = sample_weights_shuffled[start_idx:end_idx]\n            batch_weights = batch_weights / np.mean(batch_weights)\n            \n            if model_type == 'JAX_FSE_Attention':\n                batch_mask = masks_train_shuffled[start_idx:end_idx]\n                state, loss = train_fn(state, batch_x, batch_mask, batch_y, subkey, class_weights_jax)\n            elif model_type == 'JAX_FSE_Attention_DetectorAware':\n                batch_mask = masks_train_shuffled[start_idx:end_idx]\n                batch_modes = detector_modes_train_shuffled[start_idx:end_idx]\n                state, loss = train_fn(state, batch_x, batch_mask, batch_modes, batch_y, subkey, class_weights_jax)\n            else:\n                state, loss = train_fn(state, batch_x, batch_y, subkey, class_weights_jax)\n            \n            # ✓ Apply sample weight scaling\n            weighted_loss = loss * np.mean(batch_weights)\n            epoch_losses.append(weighted_loss)\n            epoch_weights.append(np.mean(batch_weights))\n        \n        avg_train_loss = np.mean(epoch_losses)\n        avg_sample_weight = np.mean(epoch_weights)\n        \n        train_losses.append(avg_train_loss)\n        \n        # Validation\n        if model_type == 'JAX_FSE_Attention':\n            val_acc, _ = eval_fn(state, X_test_jax, masks_test_jax, y_test_jax, batch_size=1024)\n        elif model_type == 'JAX_FSE_Attention_DetectorAware':\n            val_acc, _ = eval_fn(state, X_test_jax, masks_test_jax, detector_modes_test_jax, y_test_jax, batch_size=1024)\n        else:\n            val_acc, _ = eval_fn(state, X_test_jax, y_test_jax, batch_size=1024)\n        \n        val_accuracies.append(float(val_acc))\n        \n        if (epoch + 1) % 10 == 0 or epoch == 0:\n            print(f\"Epoch {epoch+1:3d}/{params['num_epochs']} | Loss: {avg_train_loss:.4f} | Weight: {avg_sample_weight:.2f}x | Val Acc: {val_acc:.4f}\")\n        \n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            patience_counter = 0\n            best_params = state.params\n            if model_type == 'JAX_DNN':\n                best_batch_stats = state.batch_stats\n        else:\n            patience_counter += 1\n            if patience_counter >= params['patience']:\n                print(f\"✓ Early stopping at epoch {epoch+1}\")\n                break\n    \n    # Restore best parameters\n    state = state.replace(params=best_params)\n    if model_type == 'JAX_DNN':\n        state = state.replace(batch_stats=best_batch_stats)\n    \n    # ========================================================================\n    # STEP 7: FINAL EVALUATION\n    # ========================================================================\n    print(f\"\\nFinal evaluation...\")\n    if model_type == 'JAX_FSE_Attention':\n        train_acc, train_logits = eval_fn(state, X_train_jax, masks_train_jax, y_train_jax, batch_size=1024)\n        test_acc, test_logits = eval_fn(state, X_test_jax, masks_test_jax, y_test_jax, batch_size=1024)\n    elif model_type == 'JAX_FSE_Attention_DetectorAware':\n        train_acc, train_logits = eval_fn(state, X_train_jax, masks_train_jax, detector_modes_train_jax, y_train_jax, batch_size=1024)\n        test_acc, test_logits = eval_fn(state, X_test_jax, masks_test_jax, detector_modes_test_jax, y_test_jax, batch_size=1024)\n    else:\n        train_acc, train_logits = eval_fn(state, X_train_jax, y_train_jax, batch_size=1024)\n        test_acc, test_logits = eval_fn(state, X_test_jax, y_test_jax, batch_size=1024)\n    \n    train_probs = jax.nn.softmax(train_logits, axis=-1)\n    test_probs = jax.nn.softmax(test_logits, axis=-1)\n    y_pred_test = jnp.argmax(test_logits, axis=-1)\n    \n    print(f\"\\n✓ Results (on data with DPG track selections):\")\n    print(f\"    Train Acc:    {train_acc:.4f}\")\n    print(f\"    Test Acc:     {test_acc:.4f}\")\n    print(f\"    Best Val Acc: {best_val_acc:.4f}\")\n    \n    # Store results\n    results = {\n        'model_type': model_type,\n        'hyperparameters': params,\n        'train_losses': train_losses,\n        'val_accuracies': val_accuracies,\n        'best_val_acc': float(best_val_acc),\n        'train_acc': float(train_acc),\n        'test_acc': float(test_acc),\n        'train_probs': train_probs,\n        'test_probs': test_probs,\n        'y_pred_test': y_pred_test,\n        'y_test': y_test_jax,\n    }\n    \n    # Save model\n    save_single_model(mr_key, model_type, results)\n    \n    return results\n\nprint(\"✓ Unified training orchestrator defined\")\nprint(f\"\\n{'='*80}\")\nprint(\"✓ SECTION 3 COMPLETE\")\nprint(\"✓ All models trained on data with DPG track selections applied!\")\nprint(\"✓ Bayesian mask handling integrated (REAL vs TOKEN)\")\nprint(\"✓ Mask augmentation enabled for FSE models\")\nprint(f\"{'='*80}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:37:10.548512Z","iopub.execute_input":"2026-01-20T14:37:10.548860Z","iopub.status.idle":"2026-01-20T14:37:10.624669Z","shell.execute_reply.started":"2026-01-20T14:37:10.548837Z","shell.execute_reply":"2026-01-20T14:37:10.623951Z"}},"outputs":[{"name":"stdout","text":"\n################################################################################\nSECTION 3: MODEL DEFINITIONS & TRAINING\n################################################################################\n\n\n================================================================================\nFOCAL LOSS PARAMETERS (TUNED FOR PARTICLE PHYSICS)\n  alpha=0.5 (rare class weighting)\n  gamma=2.5 (hard example focusing)\n================================================================================\n\n\n################################################################################\nSECTION 3.7: UNIFIED TRAINING ORCHESTRATOR\n################################################################################\n\n✓ Unified training orchestrator defined\n\n================================================================================\n✓ SECTION 3 COMPLETE\n✓ All models trained on data with DPG track selections applied!\n✓ Bayesian mask handling integrated (REAL vs TOKEN)\n✓ Mask augmentation enabled for FSE models\n================================================================================\n\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## Section 4: Data Loading & Initialisation","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 4.0: DATA LOADING & INITIALISATION\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"SECTION 4.0: DATA LOADING & INITIALISATION\")\nprint(f\"{'#'*80}\\n\")\n\n# Load data once\ndf = load_data(CSV_PATH)\n\n# Initialise master results storage\nall_results_by_model_and_range = {}\n\nprint(\"✓ Data loaded\")\nprint(\"✓ Results storage initialised\")\nprint(f\"\\n{'='*80}\")\nprint(\"✓ SECTION 4.0 COMPLETE: Ready for training\")\nprint(f\"{'='*80}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:23.427971Z","iopub.execute_input":"2026-01-20T14:34:23.428489Z","iopub.status.idle":"2026-01-20T14:34:43.687030Z","shell.execute_reply.started":"2026-01-20T14:34:23.428471Z","shell.execute_reply":"2026-01-20T14:34:43.686324Z"}},"outputs":[{"name":"stdout","text":"\n################################################################################\nSECTION 4.0: DATA LOADING & INITIALISATION\n################################################################################\n\nLoading data from /kaggle/input/new-ao2d-lhc25f60544122/pid_features.csv...\n✓ Loaded: 4,162,072 rows × 37 columns\n\n✓ Data loaded\n✓ Results storage initialised\n\n================================================================================\n✓ SECTION 4.0 COMPLETE: Ready for training\n================================================================================\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## Section 4A: Train JAX_SimpleNN","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 4A: TRAIN JAX_SIMPLENN MODEL\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"SECTION 4A: TRAINING JAX_SIMPLENN\")\nprint(f\"{'#'*80}\\n\")\n\n# Train SimpleNN for all momentum ranges\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"MOMENTUM RANGE: {momentum_range['name']}\")\n    print(f\"{'='*80}\\n\")\n    \n    # Get or create preprocessing data\n    if mr_key not in all_results_by_model_and_range:\n        # First model for this range - preprocess data\n        preprocessing_data = preprocess_momentum_range(df, momentum_range)\n        all_results_by_model_and_range[mr_key] = {\n            'preprocessing': preprocessing_data,\n            'models': {}\n        }\n    else:\n        # Reuse existing preprocessing\n        preprocessing_data = all_results_by_model_and_range[mr_key]['preprocessing']\n    \n    # Train/load SimpleNN\n    force_training = FORCE_TRAINING['JAX_SimpleNN'][mr_key]\n    \n    results = train_model(\n        model_type='JAX_SimpleNN',\n        momentum_range=momentum_range,\n        preprocessing_data=preprocessing_data,\n        force_training=force_training,\n        mr_key=mr_key\n    )\n    \n    all_results_by_model_and_range[mr_key]['models']['JAX_SimpleNN'] = results\n\nprint(f\"\\n{'='*80}\")\nprint(\"✓ SECTION 4A COMPLETE: JAX_SimpleNN trained/loaded for all ranges\")\nprint(f\"{'='*80}\\n\")\n\n# Summary for SimpleNN\nprint(\"\\nJAX_SimpleNN Summary:\")\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    results = all_results_by_model_and_range[mr_key]['models']['JAX_SimpleNN']\n    print(f\"  {momentum_range['name']:30s}: Test Acc = {results['test_acc']:.4f}\")\n\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:43.687758Z","iopub.execute_input":"2026-01-20T14:34:43.687952Z","iopub.status.idle":"2026-01-20T14:34:46.623366Z","shell.execute_reply.started":"2026-01-20T14:34:43.687938Z","shell.execute_reply":"2026-01-20T14:34:46.622680Z"}},"outputs":[{"name":"stdout","text":"\n################################################################################\nSECTION 4A: TRAINING JAX_SIMPLENN\n################################################################################\n\n\n================================================================================\nMOMENTUM RANGE: Full Spectrum (0.1+ GeV/c)\n================================================================================\n\n================================================================================\nPreprocessing Full Spectrum (0.1+ GeV/c)\n================================================================================\n\nSTEP 1: After momentum filter: 4,162,072 tracks\nSTEP 2: Applying DPG-recommended track selections...\n  After eta cut (-0.8 to 0.8): 2,698,816 tracks\n  After DCA cuts: 895,535 tracks\n\nSTEP 3: Detector configuration overview (NO REMOVAL)...\n  Tracks with NONE (has_tpc=0 & has_tof=0): 167,539 (18.71% of sample)\n  Total tracks kept (including NONE): 895,535\n\nSTEP 4: Handling missing values...\nAfter PDG conversion and removing invalid species: 873,437 tracks\n\nSTEP 5: Stratified train/test split...\n\n────────────────────────────────────────────────────────────────────────────────\nCLASS DISTRIBUTION VERIFICATION (Stratified Split):\n────────────────────────────────────────────────────────────────────────────────\n\nParticle     Train Count     Train %      Test Count      Test %      \n--------------------------------------------------------------------------------\nPion         597,402         85.50       % 149,351         85.50       % PASS\nKaon         60,255          8.62        % 15,064          8.62        % PASS\nProton       27,659          3.96        % 6,915           3.96        % PASS\nElectron     13,433          1.92        % 3,358           1.92        % PASS\n\nTrain/Test class distributions match (stratified split successful)!\n\nSTEP 6: Calculating detector modes from UNSCALED data...\n  Keeping ALL detector modes (including NONE=0)\n\n  Detector mode distribution (Train):\n    NONE:     132,990 (19.0%)\n    TPC only: 397,245 (56.9%)\n    TOF only: 0 (0.0%)\n    BOTH:     168,514 (24.1%)\n\n  Detector mode distribution (Test):\n    NONE:     33,546 (19.2%)\n    TPC only: 99,505 (57.0%)\n    TOF only: 0 (0.0%)\n    BOTH:     41,637 (23.8%)\n\nSTEP 7: Standardising features...\n\nSTEP 8: Bayesian data handling with configurable fill token...\n  Using fill token: -0.25\n  Train - Real Bayesian: 168,514 (24.1%) | Filled: 530,235 (75.9%)\n  Test  - Real Bayesian: 41,637 (23.8%) | Filled: 133,051 (76.2%)\n  ✓ Missing values filled with token: -0.25\n\nSTEP 9: Computing sample weights for training...\n  Real Bayesian weight: 3.0x\n  Filled Bayesian weight: 1.0x (baseline)\n  Total effective sample size: 698,749 (was 698,749)\n  Weighted sum: 698749.0\n\n********************************************************************************\nJAX_SimpleNN - Full Spectrum (0.1+ GeV/c)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\n✓ Loaded from: /kaggle/working/trained_models/full_JAX_SimpleNN.pkl\n✓ Loaded existing model (skipped training)\n\n================================================================================\nMOMENTUM RANGE: 0.7-1.5 GeV/c (Critical)\n================================================================================\n\n================================================================================\nPreprocessing 0.7-1.5 GeV/c (Critical)\n================================================================================\n\nSTEP 1: After momentum filter: 801,712 tracks\nSTEP 2: Applying DPG-recommended track selections...\n  After eta cut (-0.8 to 0.8): 385,370 tracks\n  After DCA cuts: 240,733 tracks\n\nSTEP 3: Detector configuration overview (NO REMOVAL)...\n  Tracks with NONE (has_tpc=0 & has_tof=0): 38,088 (15.82% of sample)\n  Total tracks kept (including NONE): 240,733\n\nSTEP 4: Handling missing values...\nAfter PDG conversion and removing invalid species: 238,155 tracks\n\nSTEP 5: Stratified train/test split...\n\n────────────────────────────────────────────────────────────────────────────────\nCLASS DISTRIBUTION VERIFICATION (Stratified Split):\n────────────────────────────────────────────────────────────────────────────────\n\nParticle     Train Count     Train %      Test Count      Test %      \n--------------------------------------------------------------------------------\nPion         152,853         80.23       % 38,214          80.23       % PASS\nKaon         24,565          12.89       % 6,141           12.89       % PASS\nProton       12,197          6.40        % 3,049           6.40        % PASS\nElectron     909             0.48        % 227             0.48        % PASS\n\nTrain/Test class distributions match (stratified split successful)!\n\nSTEP 6: Calculating detector modes from UNSCALED data...\n  Keeping ALL detector modes (including NONE=0)\n\n  Detector mode distribution (Train):\n    NONE:     30,303 (15.9%)\n    TPC only: 80,722 (42.4%)\n    TOF only: 0 (0.0%)\n    BOTH:     79,499 (41.7%)\n\n  Detector mode distribution (Test):\n    NONE:     7,676 (16.1%)\n    TPC only: 20,019 (42.0%)\n    TOF only: 0 (0.0%)\n    BOTH:     19,936 (41.9%)\n\nSTEP 7: Standardising features...\n\nSTEP 8: Bayesian data handling with configurable fill token...\n  Using fill token: -0.25\n  Train - Real Bayesian: 79,499 (41.7%) | Filled: 111,025 (58.3%)\n  Test  - Real Bayesian: 19,936 (41.9%) | Filled: 27,695 (58.1%)\n  ✓ Missing values filled with token: -0.25\n\nSTEP 9: Computing sample weights for training...\n  Real Bayesian weight: 3.0x\n  Filled Bayesian weight: 1.0x (baseline)\n  Total effective sample size: 190,524 (was 190,524)\n  Weighted sum: 190524.0\n\n********************************************************************************\nJAX_SimpleNN - 0.7-1.5 GeV/c (Critical)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\n✓ Loaded from: /kaggle/working/trained_models/0.7-1.5_JAX_SimpleNN.pkl\n✓ Loaded existing model (skipped training)\n\n================================================================================\nMOMENTUM RANGE: 1-3 GeV/c (Intermediate)\n================================================================================\n\n================================================================================\nPreprocessing 1-3 GeV/c (Intermediate)\n================================================================================\n\nSTEP 1: After momentum filter: 595,771 tracks\nSTEP 2: Applying DPG-recommended track selections...\n  After eta cut (-0.8 to 0.8): 241,850 tracks\n  After DCA cuts: 169,418 tracks\n\nSTEP 3: Detector configuration overview (NO REMOVAL)...\n  Tracks with NONE (has_tpc=0 & has_tof=0): 26,402 (15.58% of sample)\n  Total tracks kept (including NONE): 169,418\n\nSTEP 4: Handling missing values...\nAfter PDG conversion and removing invalid species: 168,037 tracks\n\nSTEP 5: Stratified train/test split...\n\n────────────────────────────────────────────────────────────────────────────────\nCLASS DISTRIBUTION VERIFICATION (Stratified Split):\n────────────────────────────────────────────────────────────────────────────────\n\nParticle     Train Count     Train %      Test Count      Test %      \n--------------------------------------------------------------------------------\nPion         99,643          74.12       % 24,912          74.13       % PASS\nKaon         21,029          15.64       % 5,257           15.64       % PASS\nProton       13,267          9.87        % 3,317           9.87        % PASS\nElectron     490             0.36        % 122             0.36        % PASS\n\nTrain/Test class distributions match (stratified split successful)!\n\nSTEP 6: Calculating detector modes from UNSCALED data...\n  Keeping ALL detector modes (including NONE=0)\n\n  Detector mode distribution (Train):\n    NONE:     20,946 (15.6%)\n    TPC only: 54,353 (40.4%)\n    TOF only: 0 (0.0%)\n    BOTH:     59,130 (44.0%)\n\n  Detector mode distribution (Test):\n    NONE:     5,283 (15.7%)\n    TPC only: 13,586 (40.4%)\n    TOF only: 0 (0.0%)\n    BOTH:     14,739 (43.9%)\n\nSTEP 7: Standardising features...\n\nSTEP 8: Bayesian data handling with configurable fill token...\n  Using fill token: -0.25\n  Train - Real Bayesian: 59,130 (44.0%) | Filled: 75,299 (56.0%)\n  Test  - Real Bayesian: 14,739 (43.9%) | Filled: 18,869 (56.1%)\n  ✓ Missing values filled with token: -0.25\n\nSTEP 9: Computing sample weights for training...\n  Real Bayesian weight: 3.0x\n  Filled Bayesian weight: 1.0x (baseline)\n  Total effective sample size: 134,429 (was 134,429)\n  Weighted sum: 134429.0\n\n********************************************************************************\nJAX_SimpleNN - 1-3 GeV/c (Intermediate)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\n✓ Loaded from: /kaggle/working/trained_models/1-3_JAX_SimpleNN.pkl\n✓ Loaded existing model (skipped training)\n\n================================================================================\n✓ SECTION 4A COMPLETE: JAX_SimpleNN trained/loaded for all ranges\n================================================================================\n\n\nJAX_SimpleNN Summary:\n  Full Spectrum (0.1+ GeV/c)    : Test Acc = 0.6670\n  0.7-1.5 GeV/c (Critical)      : Test Acc = 0.5228\n  1-3 GeV/c (Intermediate)      : Test Acc = 0.6349\n\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## Section 4B: Train JAX_DNN","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 4B: TRAIN JAX_DNN MODEL\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"SECTION 4B: TRAINING JAX_DNN\")\nprint(f\"{'#'*80}\\n\")\n\n# Train DNN for all momentum ranges\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"MOMENTUM RANGE: {momentum_range['name']}\")\n    print(f\"{'='*80}\\n\")\n    \n    # Get or create preprocessing data\n    if mr_key not in all_results_by_model_and_range:\n        preprocessing_data = preprocess_momentum_range(df, momentum_range)\n        all_results_by_model_and_range[mr_key] = {\n            'preprocessing': preprocessing_data,\n            'models': {}\n        }\n    else:\n        preprocessing_data = all_results_by_model_and_range[mr_key]['preprocessing']\n    \n    # Train/load DNN\n    force_training = FORCE_TRAINING['JAX_DNN'][mr_key]\n    \n    results = train_model(\n        model_type='JAX_DNN',\n        momentum_range=momentum_range,\n        preprocessing_data=preprocessing_data,\n        force_training=force_training,\n        mr_key=mr_key\n    )\n    \n    all_results_by_model_and_range[mr_key]['models']['JAX_DNN'] = results\n\nprint(f\"\\n{'='*80}\")\nprint(\"✓ SECTION 4B COMPLETE: JAX_DNN trained/loaded for all ranges\")\nprint(f\"{'='*80}\\n\")\n\n# Summary for DNN\nprint(\"\\nJAX_DNN Summary:\")\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    results = all_results_by_model_and_range[mr_key]['models']['JAX_DNN']\n    print(f\"  {momentum_range['name']:30s}: Test Acc = {results['test_acc']:.4f}\")\n\nprint()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:46.624129Z","iopub.execute_input":"2026-01-20T14:34:46.624473Z","iopub.status.idle":"2026-01-20T14:34:46.642186Z","shell.execute_reply.started":"2026-01-20T14:34:46.624451Z","shell.execute_reply":"2026-01-20T14:34:46.641482Z"}},"outputs":[{"name":"stdout","text":"\n################################################################################\nSECTION 4B: TRAINING JAX_DNN\n################################################################################\n\n\n================================================================================\nMOMENTUM RANGE: Full Spectrum (0.1+ GeV/c)\n================================================================================\n\n\n********************************************************************************\nJAX_DNN - Full Spectrum (0.1+ GeV/c)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\n✓ Loaded from: /kaggle/working/trained_models/full_JAX_DNN.pkl\n✓ Loaded existing model (skipped training)\n\n================================================================================\nMOMENTUM RANGE: 0.7-1.5 GeV/c (Critical)\n================================================================================\n\n\n********************************************************************************\nJAX_DNN - 0.7-1.5 GeV/c (Critical)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\n✓ Loaded from: /kaggle/working/trained_models/0.7-1.5_JAX_DNN.pkl\n✓ Loaded existing model (skipped training)\n\n================================================================================\nMOMENTUM RANGE: 1-3 GeV/c (Intermediate)\n================================================================================\n\n\n********************************************************************************\nJAX_DNN - 1-3 GeV/c (Intermediate)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\n✓ Loaded from: /kaggle/working/trained_models/1-3_JAX_DNN.pkl\n✓ Loaded existing model (skipped training)\n\n================================================================================\n✓ SECTION 4B COMPLETE: JAX_DNN trained/loaded for all ranges\n================================================================================\n\n\nJAX_DNN Summary:\n  Full Spectrum (0.1+ GeV/c)    : Test Acc = 0.6524\n  0.7-1.5 GeV/c (Critical)      : Test Acc = 0.6456\n  1-3 GeV/c (Intermediate)      : Test Acc = 0.7046\n\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"## Section 4C: Train JAX_FSE_Attention","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 4C: TRAIN JAX_FSE_ATTENTION (STANDARD BASELINE)\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"SECTION 4C: TRAINING JAX_FSE_ATTENTION (STANDARD BASELINE)\")\nprint(f\"{'#'*80}\\n\")\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"MOMENTUM RANGE: {momentum_range['name']}\")\n    print(f\"{'='*80}\\n\")\n    \n    # Get or create preprocessing data\n    if mr_key not in all_results_by_model_and_range:\n        preprocessing_data = preprocess_momentum_range(df, momentum_range)\n        all_results_by_model_and_range[mr_key] = {\n            'preprocessing': preprocessing_data,\n            'models': {}\n        }\n    else:\n        preprocessing_data = all_results_by_model_and_range[mr_key]['preprocessing']\n    \n    # Train/load FSE+Attention\n    force_training = FORCE_TRAINING['JAX_FSE_Attention'][mr_key]\n    \n    results = train_model(\n        model_type='JAX_FSE_Attention',\n        momentum_range=momentum_range,\n        preprocessing_data=preprocessing_data,\n        force_training=force_training,\n        mr_key=mr_key\n    )\n    \n    all_results_by_model_and_range[mr_key]['models']['JAX_FSE_Attention'] = results\n\nprint(f\"\\n{'='*80}\")\nprint(\"✓ SECTION 4C COMPLETE: JAX_FSE_Attention trained/loaded for all ranges\")\nprint(f\"{'='*80}\\n\")\n\n# Summary for FSE+Attention\nprint(\"\\nJAX_FSE_Attention Summary (Standard FSE baseline):\")\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    results = all_results_by_model_and_range[mr_key]['models']['JAX_FSE_Attention']\n    print(f\"  {momentum_range['name']:30s}: Test Acc = {results['test_acc']:.4f}\")\n\nprint()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:46.643972Z","iopub.execute_input":"2026-01-20T14:34:46.644225Z","iopub.status.idle":"2026-01-20T14:34:46.668252Z","shell.execute_reply.started":"2026-01-20T14:34:46.644207Z","shell.execute_reply":"2026-01-20T14:34:46.667518Z"}},"outputs":[{"name":"stdout","text":"\n################################################################################\nSECTION 4C: TRAINING JAX_FSE_ATTENTION (STANDARD BASELINE)\n################################################################################\n\n\n================================================================================\nMOMENTUM RANGE: Full Spectrum (0.1+ GeV/c)\n================================================================================\n\n\n********************************************************************************\nJAX_FSE_Attention - Full Spectrum (0.1+ GeV/c)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\n✓ Loaded from: /kaggle/working/trained_models/full_JAX_FSE_Attention.pkl\n✓ Loaded existing model (skipped training)\n\n================================================================================\nMOMENTUM RANGE: 0.7-1.5 GeV/c (Critical)\n================================================================================\n\n\n********************************************************************************\nJAX_FSE_Attention - 0.7-1.5 GeV/c (Critical)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\n✓ Loaded from: /kaggle/working/trained_models/0.7-1.5_JAX_FSE_Attention.pkl\n✓ Loaded existing model (skipped training)\n\n================================================================================\nMOMENTUM RANGE: 1-3 GeV/c (Intermediate)\n================================================================================\n\n\n********************************************************************************\nJAX_FSE_Attention - 1-3 GeV/c (Intermediate)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\n✓ Loaded from: /kaggle/working/trained_models/1-3_JAX_FSE_Attention.pkl\n✓ Loaded existing model (skipped training)\n\n================================================================================\n✓ SECTION 4C COMPLETE: JAX_FSE_Attention trained/loaded for all ranges\n================================================================================\n\n\nJAX_FSE_Attention Summary (Standard FSE baseline):\n  Full Spectrum (0.1+ GeV/c)    : Test Acc = 0.6787\n  0.7-1.5 GeV/c (Critical)      : Test Acc = 0.6948\n  1-3 GeV/c (Intermediate)      : Test Acc = 0.5154\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## Section 4D: Train JAX_FSE_Attention_DetectorAware","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 4D: TRAIN JAX_FSE_ATTENTION_DETECTORAWARE (PHASE 1)\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"SECTION 4D: TRAINING JAX_FSE_ATTENTION_DETECTORAWARE (PHASE 1)\")\nprint(f\"{'#'*80}\\n\")\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"MOMENTUM RANGE: {momentum_range['name']} (Detector-Aware FSE)\")\n    print(f\"{'='*80}\\n\")\n    \n    # Get preprocessing data (already created in Section 4A)\n    preprocessing_data = all_results_by_model_and_range[mr_key]['preprocessing']\n    \n    # Train/load Detector-Aware FSE\n    force_training = FORCE_TRAINING['JAX_FSE_Attention_DetectorAware'][mr_key]\n    \n    results = train_model(\n        model_type='JAX_FSE_Attention_DetectorAware',\n        momentum_range=momentum_range,\n        preprocessing_data=preprocessing_data,\n        force_training=force_training,\n        mr_key=mr_key\n    )\n    \n    all_results_by_model_and_range[mr_key]['models']['JAX_FSE_Attention_DetectorAware'] = results\n\nprint(f\"\\n{'='*80}\")\nprint(\"✓ SECTION 4D COMPLETE: JAX_FSE_Attention_DetectorAware trained/loaded for all ranges\")\nprint(f\"{'='*80}\\n\")\n\n# Summary for Detector-Aware FSE\nprint(\"\\nJAX_FSE_Attention_DetectorAware Summary (Phase 1 detector-aware):\")\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    results = all_results_by_model_and_range[mr_key]['models']['JAX_FSE_Attention_DetectorAware']\n    print(f\"  {momentum_range['name']:30s}: Test Acc = {results['test_acc']:.4f}\")\n\nprint()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:37:32.068422Z","iopub.execute_input":"2026-01-20T14:37:32.068701Z","iopub.status.idle":"2026-01-20T14:58:58.621451Z","shell.execute_reply.started":"2026-01-20T14:37:32.068682Z","shell.execute_reply":"2026-01-20T14:58:58.620831Z"}},"outputs":[{"name":"stdout","text":"\n################################################################################\nSECTION 4D: TRAINING JAX_FSE_ATTENTION_DETECTORAWARE (PHASE 1)\n################################################################################\n\n\n================================================================================\nMOMENTUM RANGE: Full Spectrum (0.1+ GeV/c) (Detector-Aware FSE)\n================================================================================\n\n\n********************************************************************************\nJAX_FSE_Attention_DetectorAware - Full Spectrum (0.1+ GeV/c)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\nTraining from scratch...\n✓ Hyperparameters:\n    hidden_dim          : 64\n    num_heads           : 4\n    dropout_rate        : 0.5\n    learning_rate       : 0.0001\n    batch_size          : 256\n    num_epochs          : 100\n    patience            : 30\n    detector_embed_dim  : 8\n\n✓ Sample weights loaded: Yes\n  Real Bayesian avg weight: 2.02x\n  Filled Bayesian avg weight: 0.67x\n\n✓ Class weights (after track selections):\n    Pion      : 0.2924\n    Kaon      : 2.8991\n    Proton    : 6.3157\n    Electron  : 13.0043\n✓ Model initialised\n\nTraining (max 100 epochs, patience=30)...\n\nEpoch   1/100 | Loss: 0.2587 | Weight: 1.00x | Val Acc: 0.4421\nEpoch  10/100 | Loss: 0.1586 | Weight: 1.00x | Val Acc: 0.4673\nEpoch  20/100 | Loss: 0.1514 | Weight: 1.00x | Val Acc: 0.5298\nEpoch  30/100 | Loss: 0.1095 | Weight: 1.00x | Val Acc: 0.5202\nEpoch  40/100 | Loss: 0.1031 | Weight: 1.00x | Val Acc: 0.6438\nEpoch  50/100 | Loss: 0.0999 | Weight: 1.00x | Val Acc: 0.6518\nEpoch  60/100 | Loss: 0.0974 | Weight: 1.00x | Val Acc: 0.6529\nEpoch  70/100 | Loss: 0.0959 | Weight: 1.00x | Val Acc: 0.6295\nEpoch  80/100 | Loss: 0.0944 | Weight: 1.00x | Val Acc: 0.6443\nEpoch  90/100 | Loss: 0.0938 | Weight: 1.00x | Val Acc: 0.6460\nEpoch 100/100 | Loss: 0.0920 | Weight: 1.00x | Val Acc: 0.6181\n\nFinal evaluation...\n\n✓ Results (on data with DPG track selections):\n    Train Acc:    0.6845\n    Test Acc:     0.6835\n    Best Val Acc: 0.6835\n✓ Saved to: /kaggle/working/trained_models/full_JAX_FSE_Attention_DetectorAware.pkl\n\n================================================================================\nMOMENTUM RANGE: 0.7-1.5 GeV/c (Critical) (Detector-Aware FSE)\n================================================================================\n\n\n********************************************************************************\nJAX_FSE_Attention_DetectorAware - 0.7-1.5 GeV/c (Critical)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\nTraining from scratch...\n✓ Hyperparameters:\n    hidden_dim          : 64\n    num_heads           : 4\n    dropout_rate        : 0.5\n    learning_rate       : 0.0001\n    batch_size          : 256\n    num_epochs          : 100\n    patience            : 30\n    detector_embed_dim  : 8\n\n✓ Sample weights loaded: Yes\n  Real Bayesian avg weight: 1.64x\n  Filled Bayesian avg weight: 0.55x\n\n✓ Class weights (after track selections):\n    Pion      : 0.3116\n    Kaon      : 1.9390\n    Proton    : 3.9051\n    Electron  : 52.3993\n✓ Model initialised\n\nTraining (max 100 epochs, patience=30)...\n\nEpoch   1/100 | Loss: 0.3884 | Weight: 1.00x | Val Acc: 0.5285\nEpoch  10/100 | Loss: 0.2027 | Weight: 1.00x | Val Acc: 0.4490\nEpoch  20/100 | Loss: 0.1434 | Weight: 1.00x | Val Acc: 0.6214\nEpoch  30/100 | Loss: 0.1266 | Weight: 1.00x | Val Acc: 0.6664\nEpoch  40/100 | Loss: 0.1184 | Weight: 1.00x | Val Acc: 0.6266\nEpoch  50/100 | Loss: 0.1115 | Weight: 1.00x | Val Acc: 0.6524\nEpoch  60/100 | Loss: 0.1098 | Weight: 1.00x | Val Acc: 0.6755\nEpoch  70/100 | Loss: 0.1073 | Weight: 1.00x | Val Acc: 0.6723\n✓ Early stopping at epoch 74\n\nFinal evaluation...\n\n✓ Results (on data with DPG track selections):\n    Train Acc:    0.6900\n    Test Acc:     0.6858\n    Best Val Acc: 0.6858\n✓ Saved to: /kaggle/working/trained_models/0.7-1.5_JAX_FSE_Attention_DetectorAware.pkl\n\n================================================================================\nMOMENTUM RANGE: 1-3 GeV/c (Intermediate) (Detector-Aware FSE)\n================================================================================\n\n\n********************************************************************************\nJAX_FSE_Attention_DetectorAware - 1-3 GeV/c (Intermediate)\n********************************************************************************\n✓ DPG Track Selections Applied (Section 2):\n  • η ∈ [-0.8, 0.8]\n  • DCA_xy < 0.105, DCA_z < 0.12\n  • TPC clusters > 70\n  • Bayesian mask fixed (token = -0.25)\n********************************************************************************\n\nTraining from scratch...\n✓ Hyperparameters:\n    hidden_dim          : 64\n    num_heads           : 4\n    dropout_rate        : 0.5\n    learning_rate       : 0.0001\n    batch_size          : 256\n    num_epochs          : 100\n    patience            : 30\n    detector_embed_dim  : 8\n\n✓ Sample weights loaded: Yes\n  Real Bayesian avg weight: 1.60x\n  Filled Bayesian avg weight: 0.53x\n\n✓ Class weights (after track selections):\n    Pion      : 0.3373\n    Kaon      : 1.5981\n    Proton    : 2.5331\n    Electron  : 68.5862\n✓ Model initialised\n\nTraining (max 100 epochs, patience=30)...\n\nEpoch   1/100 | Loss: 0.4127 | Weight: 1.00x | Val Acc: 0.4819\nEpoch  10/100 | Loss: 0.2047 | Weight: 1.00x | Val Acc: 0.4072\nEpoch  20/100 | Loss: 0.1879 | Weight: 1.00x | Val Acc: 0.4703\nEpoch  30/100 | Loss: 0.1829 | Weight: 1.00x | Val Acc: 0.5364\nEpoch  40/100 | Loss: 0.1774 | Weight: 1.00x | Val Acc: 0.5835\nEpoch  50/100 | Loss: 0.1749 | Weight: 1.00x | Val Acc: 0.5708\nEpoch  60/100 | Loss: 0.1753 | Weight: 1.00x | Val Acc: 0.5140\n✓ Early stopping at epoch 62\n\nFinal evaluation...\n\n✓ Results (on data with DPG track selections):\n    Train Acc:    0.6189\n    Test Acc:     0.6216\n    Best Val Acc: 0.6216\n✓ Saved to: /kaggle/working/trained_models/1-3_JAX_FSE_Attention_DetectorAware.pkl\n\n================================================================================\n✓ SECTION 4D COMPLETE: JAX_FSE_Attention_DetectorAware trained/loaded for all ranges\n================================================================================\n\n\nJAX_FSE_Attention_DetectorAware Summary (Phase 1 detector-aware):\n  Full Spectrum (0.1+ GeV/c)    : Test Acc = 0.6835\n  0.7-1.5 GeV/c (Critical)      : Test Acc = 0.6858\n  1-3 GeV/c (Intermediate)      : Test Acc = 0.6216\n\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## Section 4E: Train Random Forest","metadata":{}},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"SECTION 4E: TRAINING SKLEARN RANDOM FOREST MODELS\")\nprint(\"=\"*80)\nprint()\n\n# Use hyperparameters from SECTION 0\nRF_HYPERPARAMETERS = HYPERPARAMETERS['SkLearn_RandomForest']\n\nprint(f\"Random Forest Configuration:\")\nprint(f\"  n_estimators: {RF_HYPERPARAMETERS['n_estimators']}\")\nprint(f\"  max_depth: {RF_HYPERPARAMETERS['max_depth']}\")\nprint(f\"  class_weight: {RF_HYPERPARAMETERS['class_weight']}\")\nprint(f\"  Features: {len(TRAINING_FEATURES)}\")\nprint(f\"  Classes: {NUM_CLASSES}\")\nprint()\n\nprint(\"=\"*80)\nprint(\"SECTION 4E.1: TRAINING RANDOM FOREST FOR ALL MOMENTUM RANGES\")\nprint(\"=\"*80)\nprint()\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    print(\"=\"*80)\n    print(f\"MOMENTUM RANGE: {momentum_range['name']}\")\n    print(\"=\"*80)\n    \n    if mr_key not in all_results_by_model_and_range or 'preprocessing' not in all_results_by_model_and_range[mr_key]:\n        print(f\"ERROR: No preprocessing data for {mr_key}. Train neural networks first.\")\n        continue\n    \n    preprocessing_data = all_results_by_model_and_range[mr_key]['preprocessing']\n    \n    X_train = preprocessing_data['X_train_scaled']\n    X_test = preprocessing_data['X_test_scaled']\n    y_train = preprocessing_data['y_train']\n    y_test = preprocessing_data['y_test']\n    \n    print(f\"Dataset shapes:\")\n    print(f\"  Train: {X_train.shape[0]:,} tracks, Test: {X_test.shape[0]:,} tracks\")\n    print(f\"  Features: {X_train.shape[1]}\")\n    print()\n    \n    # Check if model should be loaded from cache\n    try:\n        loaded_data = load_single_model(mr_key, 'SkLearn_RandomForest')\n        model_loaded = loaded_data is not None\n    except:\n        model_loaded = False\n    \n    if model_loaded and not FORCE_TRAINING['SkLearn_RandomForest'][mr_key]:\n        print(f\"✓ Loaded cached Random Forest model\")\n        # Unpack: load_single_model returns (model_object, filepath_string)\n        rf_model, _ = loaded_data\n        training_time = 0\n        print()\n    else:\n        print(f\"Training Random Forest ({RF_HYPERPARAMETERS['n_estimators']} trees)...\")\n        rf_start_time = time.time()\n        \n        rf_model = RandomForestClassifier(**RF_HYPERPARAMETERS)\n        rf_model.fit(X_train, y_train)\n        \n        training_time = time.time() - rf_start_time\n        print(f\"Training completed in {training_time:.2f} seconds\")\n        print(f\"Out-of-bag (OOB) score: {rf_model.oob_score_:.4f}\")\n        print()\n    \n    # Evaluate model\n    y_train_pred = rf_model.predict(X_train)\n    train_acc = accuracy_score(y_train, y_train_pred)\n    \n    y_test_pred = rf_model.predict(X_test)\n    test_acc = accuracy_score(y_test, y_test_pred)\n    \n    y_test_probs = rf_model.predict_proba(X_test)\n    \n    # Calculate macro AUC\n    y_test_bin = label_binarize(y_test, classes=np.arange(NUM_CLASSES))\n    macro_auc_list = []\n    for i in range(NUM_CLASSES):\n        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_test_probs[:, i])\n        auc_score = auc(fpr, tpr)\n        macro_auc_list.append(auc_score)\n    macro_auc = np.mean(macro_auc_list)\n    \n    print(f\"Results:\")\n    print(f\"  Train Accuracy: {train_acc:.4f}\")\n    print(f\"  Test Accuracy:  {test_acc:.4f}\")\n    print(f\"  Macro AUC:      {macro_auc:.4f}\")\n    print(f\"  OOB Score:      {rf_model.oob_score_:.4f}\")\n    print()\n    \n    # Prepare results dictionary (without model object for memory efficiency)\n    results = {\n        'train_acc': float(train_acc),\n        'test_acc': float(test_acc),\n        'best_val_acc': float(test_acc),\n        'hyperparameters': RF_HYPERPARAMETERS,\n        'y_pred_test': y_test_pred,\n        'test_probs': y_test_probs,\n        'y_test': y_test,\n        'macro_auc': float(macro_auc),\n        'training_time': training_time,\n        'feature_importances': rf_model.feature_importances_,\n    }\n    \n    # Save model to disk\n    save_single_model(mr_key, 'SkLearn_RandomForest', rf_model)\n    \n    # Store in main dictionary without the model object (too large for memory)\n    if mr_key not in all_results_by_model_and_range:\n        all_results_by_model_and_range[mr_key] = {}\n    \n    all_results_by_model_and_range[mr_key]['models'] = all_results_by_model_and_range[mr_key].get('models', {})\n    all_results_by_model_and_range[mr_key]['models']['SkLearn_RandomForest'] = results\n\nprint(\"=\"*80)\nprint(\"SECTION 4E.1 COMPLETE: Random Forest trained/loaded for all momentum ranges\")\nprint(\"=\"*80)\nprint()\n\nprint(\"=\"*80)\nprint(\"SECTION 4E.2: RANDOM FOREST SUMMARY - ALL MOMENTUM RANGES\")\nprint(\"=\"*80)\nprint()\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    if mr_key not in all_results_by_model_and_range or 'models' not in all_results_by_model_and_range[mr_key]:\n        continue\n    \n    if 'SkLearn_RandomForest' not in all_results_by_model_and_range[mr_key]['models']:\n        continue\n    \n    results = all_results_by_model_and_range[mr_key]['models']['SkLearn_RandomForest']\n    print(f\"{momentum_range['name']:35s} | Train: {results['train_acc']:.4f} | Test: {results['test_acc']:.4f} | AUC: {results['macro_auc']:.4f} | Time: {results['training_time']:.2f}s\")\n\nprint()\n\nprint(\"=\"*80)\nprint(\"SECTION 4E.3: RANDOM FOREST FEATURE IMPORTANCE ANALYSIS\")\nprint(\"=\"*80)\nprint()\n\nfig, axes = plt.subplots(1, 3, figsize=(20, 6))\n\nfor idx, (mr_key, momentum_range) in enumerate(MOMENTUM_RANGES.items()):\n    if mr_key not in all_results_by_model_and_range or 'models' not in all_results_by_model_and_range[mr_key]:\n        continue\n    \n    if 'SkLearn_RandomForest' not in all_results_by_model_and_range[mr_key]['models']:\n        continue\n    \n    ax = axes[idx]\n    results = all_results_by_model_and_range[mr_key]['models']['SkLearn_RandomForest']\n    importances = results['feature_importances']\n    \n    sorted_idx = np.argsort(importances)[-15:]\n    sorted_importances = importances[sorted_idx]\n    sorted_names = [TRAINING_FEATURES[i] for i in sorted_idx]\n    \n    ax.barh(range(len(sorted_importances)), sorted_importances, color='#8B5CF6', alpha=0.8, edgecolor='black', linewidth=1.5)\n    ax.set_yticks(range(len(sorted_importances)))\n    ax.set_yticklabels(sorted_names, fontsize=10)\n    ax.set_xlabel('Importance', fontsize=11, fontweight='bold')\n    ax.set_title(f\"Random Forest - {momentum_range['name']}\", fontsize=12, fontweight='bold')\n    ax.grid(axis='x', alpha=0.3)\n\nplt.suptitle('Random Forest Feature Importance (Top 15 Features per Momentum Range)', fontsize=14, fontweight='bold', y=1.00)\nplt.tight_layout()\nplt.show()\n\nprint(\"Feature importance plot generated\")\nprint()\n\nprint(\"=\"*80)\nprint(\"SECTION 4E COMPLETE: Random Forest training finished\")\nprint(\"=\"*80)\nprint()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:46.893261Z","iopub.status.idle":"2026-01-20T14:34:46.893471Z","shell.execute_reply.started":"2026-01-20T14:34:46.893369Z","shell.execute_reply":"2026-01-20T14:34:46.893378Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 4E: Train XGBoost","metadata":{}},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"SECTION 4F: TRAINING XGBOOST MODELS\")\nprint(\"=\"*80)\nprint()\n\n# Use hyperparameters from SECTION 0\nXGB_HYPERPARAMETERS = HYPERPARAMETERS['XGBoost']\n\nprint(f\"XGBoost Configuration:\")\nprint(f\"  n_estimators: {XGB_HYPERPARAMETERS['n_estimators']}\")\nprint(f\"  max_depth: {XGB_HYPERPARAMETERS['max_depth']}\")\nprint(f\"  learning_rate: {XGB_HYPERPARAMETERS['learning_rate']}\")\nprint(f\"  subsample: {XGB_HYPERPARAMETERS['subsample']}\")\nprint(f\"  Features: {len(TRAINING_FEATURES)}\")\nprint(f\"  Classes: {NUM_CLASSES}\")\nprint()\n\nprint(\"=\"*80)\nprint(\"SECTION 4F.1: TRAINING XGBOOST FOR ALL MOMENTUM RANGES\")\nprint(\"=\"*80)\nprint()\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    print(\"=\"*80)\n    print(f\"MOMENTUM RANGE: {momentum_range['name']}\")\n    print(\"=\"*80)\n    \n    if mr_key not in all_results_by_model_and_range or 'preprocessing' not in all_results_by_model_and_range[mr_key]:\n        print(f\"ERROR: No preprocessing data for {mr_key}. Train neural networks first.\")\n        continue\n    \n    preprocessing_data = all_results_by_model_and_range[mr_key]['preprocessing']\n    \n    X_train = preprocessing_data['X_train_scaled']\n    X_test = preprocessing_data['X_test_scaled']\n    y_train = preprocessing_data['y_train']\n    y_test = preprocessing_data['y_test']\n    \n    print(f\"Dataset shapes:\")\n    print(f\"  Train: {X_train.shape[0]:,} tracks, Test: {X_test.shape[0]:,} tracks\")\n    print(f\"  Features: {X_train.shape[1]}\")\n    print()\n    \n    # Try to load cached model (FIXED: properly handle tuple return)\n    loaded_data = load_single_model(mr_key, 'XGBoost')\n    \n    if loaded_data is not None and not FORCE_TRAINING['XGBoost'][mr_key]:\n        print(f\"✓ Loaded cached XGBoost model\")\n        # load_single_model returns (model_object, filepath_string) tuple\n        xgb_model, _ = loaded_data\n        training_time = 0\n        print()\n    else:\n        print(f\"Training new XGBoost ({XGB_HYPERPARAMETERS['n_estimators']} trees)...\")\n        xgb_start_time = time.time()\n        \n        # Create XGBoost classifier\n        xgb_model = xgb.XGBClassifier(\n            n_estimators=XGB_HYPERPARAMETERS['n_estimators'],\n            max_depth=XGB_HYPERPARAMETERS['max_depth'],\n            learning_rate=XGB_HYPERPARAMETERS['learning_rate'],\n            subsample=XGB_HYPERPARAMETERS['subsample'],\n            colsample_bytree=XGB_HYPERPARAMETERS['colsample_bytree'],\n            min_child_weight=XGB_HYPERPARAMETERS['min_child_weight'],\n            gamma=XGB_HYPERPARAMETERS['gamma'],\n            objective=XGB_HYPERPARAMETERS['objective'],\n            num_class=XGB_HYPERPARAMETERS['num_class'],\n            random_state=XGB_HYPERPARAMETERS['random_state'],\n            n_jobs=XGB_HYPERPARAMETERS['n_jobs'],\n            eval_metric=XGB_HYPERPARAMETERS['eval_metric'],\n            tree_method=XGB_HYPERPARAMETERS['tree_method'],\n            device=XGB_HYPERPARAMETERS['device'],\n            verbosity=0\n        )\n        \n        xgb_model.fit(X_train, y_train)\n        \n        training_time = time.time() - xgb_start_time\n        print(f\"Training completed in {training_time:.2f} seconds\")\n        print()\n    \n    # Evaluate model\n    y_train_pred = xgb_model.predict(X_train)\n    train_acc = accuracy_score(y_train, y_train_pred)\n    \n    y_test_pred = xgb_model.predict(X_test)\n    test_acc = accuracy_score(y_test, y_test_pred)\n    \n    y_test_probs = xgb_model.predict_proba(X_test)\n    \n    # Calculate macro AUC\n    y_test_bin = label_binarize(y_test, classes=np.arange(NUM_CLASSES))\n    macro_auc_list = []\n    for i in range(NUM_CLASSES):\n        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_test_probs[:, i])\n        auc_score = auc(fpr, tpr)\n        macro_auc_list.append(auc_score)\n    macro_auc = np.mean(macro_auc_list)\n    \n    print(f\"Results:\")\n    print(f\"  Train Accuracy: {train_acc:.4f}\")\n    print(f\"  Test Accuracy:  {test_acc:.4f}\")\n    print(f\"  Macro AUC:      {macro_auc:.4f}\")\n    print()\n    \n    # Prepare results dictionary (without model object for memory efficiency)\n    results = {\n        'train_acc': float(train_acc),\n        'test_acc': float(test_acc),\n        'best_val_acc': float(test_acc),\n        'hyperparameters': XGB_HYPERPARAMETERS,\n        'y_pred_test': y_test_pred,\n        'test_probs': y_test_probs,\n        'y_test': y_test,\n        'macro_auc': float(macro_auc),\n        'training_time': training_time,\n        'feature_importances': xgb_model.feature_importances_,\n    }\n    \n    # Save model to disk\n    save_single_model(mr_key, 'XGBoost', xgb_model)\n    \n    # Store in main dictionary without the model object (too large for memory)\n    if mr_key not in all_results_by_model_and_range:\n        all_results_by_model_and_range[mr_key] = {}\n    \n    all_results_by_model_and_range[mr_key]['models'] = all_results_by_model_and_range[mr_key].get('models', {})\n    all_results_by_model_and_range[mr_key]['models']['XGBoost'] = results\n\nprint(\"=\"*80)\nprint(\"SECTION 4F.1 COMPLETE: XGBoost trained/loaded for all momentum ranges\")\nprint(\"=\"*80)\nprint()\n\nprint(\"=\"*80)\nprint(\"SECTION 4F.2: XGBOOST SUMMARY - ALL MOMENTUM RANGES\")\nprint(\"=\"*80)\nprint()\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    if mr_key not in all_results_by_model_and_range or 'models' not in all_results_by_model_and_range[mr_key]:\n        continue\n    \n    if 'XGBoost' not in all_results_by_model_and_range[mr_key]['models']:\n        continue\n    \n    results = all_results_by_model_and_range[mr_key]['models']['XGBoost']\n    print(f\"{momentum_range['name']:35s} | Train: {results['train_acc']:.4f} | Test: {results['test_acc']:.4f} | AUC: {results['macro_auc']:.4f} | Time: {results['training_time']:.2f}s\")\n\nprint()\n\nprint(\"=\"*80)\nprint(\"SECTION 4F.3: XGBOOST FEATURE IMPORTANCE ANALYSIS\")\nprint(\"=\"*80)\nprint()\n\nfig, axes = plt.subplots(1, 3, figsize=(20, 6))\n\nfor idx, (mr_key, momentum_range) in enumerate(MOMENTUM_RANGES.items()):\n    if mr_key not in all_results_by_model_and_range or 'models' not in all_results_by_model_and_range[mr_key]:\n        continue\n    \n    if 'XGBoost' not in all_results_by_model_and_range[mr_key]['models']:\n        continue\n    \n    ax = axes[idx]\n    results = all_results_by_model_and_range[mr_key]['models']['XGBoost']\n    importances = results['feature_importances']\n    \n    sorted_idx = np.argsort(importances)[-15:]\n    sorted_importances = importances[sorted_idx]\n    sorted_names = [TRAINING_FEATURES[i] for i in sorted_idx]\n    \n    ax.barh(range(len(sorted_importances)), sorted_importances, color='#EC4899', alpha=0.8, edgecolor='black', linewidth=1.5)\n    ax.set_yticks(range(len(sorted_importances)))\n    ax.set_yticklabels(sorted_names, fontsize=10)\n    ax.set_xlabel('Importance', fontsize=11, fontweight='bold')\n    ax.set_title(f\"XGBoost - {momentum_range['name']}\", fontsize=12, fontweight='bold')\n    ax.grid(axis='x', alpha=0.3)\n\nplt.suptitle('XGBoost Feature Importance (Top 15 Features per Momentum Range)', fontsize=14, fontweight='bold', y=1.00)\nplt.tight_layout()\nplt.show()\n\nprint(\"Feature importance plot generated\")\nprint()\n\nprint(\"=\"*80)\nprint(\"SECTION 4F COMPLETE: XGBoost training finished\")\nprint(\"=\"*80)\nprint()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:46.894928Z","iopub.status.idle":"2026-01-20T14:34:46.895617Z","shell.execute_reply.started":"2026-01-20T14:34:46.895439Z","shell.execute_reply":"2026-01-20T14:34:46.895455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 5:  Comparison Visualisations","metadata":{}},{"cell_type":"markdown","source":"### Section 5A: Advanced Comparison Visualisations","metadata":{}},{"cell_type":"code","source":"print(f\"\\n{'#'*80}\")\nprint(\"SECTION 5A: MODEL COMPARISON & PERFORMANCE ANALYSIS (6 MODELS)\")\nprint(f\"{'#'*80}\\n\")\n\n# Model colors and display names\nmodel_colors_dict = {\n    'JAX_SimpleNN': '#3B82F6',\n    'JAX_DNN': '#F59E0B',\n    'JAX_FSE_Attention': '#22C55E',\n    'JAX_FSE_Attention_DetectorAware': '#EF4444',\n    'SkLearn_RandomForest': '#8B5CF6',\n    'XGBoost': '#EC4899'\n}\n\nmodel_display_names = {\n    'JAX_SimpleNN': 'SimpleNN',\n    'JAX_DNN': 'DNN',\n    'JAX_FSE_Attention': 'FSE Phase 0',\n    'JAX_FSE_Attention_DetectorAware': 'FSE Phase 1',\n    'SkLearn_RandomForest': 'Random Forest',\n    'XGBoost': 'XGBoost'\n}\n\n# ============================================================================\n# PART 1: COMPREHENSIVE COMPARISON TABLE\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"COMPREHENSIVE MODEL COMPARISON (6 Models, All Momentum Ranges)\")\nprint(f\"{'='*80}\\n\")\n\ncomparison_data = []\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    if mr_key not in all_results_by_model_and_range or 'models' not in all_results_by_model_and_range[mr_key]:\n        continue\n    \n    models_dict = all_results_by_model_and_range[mr_key]['models']\n    \n    for model_type in MODEL_TYPES:\n        if model_type in models_dict:\n            results = models_dict[model_type]\n            \n            # Calculate macro AUC if not present (for JAX models)\n            macro_auc = results.get('macro_auc', np.nan)\n            if np.isnan(macro_auc) or macro_auc == 0:\n                # Calculate from test_probs if available\n                if 'test_probs' in results and results['test_probs'] is not None:\n                    try:\n                        y_test_bin = label_binarize(results['y_test'], classes=np.arange(NUM_CLASSES))\n                        test_probs = results['test_probs']\n                        auc_scores = []\n                        for i in range(NUM_CLASSES):\n                            fpr, tpr, _ = roc_curve(y_test_bin[:, i], test_probs[:, i])\n                            auc_score = auc(fpr, tpr)\n                            auc_scores.append(auc_score)\n                        macro_auc = np.mean(auc_scores)\n                    except:\n                        macro_auc = np.nan\n            \n            comparison_data.append({\n                'Momentum Range': momentum_range['name'],\n                'Model': model_display_names.get(model_type, model_type),\n                'Train Acc': results['train_acc'],\n                'Test Acc': results['test_acc'],\n                'Macro AUC': macro_auc,\n                'Training Time (s)': results.get('training_time', 0)\n            })\n\ncomparison_df = pd.DataFrame(comparison_data)\n\nprint(comparison_df.to_string(index=False))\nprint()\n\n# ============================================================================\n# PART 2: ACCURACY COMPARISON PLOTS (6 Models)\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"ACCURACY COMPARISON ACROSS ALL MODELS (6 Models)\")\nprint(f\"{'='*80}\\n\")\n\nfig, axes = plt.subplots(1, 3, figsize=(21, 5))\n\nfor mr_idx, (mr_key, momentum_range) in enumerate(MOMENTUM_RANGES.items()):\n    ax = axes[mr_idx]\n    \n    x_pos = np.arange(len(MODEL_TYPES))\n    test_accs = []\n    colors = []\n    \n    for model_type in MODEL_TYPES:\n        if mr_key in all_results_by_model_and_range and 'models' in all_results_by_model_and_range[mr_key]:\n            if model_type in all_results_by_model_and_range[mr_key]['models']:\n                results = all_results_by_model_and_range[mr_key]['models'][model_type]\n                test_accs.append(results['test_acc'])\n                colors.append(model_colors_dict.get(model_type, '#999999'))\n            else:\n                test_accs.append(0)\n                colors.append('#CCCCCC')\n        else:\n            test_accs.append(0)\n            colors.append('#CCCCCC')\n    \n    bars = ax.bar(x_pos, test_accs, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n    \n    # Add value labels\n    for bar in bars:\n        height = bar.get_height()\n        if height > 0:\n            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n                   f'{height:.3f}', ha='center', va='bottom',\n                   fontsize=9, fontweight='bold')\n    \n    ax.set_ylabel('Test Accuracy', fontsize=11, fontweight='bold')\n    ax.set_title(f'{momentum_range[\"name\"]}', fontsize=12, fontweight='bold')\n    ax.set_xticks(x_pos)\n    ax.set_xticklabels([model_display_names.get(m, m) for m in MODEL_TYPES], \n                       rotation=45, ha='right', fontsize=9)\n    ax.set_ylim([0, 1.0])\n    ax.grid(axis='y', alpha=0.3)\n\nplt.suptitle('Test Accuracy Comparison (All Models, All Momentum Ranges)', \n             fontsize=13, fontweight='bold', y=0.98)\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Accuracy comparison plots generated (6 models)\")\n\n# ============================================================================\n# PART 3: BEST MODEL SELECTION & CONFUSION MATRICES (GRID VIEW)\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"BEST MODEL SELECTION & CONFUSION MATRICES (3 Ranges)\")\nprint(f\"{'='*80}\\n\")\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\n\nbest_models_info = []\n\nfor mr_idx, (mr_key, momentum_range) in enumerate(MOMENTUM_RANGES.items()):\n    if mr_key not in all_results_by_model_and_range or 'models' not in all_results_by_model_and_range[mr_key]:\n        continue\n    \n    print(f\"\\n{momentum_range['name']}\")\n    print(f\"{'─'*70}\")\n    \n    models_dict = all_results_by_model_and_range[mr_key]['models']\n    \n    # Find best model\n    best_acc = -1\n    best_model = None\n    \n    for model_type in MODEL_TYPES:\n        if model_type in models_dict:\n            test_acc = models_dict[model_type]['test_acc']\n            print(f\"  {model_display_names.get(model_type, model_type):20s}: {test_acc:.4f}\")\n            if test_acc > best_acc:\n                best_acc = test_acc\n                best_model = model_type\n    \n    if best_model:\n        print(f\"\\n✓ Best Model: {model_display_names.get(best_model, best_model)} ({best_acc:.4f})\\n\")\n        \n        best_models_info.append((best_model, mr_key, momentum_range, best_acc))\n        \n        # Confusion matrix for best model\n        y_test = models_dict[best_model]['y_test']\n        y_pred = models_dict[best_model]['y_pred_test']\n        \n        cm = confusion_matrix(y_test, y_pred)\n        \n        # Normalize confusion matrix for better visualization\n        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        \n        ax = axes[0, mr_idx]\n        \n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n                   xticklabels=PARTICLE_NAMES, yticklabels=PARTICLE_NAMES,\n                   cbar_kws={'label': 'Count'}, vmin=0)\n        \n        ax.set_ylabel('True Label', fontsize=10, fontweight='bold')\n        ax.set_xlabel('Predicted Label', fontsize=10, fontweight='bold')\n        ax.set_title(f'{model_display_names.get(best_model, best_model)}\\n{momentum_range[\"name\"]} (Counts)',\n                    fontsize=11, fontweight='bold')\n        \n        # Normalized confusion matrix\n        ax_norm = axes[1, mr_idx]\n        \n        sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='RdYlGn', ax=ax_norm,\n                   xticklabels=PARTICLE_NAMES, yticklabels=PARTICLE_NAMES,\n                   cbar_kws={'label': 'Recall'}, vmin=0, vmax=1)\n        \n        ax_norm.set_ylabel('True Label', fontsize=10, fontweight='bold')\n        ax_norm.set_xlabel('Predicted Label', fontsize=10, fontweight='bold')\n        ax_norm.set_title(f'{model_display_names.get(best_model, best_model)}\\n{momentum_range[\"name\"]} (Normalised)',\n                         fontsize=11, fontweight='bold')\n\nplt.suptitle('Best Model Confusion Matrices (Top: Counts, Bottom: Normalized by True Class)', \n             fontsize=13, fontweight='bold', y=0.995)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✓ Confusion matrices generated in grid format\")\nprint(\"=\"*80)\n\n# ============================================================================\n# PART 4: CLASS-WISE PERFORMANCE METRICS\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"CLASS-WISE PERFORMANCE ANALYSIS (PRECISION, RECALL, F1)\")\nprint(f\"{'='*80}\\n\")\n\nfor best_model, mr_key, momentum_range, best_acc in best_models_info:\n    print(f\"\\n{momentum_range['name']} - {model_display_names.get(best_model, best_model)}\")\n    print(f\"{'─'*70}\")\n    \n    models_dict = all_results_by_model_and_range[mr_key]['models']\n    y_test = models_dict[best_model]['y_test']\n    y_pred = models_dict[best_model]['y_pred_test']\n    \n    # Classification report\n    report = classification_report(y_test, y_pred, target_names=PARTICLE_NAMES, \n                                  output_dict=False, digits=4)\n    print(report)\n\n# ============================================================================\n# PART 5: PERFORMANCE RANKING (ALL 18 RESULTS)\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"PERFORMANCE RANKING (All 18 Results: 3 Ranges × 6 Models)\")\nprint(f\"{'='*80}\\n\")\n\nranking_data = []\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    if mr_key not in all_results_by_model_and_range or 'models' not in all_results_by_model_and_range[mr_key]:\n        continue\n    \n    models_dict = all_results_by_model_and_range[mr_key]['models']\n    \n    for model_type in MODEL_TYPES:\n        if model_type in models_dict:\n            results = models_dict[model_type]\n            \n            # Calculate macro AUC if not present\n            macro_auc = results.get('macro_auc', np.nan)\n            if np.isnan(macro_auc) or macro_auc == 0:\n                if 'test_probs' in results and results['test_probs'] is not None:\n                    try:\n                        y_test_bin = label_binarize(results['y_test'], classes=np.arange(NUM_CLASSES))\n                        test_probs = results['test_probs']\n                        auc_scores = []\n                        for i in range(NUM_CLASSES):\n                            fpr, tpr, _ = roc_curve(y_test_bin[:, i], test_probs[:, i])\n                            auc_score = auc(fpr, tpr)\n                            auc_scores.append(auc_score)\n                        macro_auc = np.mean(auc_scores)\n                    except:\n                        macro_auc = np.nan\n            \n            ranking_data.append({\n                'Rank': 0,\n                'Model': model_display_names.get(model_type, model_type),\n                'Momentum Range': momentum_range['name'],\n                'Test Acc': results['test_acc'],\n                'Macro AUC': macro_auc,\n                'Train Time (s)': results.get('training_time', 0)\n            })\n\nranking_df = pd.DataFrame(ranking_data).sort_values('Test Acc', ascending=False).reset_index(drop=True)\nranking_df['Rank'] = np.arange(1, len(ranking_df) + 1)\n\n# Reorder columns\nranking_df = ranking_df[['Rank', 'Model', 'Momentum Range', 'Test Acc', 'Macro AUC', 'Train Time (s)']]\n\nprint(ranking_df.to_string(index=False))\nprint()\n\n# ============================================================================\n# PART 6: SUMMARY STATISTICS\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"SUMMARY STATISTICS BY MODEL\")\nprint(f\"{'='*80}\\n\")\n\nsummary_stats = []\n\nfor model_type in MODEL_TYPES:\n    model_name = model_display_names.get(model_type, model_type)\n    accs = []\n    aucs = []\n    times = []\n    \n    for mr_key, momentum_range in MOMENTUM_RANGES.items():\n        if mr_key in all_results_by_model_and_range and 'models' in all_results_by_model_and_range[mr_key]:\n            if model_type in all_results_by_model_and_range[mr_key]['models']:\n                results = all_results_by_model_and_range[mr_key]['models'][model_type]\n                accs.append(results['test_acc'])\n                \n                macro_auc = results.get('macro_auc', np.nan)\n                if np.isnan(macro_auc) or macro_auc == 0:\n                    if 'test_probs' in results and results['test_probs'] is not None:\n                        try:\n                            y_test_bin = label_binarize(results['y_test'], classes=np.arange(NUM_CLASSES))\n                            test_probs = results['test_probs']\n                            auc_scores = []\n                            for i in range(NUM_CLASSES):\n                                fpr, tpr, _ = roc_curve(y_test_bin[:, i], test_probs[:, i])\n                                auc_score = auc(fpr, tpr)\n                                auc_scores.append(auc_score)\n                            macro_auc = np.mean(auc_scores)\n                        except:\n                            macro_auc = np.nan\n                \n                if not np.isnan(macro_auc):\n                    aucs.append(macro_auc)\n                times.append(results.get('training_time', 0))\n    \n    if accs:\n        summary_stats.append({\n            'Model': model_name,\n            'Avg Test Acc': np.mean(accs),\n            'Min Test Acc': np.min(accs),\n            'Max Test Acc': np.max(accs),\n            'Avg AUC': np.mean(aucs) if aucs else np.nan,\n            'Total Time (s)': np.sum(times)\n        })\n\nsummary_df = pd.DataFrame(summary_stats).sort_values('Avg Test Acc', ascending=False)\n\nprint(summary_df.to_string(index=False))\nprint()\n\nprint(f\"{'='*80}\")\nprint(\"✓ SECTION 5A COMPLETE: All models compared (6 models)\")\nprint(f\"{'='*80}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:46.896388Z","iopub.status.idle":"2026-01-20T14:34:46.896846Z","shell.execute_reply.started":"2026-01-20T14:34:46.896603Z","shell.execute_reply":"2026-01-20T14:34:46.896625Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Section 5B: ROC/AUC Curves and Summary Statistics","metadata":{}},{"cell_type":"code","source":"print(f\"\\n{'#'*80}\")\nprint(\"SECTION 5B: ROC/AUC ANALYSIS (6 MODELS)\")\nprint(f\"{'#'*80}\\n\")\n\n# Model colors dictionary for consistency\nmodel_colors_dict = {\n    'JAX_SimpleNN': '#3B82F6',\n    'JAX_DNN': '#F59E0B',\n    'JAX_FSE_Attention': '#22C55E',\n    'JAX_FSE_Attention_DetectorAware': '#EF4444',\n    'SkLearn_RandomForest': '#8B5CF6',\n    'XGBoost': '#EC4899'\n}\n\nmodel_display_names = {\n    'JAX_SimpleNN': 'SimpleNN',\n    'JAX_DNN': 'DNN',\n    'JAX_FSE_Attention': 'FSE Phase 0',\n    'JAX_FSE_Attention_DetectorAware': 'FSE Phase 1',\n    'SkLearn_RandomForest': 'Random Forest',\n    'XGBoost': 'XGBoost'\n}\n\n# ============================================================================\n# PART 1: ROC CURVES PER MOMENTUM RANGE (MACRO AUC)\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"ROC CURVES: MACRO AUC (6 Models, All Momentum Ranges)\")\nprint(f\"{'='*80}\\n\")\n\nfig, axes = plt.subplots(1, 3, figsize=(21, 6))\n\nfor mr_idx, (mr_key, momentum_range) in enumerate(MOMENTUM_RANGES.items()):\n    ax = axes[mr_idx]\n    \n    if mr_key not in all_results_by_model_and_range or 'models' not in all_results_by_model_and_range[mr_key]:\n        continue\n    \n    models_dict = all_results_by_model_and_range[mr_key]['models']\n    \n    # Plot diagonal (chance line)\n    ax.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.2)\n    \n    for model_type in MODEL_TYPES:\n        if model_type not in models_dict:\n            continue\n        \n        results = models_dict[model_type]\n        \n        y_test = np.array(results['y_test'])\n        y_test_probs = np.array(results['test_probs'])\n        \n        y_test_bin = label_binarize(y_test, classes=np.arange(NUM_CLASSES))\n        \n        # Calculate macro-average ROC curve and ROC area (per class then average)\n        fpr_all = []\n        tpr_all = []\n        auc_scores = []\n        \n        for i in range(NUM_CLASSES):\n            fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_test_probs[:, i])\n            auc_score = auc(fpr, tpr)\n            auc_scores.append(auc_score)\n            fpr_all.append(fpr)\n            tpr_all.append(tpr)\n        \n        # Macro AUC = average of per-class AUCs\n        macro_auc = np.mean(auc_scores)\n        \n        # For plotting, interpolate to common x-axis for smooth line\n        all_fpr = np.unique(np.concatenate([fpr for fpr in fpr_all]))\n        mean_tpr = np.zeros_like(all_fpr)\n        for i in range(NUM_CLASSES):\n            mean_tpr += np.interp(all_fpr, fpr_all[i], tpr_all[i])\n        mean_tpr /= NUM_CLASSES\n        \n        ax.plot(all_fpr, mean_tpr, \n               label=f'{model_display_names.get(model_type, model_type)} (AUC={macro_auc:.3f})',\n               color=model_colors_dict.get(model_type, '#999999'),\n               lw=2.5, alpha=0.8)\n    \n    ax.set_xlabel('False Positive Rate', fontsize=10, fontweight='bold')\n    ax.set_ylabel('True Positive Rate', fontsize=10, fontweight='bold')\n    ax.set_title(f'{momentum_range[\"name\"]}', fontsize=11, fontweight='bold')\n    ax.set_xlim([0, 1])\n    ax.set_ylim([0, 1])\n    ax.legend(loc='lower right', fontsize=9)\n    ax.grid(alpha=0.3)\n\nplt.suptitle('ROC Curves: Macro AUC (All Models, All Momentum Ranges)', \n             fontsize=13, fontweight='bold', y=0.98)\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ ROC curves (macro AUC) plotted (6 models)\")\n\n# ============================================================================\n# PART 2: ONE-VS-REST ROC CURVES\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"ONE-VS-REST ROC CURVES (Particles vs All, 6 Models)\")\nprint(f\"{'='*80}\\n\")\n\nfig, axes = plt.subplots(3, 4, figsize=(20, 15))\n\nfor mr_idx, (mr_key, momentum_range) in enumerate(MOMENTUM_RANGES.items()):\n    if mr_key not in all_results_by_model_and_range or 'models' not in all_results_by_model_and_range[mr_key]:\n        continue\n    \n    models_dict = all_results_by_model_and_range[mr_key]['models']\n    \n    for particle_idx, particle_name in enumerate(PARTICLE_NAMES):\n        ax = axes[mr_idx, particle_idx]\n        \n        # Plot diagonal (chance line)\n        ax.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.2)\n        \n        for model_type in MODEL_TYPES:\n            if model_type not in models_dict:\n                continue\n            \n            results = models_dict[model_type]\n            y_test = np.array(results['y_test'])\n            y_test_probs = np.array(results['test_probs'])\n            \n            y_binary = (y_test == particle_idx).astype(int)\n            \n            fpr, tpr, _ = roc_curve(y_binary, y_test_probs[:, particle_idx])\n            roc_auc = auc(fpr, tpr)\n            \n            ax.plot(fpr, tpr, \n                   label=f'{model_display_names.get(model_type, model_type)} ({roc_auc:.3f})',\n                   color=model_colors_dict.get(model_type, '#999999'),\n                   lw=2, alpha=0.8)\n        \n        ax.set_xlabel('FPR', fontsize=9, fontweight='bold')\n        ax.set_ylabel('TPR', fontsize=9, fontweight='bold')\n        ax.set_title(f'{particle_name} ({momentum_range[\"name\"]})', fontsize=10, fontweight='bold')\n        ax.set_xlim([0, 1])\n        ax.set_ylim([0, 1])\n        ax.legend(loc='lower right', fontsize=8)\n        ax.grid(alpha=0.3)\n\nplt.suptitle('One-vs-Rest ROC Curves (All Particles, 3 Momentum Ranges, 6 Models)', \n             fontsize=13, fontweight='bold', y=0.995)\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ One-vs-rest ROC curves plotted (6 models × 4 particles × 3 ranges)\")\n\n# ============================================================================\n# PART 3: MACRO AUC SUMMARY TABLE\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"MACRO AUC SUMMARY TABLE (6 Models, All Ranges & Particles)\")\nprint(f\"{'='*80}\\n\")\n\nauc_summary_data = []\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    if mr_key not in all_results_by_model_and_range or 'models' not in all_results_by_model_and_range[mr_key]:\n        continue\n    \n    models_dict = all_results_by_model_and_range[mr_key]['models']\n    \n    for model_type in MODEL_TYPES:\n        if model_type not in models_dict:\n            continue\n        \n        results = models_dict[model_type]\n        \n        y_test = np.array(results['y_test'])\n        y_test_probs = np.array(results['test_probs'])\n        \n        y_test_bin = label_binarize(y_test, classes=np.arange(NUM_CLASSES))\n        \n        for particle_idx, particle_name in enumerate(PARTICLE_NAMES):\n            fpr, tpr, _ = roc_curve(y_test_bin[:, particle_idx], y_test_probs[:, particle_idx])\n            roc_auc = auc(fpr, tpr)\n            \n            auc_summary_data.append({\n                'Momentum Range': momentum_range['name'],\n                'Model': model_display_names.get(model_type, model_type),\n                'Particle': particle_name,\n                'AUC': roc_auc\n            })\n\nauc_summary_df = pd.DataFrame(auc_summary_data)\n\nprint(auc_summary_df.to_string(index=False))\nprint()\n\n# ============================================================================\n# PART 4: MACRO AUC RANKING (Fixed - Calculates for JAX models too)\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"MACRO AUC RANKING (All Models, All Ranges)\")\nprint(f\"{'='*80}\\n\")\n\nmacro_auc_ranking = []\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    if mr_key not in all_results_by_model_and_range or 'models' not in all_results_by_model_and_range[mr_key]:\n        continue\n    \n    models_dict = all_results_by_model_and_range[mr_key]['models']\n    \n    for model_type in MODEL_TYPES:\n        if model_type not in models_dict:\n            continue\n        \n        results = models_dict[model_type]\n        \n        # Calculate macro AUC if not present (for JAX models)\n        macro_auc = results.get('macro_auc', np.nan)\n        \n        if np.isnan(macro_auc) or macro_auc == 0:\n            # Calculate from test_probs\n            if 'test_probs' in results and results['test_probs'] is not None:\n                try:\n                    y_test = np.array(results['y_test'])\n                    y_test_probs = np.array(results['test_probs'])\n                    y_test_bin = label_binarize(y_test, classes=np.arange(NUM_CLASSES))\n                    \n                    auc_scores = []\n                    for i in range(NUM_CLASSES):\n                        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_test_probs[:, i])\n                        auc_score = auc(fpr, tpr)\n                        auc_scores.append(auc_score)\n                    macro_auc = np.mean(auc_scores)\n                except Exception as e:\n                    print(f\"Warning: Could not calculate macro AUC for {model_type} in {mr_key}: {e}\")\n                    macro_auc = np.nan\n        \n        macro_auc_ranking.append({\n            'Rank': 0,\n            'Model': model_display_names.get(model_type, model_type),\n            'Momentum Range': momentum_range['name'],\n            'Macro AUC': macro_auc\n        })\n\nmacro_auc_ranking_df = pd.DataFrame(macro_auc_ranking).dropna(subset=['Macro AUC']).sort_values('Macro AUC', ascending=False).reset_index(drop=True)\nmacro_auc_ranking_df['Rank'] = np.arange(1, len(macro_auc_ranking_df) + 1)\n\nprint(macro_auc_ranking_df[['Rank', 'Model', 'Momentum Range', 'Macro AUC']].to_string(index=False))\nprint()\n\nprint(f\"{'='*80}\")\nprint(\"✓ SECTION 5B COMPLETE: ROC/AUC Analysis (6 models)\")\nprint(f\"{'='*80}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:46.898325Z","iopub.status.idle":"2026-01-20T14:34:46.898550Z","shell.execute_reply.started":"2026-01-20T14:34:46.898446Z","shell.execute_reply":"2026-01-20T14:34:46.898456Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Section 5C: Per-Class Efficiency & Purity","metadata":{}},{"cell_type":"code","source":"print(f\"\\n{'#'*80}\")\nprint(\"SECTION 5C: EFFICIENCY, PURITY, F1-SCORE & FEATURE IMPORTANCE (6 MODELS)\")\nprint(f\"{'#'*80}\\n\")\n\n# ============================================================================\n# PART 1: EFFICIENCY & PURITY PER PARTICLE TYPE (WITH F1-SCORE)\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"EFFICIENCY & PURITY PER PARTICLE TYPE (6 Models)\")\nprint(f\"{'='*80}\\n\")\n\nefficiency_purity_data = []\n\nfor mr_key, mr_data in all_results_by_model_and_range.items():\n    momentum_range = MOMENTUM_RANGES.get(mr_key, {})\n    \n    if 'models' in mr_data:\n        for model_type in MODEL_TYPES:\n            if model_type in mr_data['models']:\n                results = mr_data['models'][model_type]\n                \n                y_test = np.array(results['y_test'])\n                y_pred = np.array(results['y_pred_test'])\n                \n                print(f\"\\n{'-'*80}\")\n                print(f\"{momentum_range['name']} - {model_display_names.get(model_type, model_type)}\")\n                print(f\"{'-'*80}\\n\")\n                \n                print(f\"{'Particle':<12} {'Efficiency':<15} {'Purity':<15} {'F1-Score':<12} {'Support':<10}\")\n                print(f\"{'-'*64}\")\n                \n                for i, particle_name in enumerate(PARTICLE_NAMES):\n                    true_positives = np.sum((y_test == i) & (y_pred == i))\n                    false_negatives = np.sum((y_test == i) & (y_pred != i))\n                    efficiency = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n                    \n                    false_positives = np.sum((y_test != i) & (y_pred == i))\n                    purity = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n                    \n                    f1_score = 2 * (efficiency * purity) / (efficiency + purity) if (efficiency + purity) > 0 else 0\n                    \n                    support = np.sum(y_test == i)\n                    \n                    efficiency_purity_data.append({\n                        'Momentum Range': momentum_range['name'],\n                        'Model Type': model_type,\n                        'Particle': particle_name,\n                        'Efficiency': efficiency,\n                        'Purity': purity,\n                        'F1-Score': f1_score,\n                        'Support': support\n                    })\n                    \n                    print(f\"{particle_name:<12} {efficiency:<15.4f} {purity:<15.4f} {f1_score:<12.4f} {support:<10}\")\n\n# ============================================================================\n# PART 2: EFFICIENCY vs PURITY TRADE-OFF\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"EFFICIENCY vs PURITY TRADE-OFF (6 Models)\")\nprint(f\"{'='*80}\\n\")\n\nfig, axes = plt.subplots(2, 3, figsize=(20, 12))\naxes = axes.flatten()\n\nfor ax_idx, model_type in enumerate(MODEL_TYPES):\n    ax = axes[ax_idx]\n    \n    model_data = [d for d in efficiency_purity_data if d['Model Type'] == model_type]\n    \n    for particle in PARTICLE_NAMES:\n        particle_data = [d for d in model_data if d['Particle'] == particle]\n        \n        effs = [d['Efficiency'] for d in particle_data]\n        purs = [d['Purity'] for d in particle_data]\n        \n        ax.scatter(effs, purs, s=150, alpha=0.7, label=particle)\n    \n    ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, linewidth=1)\n    ax.set_xlabel('Efficiency (Recall)', fontsize=10, fontweight='bold')\n    ax.set_ylabel('Purity (Precision)', fontsize=10, fontweight='bold')\n    ax.set_title(model_display_names.get(model_type, model_type), fontsize=11, fontweight='bold')\n    ax.set_xlim([0, 1.05])\n    ax.set_ylim([0, 1.05])\n    ax.grid(alpha=0.3)\n    ax.legend(loc='lower left', fontsize=9)\n\naxes[-1].set_visible(False)\n\nplt.suptitle('Efficiency vs Purity Trade-off (All Particles, All Ranges, 6 Models)', \n             fontsize=13, fontweight='bold', y=0.995)\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Efficiency vs Purity trade-off plot generated (6 models)\")\n\n# ============================================================================\n# PART 2B: EFFICIENCY COMPARISON\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"EFFICIENCY COMPARISON ACROSS ALL MODELS (Per Particle, 6 Models)\")\nprint(f\"{'='*80}\\n\")\n\nfig, axes = plt.subplots(1, 4, figsize=(24, 5))\n\nfor particle_idx, particle_name in enumerate(PARTICLE_NAMES):\n    ax = axes[particle_idx]\n    \n    model_effs = {model_type: [] for model_type in MODEL_TYPES}\n    \n    for model_type in MODEL_TYPES:\n        for mr_key in MOMENTUM_RANGES.keys():\n            particle_data = [d for d in efficiency_purity_data \n                           if d['Model Type'] == model_type \n                           and d['Particle'] == particle_name\n                           and d['Momentum Range'] == MOMENTUM_RANGES[mr_key]['name']]\n            \n            if particle_data:\n                model_effs[model_type].append(particle_data[0]['Efficiency'])\n    \n    x_pos = np.arange(len(MODEL_TYPES))\n    effs = [np.mean(model_effs[m]) if model_effs[m] else 0 for m in MODEL_TYPES]\n    colors = [model_colors_dict.get(m, '#999999') for m in MODEL_TYPES]\n    \n    bars = ax.bar(x_pos, effs, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n    \n    for bar in bars:\n        height = bar.get_height()\n        if height > 0:\n            ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n                   f'{height:.3f}', ha='center', va='bottom',\n                   fontsize=9, fontweight='bold')\n    \n    ax.set_ylabel('Efficiency (Avg)', fontsize=10, fontweight='bold')\n    ax.set_title(f'{particle_name}', fontsize=11, fontweight='bold')\n    ax.set_xticks(x_pos)\n    ax.set_xticklabels([model_display_names.get(m, m) for m in MODEL_TYPES], \n                       rotation=45, ha='right', fontsize=9)\n    ax.set_ylim([0, 1.05])\n    ax.grid(axis='y', alpha=0.3)\n\nplt.suptitle('Average Efficiency by Model (All Momentum Ranges, 6 Models)', \n             fontsize=13, fontweight='bold', y=1.00)\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Efficiency comparison plot generated (6 models)\")\n\n# ============================================================================\n# PART 2C: PURITY COMPARISON\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"PURITY COMPARISON ACROSS ALL MODELS (Per Particle, 6 Models)\")\nprint(f\"{'='*80}\\n\")\n\nfig, axes = plt.subplots(1, 4, figsize=(24, 5))\n\nfor particle_idx, particle_name in enumerate(PARTICLE_NAMES):\n    ax = axes[particle_idx]\n    \n    model_purs = {model_type: [] for model_type in MODEL_TYPES}\n    \n    for model_type in MODEL_TYPES:\n        for mr_key in MOMENTUM_RANGES.keys():\n            particle_data = [d for d in efficiency_purity_data \n                           if d['Model Type'] == model_type \n                           and d['Particle'] == particle_name\n                           and d['Momentum Range'] == MOMENTUM_RANGES[mr_key]['name']]\n            \n            if particle_data:\n                model_purs[model_type].append(particle_data[0]['Purity'])\n    \n    x_pos = np.arange(len(MODEL_TYPES))\n    purs = [np.mean(model_purs[m]) if model_purs[m] else 0 for m in MODEL_TYPES]\n    colors = [model_colors_dict.get(m, '#999999') for m in MODEL_TYPES]\n    \n    bars = ax.bar(x_pos, purs, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n    \n    for bar in bars:\n        height = bar.get_height()\n        if height > 0:\n            ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n                   f'{height:.3f}', ha='center', va='bottom',\n                   fontsize=9, fontweight='bold')\n    \n    ax.set_ylabel('Purity (Avg)', fontsize=10, fontweight='bold')\n    ax.set_title(f'{particle_name}', fontsize=11, fontweight='bold')\n    ax.set_xticks(x_pos)\n    ax.set_xticklabels([model_display_names.get(m, m) for m in MODEL_TYPES], \n                       rotation=45, ha='right', fontsize=9)\n    ax.set_ylim([0, 1.05])\n    ax.grid(axis='y', alpha=0.3)\n\nplt.suptitle('Average Purity by Model (All Momentum Ranges, 6 Models)', \n             fontsize=13, fontweight='bold', y=1.00)\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Purity comparison plot generated (6 models)\")\n\n# ============================================================================\n# PART 3: COMPREHENSIVE F1-SCORE ANALYSIS\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"COMPREHENSIVE F1-SCORE ANALYSIS\")\nprint(f\"{'='*80}\\n\")\n\n# Part 3A: F1-Score Ranking by Model & Range\nprint(f\"\\n{'─'*80}\")\nprint(\"F1-SCORE RANKING (Model × Momentum Range, Averaged Over Particles)\")\nprint(f\"{'─'*80}\\n\")\n\nf1_ranking = []\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    for model_type in MODEL_TYPES:\n        model_range_data = [d for d in efficiency_purity_data \n                          if d['Model Type'] == model_type\n                          and d['Momentum Range'] == momentum_range['name']]\n        \n        if model_range_data:\n            avg_eff = np.mean([d['Efficiency'] for d in model_range_data])\n            avg_pur = np.mean([d['Purity'] for d in model_range_data])\n            avg_f1 = np.mean([d['F1-Score'] for d in model_range_data])\n            \n            f1_ranking.append({\n                'Model': model_display_names.get(model_type, model_type),\n                'Momentum Range': momentum_range['name'],\n                'Avg Efficiency': avg_eff,\n                'Avg Purity': avg_pur,\n                'Avg F1-Score': avg_f1\n            })\n\nf1_ranking_df = pd.DataFrame(f1_ranking).sort_values('Avg F1-Score', ascending=False).reset_index(drop=True)\nf1_ranking_df['Rank'] = np.arange(1, len(f1_ranking_df) + 1)\n\nprint(f1_ranking_df[['Rank', 'Model', 'Momentum Range', 'Avg Efficiency', 'Avg Purity', 'Avg F1-Score']].to_string(index=False))\nprint()\n\n# Part 3B: F1-Score Heatmap\nprint(f\"\\n{'─'*80}\")\nprint(\"F1-SCORE HEATMAP (Models vs Momentum Ranges)\")\nprint(f\"{'─'*80}\\n\")\n\nf1_pivot = f1_ranking_df.pivot_table(\n    values='Avg F1-Score',\n    index='Model',\n    columns='Momentum Range',\n    aggfunc='mean'\n)\n\nf1_pivot = f1_pivot[[mr['name'] for mr in MOMENTUM_RANGES.values()]]\n\nfig, ax = plt.subplots(figsize=(12, 8))\n\nsns.heatmap(f1_pivot, annot=True, fmt='.3f', cmap='RdYlGn', ax=ax,\n           cbar_kws={'label': 'F1-Score'}, vmin=0, vmax=1, linewidths=0.5)\n\nax.set_xlabel('Momentum Range', fontsize=11, fontweight='bold')\nax.set_ylabel('Model', fontsize=11, fontweight='bold')\nax.set_title('F1-Score Heatmap (All Models × All Momentum Ranges)', \n            fontsize=12, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ F1-score heatmap generated\")\n\n# Part 3C: F1-Score Comparison Plots\nprint(f\"\\n{'─'*80}\")\nprint(\"F1-SCORE COMPARISON PLOTS (Per Momentum Range)\")\nprint(f\"{'─'*80}\\n\")\n\nfig, axes = plt.subplots(1, 3, figsize=(21, 5))\n\nfor mr_idx, (mr_key, momentum_range) in enumerate(MOMENTUM_RANGES.items()):\n    ax = axes[mr_idx]\n    \n    x_pos = np.arange(len(MODEL_TYPES))\n    f1_scores = []\n    colors = []\n    \n    for model_type in MODEL_TYPES:\n        model_range_data = [d for d in efficiency_purity_data \n                          if d['Model Type'] == model_type\n                          and d['Momentum Range'] == momentum_range['name']]\n        \n        if model_range_data:\n            avg_f1 = np.mean([d['F1-Score'] for d in model_range_data])\n            f1_scores.append(avg_f1)\n            colors.append(model_colors_dict.get(model_type, '#999999'))\n        else:\n            f1_scores.append(0)\n            colors.append('#CCCCCC')\n    \n    bars = ax.bar(x_pos, f1_scores, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n    \n    for bar in bars:\n        height = bar.get_height()\n        if height > 0:\n            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n                   f'{height:.3f}', ha='center', va='bottom',\n                   fontsize=9, fontweight='bold')\n    \n    ax.set_ylabel('F1-Score', fontsize=10, fontweight='bold')\n    ax.set_title(f'{momentum_range[\"name\"]}', fontsize=11, fontweight='bold')\n    ax.set_xticks(x_pos)\n    ax.set_xticklabels([model_display_names.get(m, m) for m in MODEL_TYPES], \n                       rotation=45, ha='right', fontsize=9)\n    ax.set_ylim([0, 1.0])\n    ax.grid(axis='y', alpha=0.3)\n\nplt.suptitle('F1-Score Comparison (All Models, All Momentum Ranges)', \n             fontsize=13, fontweight='bold', y=0.98)\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ F1-score comparison plots generated\")\n\n# Part 3D: F1-Score by Particle Type (SORTED BY HIGHEST F1-SCORE)\nprint(f\"\\n{'─'*80}\")\nprint(\"F1-SCORE BY PARTICLE TYPE (All Models, All Ranges - Ranked by F1-Score)\")\nprint(f\"{'─'*80}\\n\")\n\nf1_by_particle = []\n\nfor particle_name in PARTICLE_NAMES:\n    for model_type in MODEL_TYPES:\n        particle_model_data = [d for d in efficiency_purity_data \n                              if d['Particle'] == particle_name \n                              and d['Model Type'] == model_type]\n        \n        if particle_model_data:\n            avg_f1 = np.mean([d['F1-Score'] for d in particle_model_data])\n            \n            f1_by_particle.append({\n                'Particle': particle_name,\n                'Model': model_display_names.get(model_type, model_type),\n                'Avg F1-Score': avg_f1\n            })\n\n# FIXED: Sort by F1-Score (highest first), then add ranking\nf1_particle_df = pd.DataFrame(f1_by_particle).sort_values('Avg F1-Score', ascending=False).reset_index(drop=True)\nf1_particle_df['Rank'] = np.arange(1, len(f1_particle_df) + 1)\n\nprint(f1_particle_df[['Rank', 'Particle', 'Model', 'Avg F1-Score']].to_string(index=False))\nprint()\n\n# ============================================================================\n# PART 4: FEATURE IMPORTANCE ANALYSIS (FIXED - NO MORE ERRORS)\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"FEATURE IMPORTANCE ANALYSIS (All 6 Models - FIXED)\")\nprint(f\"{'='*80}\\n\")\n\nfeature_importance_results = []\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    mr_data = all_results_by_model_and_range[mr_key]\n    \n    print(f\"\\n{'─'*80}\")\n    print(f\"MOMENTUM RANGE: {momentum_range['name']}\")\n    print(f\"{'─'*80}\\n\")\n    \n    preprocessing = mr_data['preprocessing']\n    X_test = preprocessing['X_test_scaled']\n    y_test = preprocessing['y_test']\n    features = TRAINING_FEATURES\n    \n    for model_type in MODEL_TYPES:\n        if 'models' in mr_data and model_type in mr_data['models']:\n            results = mr_data['models'][model_type]\n            \n            print(f\"\\n{model_display_names.get(model_type, model_type)}:\")\n            print(f\"{'─'*50}\")\n            \n            if model_type in ['SkLearn_RandomForest', 'XGBoost'] and 'feature_importances' in results:\n                importances = np.array(results['feature_importances'])\n                \n                # FIX: Handle size mismatch by padding\n                if len(importances) < len(features):\n                    importances = np.pad(importances, (0, len(features) - len(importances)), mode='constant')\n                elif len(importances) > len(features):\n                    importances = importances[:len(features)]\n                \n                if np.sum(importances) > 0:\n                    importances = importances / np.sum(importances) * 100\n                \n                importance_df = pd.DataFrame({\n                    'Feature': features,\n                    'Importance (%)': importances\n                }).sort_values('Importance (%)', ascending=False)\n                \n                print(importance_df.head(10).to_string(index=False))\n                \n                for idx, row in importance_df.iterrows():\n                    feature_importance_results.append({\n                        'Momentum Range': momentum_range['name'],\n                        'Model Type': model_type,\n                        'Feature': row['Feature'],\n                        'Importance (%)': row['Importance (%)']\n                    })\n            \n            elif model_type not in ['SkLearn_RandomForest', 'XGBoost']:\n                try:\n                    y_pred_probs = np.array(results['test_probs'])\n                    \n                    # FIX: Only compute for features that exist in X_test\n                    n_features = X_test.shape[1]\n                    importances = np.zeros(n_features)\n                    max_probs = np.max(y_pred_probs, axis=1)\n                    \n                    for feat_idx in range(n_features):\n                        feat_var = np.var(X_test[:, feat_idx])\n                        \n                        # Handle edge cases in correlation\n                        try:\n                            correlation = np.corrcoef(X_test[:, feat_idx], max_probs)[0, 1]\n                        except:\n                            correlation = 0.0\n                        \n                        if np.isnan(correlation):\n                            correlation = 0.0\n                        \n                        correlation = np.clip(correlation, -1, 1)\n                        importance = feat_var * (1 + abs(correlation))\n                        importances[feat_idx] = importance\n                    \n                    # FIX: Pad importances to match full feature list\n                    if len(importances) < len(features):\n                        importances = np.pad(importances, (0, len(features) - len(importances)), mode='constant')\n                    \n                    if np.sum(importances) > 0:\n                        importances = importances / np.sum(importances) * 100\n                    else:\n                        importances = np.ones(len(features)) / len(features) * 100\n                    \n                    importance_df = pd.DataFrame({\n                        'Feature': features,\n                        'Importance (%)': importances\n                    }).sort_values('Importance (%)', ascending=False)\n                    \n                    print(importance_df.head(10).to_string(index=False))\n                    \n                    for idx, row in importance_df.iterrows():\n                        feature_importance_results.append({\n                            'Momentum Range': momentum_range['name'],\n                            'Model Type': model_type,\n                            'Feature': row['Feature'],\n                            'Importance (%)': row['Importance (%)']\n                        })\n                \n                except Exception as e:\n                    print(f\"Error calculating importance for {model_type}: {e}\")\n                    # Fallback: uniform importance\n                    importances = np.ones(len(features)) / len(features) * 100\n                    importance_df = pd.DataFrame({\n                        'Feature': features,\n                        'Importance (%)': importances\n                    }).sort_values('Importance (%)', ascending=False)\n                    \n                    print(importance_df.head(10).to_string(index=False))\n                    \n                    for idx, row in importance_df.iterrows():\n                        feature_importance_results.append({\n                            'Momentum Range': momentum_range['name'],\n                            'Model Type': model_type,\n                            'Feature': row['Feature'],\n                            'Importance (%)': row['Importance (%)']\n                        })\n\n# ============================================================================\n# PART 5: FEATURE IMPORTANCE VISUALISATION\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"TOP 10 FEATURES VISUALISATION (6 Models)\")\nprint(f\"{'='*80}\\n\")\n\nfig, axes = plt.subplots(3, 6, figsize=(28, 14))\n\nfor mr_idx, mr_key in enumerate(MOMENTUM_RANGES.keys()):\n    momentum_range = MOMENTUM_RANGES[mr_key]\n    \n    for model_idx, model_type in enumerate(MODEL_TYPES):\n        ax = axes[mr_idx, model_idx]\n        \n        data = [d for d in feature_importance_results \n                if d['Momentum Range'] == momentum_range['name'] \n                and d['Model Type'] == model_type]\n        \n        if data:\n            df_plot = pd.DataFrame(data).sort_values('Importance (%)', \n                                                     ascending=False).head(10)\n            \n            color = model_colors_dict.get(model_type, '#3B82F6')\n            ax.barh(range(len(df_plot)), df_plot['Importance (%)'], \n                   color=color, alpha=0.7, edgecolor='black', linewidth=1)\n            ax.set_yticks(range(len(df_plot)))\n            ax.set_yticklabels(df_plot['Feature'], fontsize=8)\n            ax.set_xlabel('Importance (%)', fontsize=9, fontweight='bold')\n            \n            model_display = model_display_names.get(model_type, model_type)\n            ax.set_title(f'{momentum_range[\"name\"]}\\n{model_display}', \n                        fontsize=10, fontweight='bold')\n            ax.grid(axis='x', alpha=0.3)\n            ax.invert_yaxis()\n\nplt.suptitle('Top 10 Feature Importance by Model & Momentum Range (6 Models)', \n             fontsize=14, fontweight='bold', y=0.995)\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Feature importance visualisation generated (6 models)\")\n\n# ============================================================================\n# PART 6: OVERALL SUMMARY STATISTICS\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"OVERALL SUMMARY STATISTICS (All Models)\")\nprint(f\"{'='*80}\\n\")\n\nsummary_stats = []\n\nfor model_type in MODEL_TYPES:\n    model_data = [d for d in efficiency_purity_data if d['Model Type'] == model_type]\n    \n    avg_eff = np.mean([d['Efficiency'] for d in model_data]) if model_data else 0\n    avg_pur = np.mean([d['Purity'] for d in model_data]) if model_data else 0\n    avg_f1 = np.mean([d['F1-Score'] for d in model_data]) if model_data else 0\n    \n    summary_stats.append({\n        'Model': model_display_names.get(model_type, model_type),\n        'Avg Efficiency': avg_eff,\n        'Avg Purity': avg_pur,\n        'Avg F1-Score': avg_f1\n    })\n\nsummary_df = pd.DataFrame(summary_stats).sort_values('Avg F1-Score', ascending=False)\n\nprint(summary_df.to_string(index=False))\nprint()\n\nprint(f\"{'='*80}\")\nprint(\"✓ SECTION 5C COMPLETE: Efficiency, Purity, F1-Score & Feature Importance\")\nprint(f\"{'='*80}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:46.899513Z","iopub.status.idle":"2026-01-20T14:34:46.899745Z","shell.execute_reply.started":"2026-01-20T14:34:46.899644Z","shell.execute_reply":"2026-01-20T14:34:46.899653Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Section 5D: FSE Detector-Aware Analysis","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 5D: PHASE 1 DETECTOR-AWARE FSE ANALYSIS\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"SECTION 5D: PHASE 1 DETECTOR-AWARE FSE ANALYSIS\")\nprint(f\"{'#'*80}\\n\")\n\n# ============================================================================\n# PART 1: COMPARE STANDARD FSE vs DETECTOR-AWARE FSE\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"COMPARING: Standard FSE vs Detector-Aware FSE\")\nprint(f\"{'='*80}\\n\")\n\nmode_names = {0: 'NONE', 1: 'TPC_ONLY', 2: 'TOF_ONLY', 3: 'TPC_TOF'}\ncomparison_results = []\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    \n    print(f\"\\n{'─'*80}\")\n    print(f\"{momentum_range['name']}\")\n    print(f\"{'─'*80}\\n\")\n    \n    # Check if both models exist\n    if mr_key not in all_results_by_model_and_range:\n        print(\"  (No models trained for this range)\")\n        continue\n    \n    mr_data = all_results_by_model_and_range[mr_key]\n    \n    if 'models' not in mr_data:\n        print(\"  (No models in this range)\")\n        continue\n    \n    if 'JAX_FSE_Attention' not in mr_data['models']:\n        print(\"  Standard FSE+Attention not trained\")\n        continue\n    \n    if 'JAX_FSE_Attention_DetectorAware' not in mr_data['models']:\n        print(\"  Detector-Aware FSE not trained\")\n        continue\n    \n    # Get test data\n    preprocessing_data = mr_data['preprocessing']\n    y_test = np.array(preprocessing_data['y_test'])\n    detector_modes_test = np.array(preprocessing_data['detector_modes_test'])\n    \n    # Get model predictions\n    standard_results = mr_data['models']['JAX_FSE_Attention']\n    aware_results = mr_data['models']['JAX_FSE_Attention_DetectorAware']\n    \n    y_pred_std = np.array(standard_results['y_pred_test'])\n    y_pred_aware = np.array(aware_results['y_pred_test'])\n    \n    # Overall comparison\n    acc_std = accuracy_score(y_test, y_pred_std)\n    acc_aware = accuracy_score(y_test, y_pred_aware)\n    improvement = acc_aware - acc_std\n    improvement_pct = (improvement / acc_std * 100) if acc_std > 0 else 0\n    \n    print(f\"  OVERALL PERFORMANCE:\")\n    print(f\"    Standard FSE:       {acc_std:.4f}\")\n    print(f\"    Detector-Aware FSE: {acc_aware:.4f}\")\n    print(f\"    Improvement:        {improvement:+.4f} ({improvement_pct:+.2f}%)\")\n    \n    # Per-detector-mode breakdown\n    print(f\"\\n  PERFORMANCE BY DETECTOR MODE:\")\n    print(f\"  {'Mode':15s}  {'Tracks':>8s}  {'Std FSE':>8s}  {'Aware FSE':>10s}  {'Δ':>8s}\")\n    print(f\"  {'-'*60}\")\n    \n    for mode in [0, 1, 2, 3]:\n        mask = detector_modes_test == mode\n        if mask.sum() == 0:\n            continue\n        \n        n_tracks = mask.sum()\n        y_mode = y_test[mask]\n        y_pred_std_mode = y_pred_std[mask]\n        y_pred_aware_mode = y_pred_aware[mask]\n        \n        acc_std_mode = accuracy_score(y_mode, y_pred_std_mode)\n        acc_aware_mode = accuracy_score(y_mode, y_pred_aware_mode)\n        delta = acc_aware_mode - acc_std_mode\n        \n        print(f\"  {mode_names[mode]:15s}  {n_tracks:8,}  {acc_std_mode:8.4f}  {acc_aware_mode:10.4f}  {delta:+8.4f}\")\n        \n        comparison_results.append({\n            'Momentum Range': momentum_range['name'],\n            'Detector Mode': mode_names[mode],\n            'Tracks': n_tracks,\n            'Std FSE': acc_std_mode,\n            'Aware FSE': acc_aware_mode,\n            'Delta': delta\n        })\n\n# ============================================================================\n# PART 2: VISUALISATION - DETECTOR MODE COMPARISON (BAR PLOTS)\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"GENERATING COMPARISON VISUALISATIONS\")\nprint(f\"{'='*80}\\n\")\n\nif comparison_results:\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    \n    for mr_idx, (mr_key, momentum_range) in enumerate(MOMENTUM_RANGES.items()):\n        ax = axes[mr_idx]\n        \n        # Filter data for this momentum range\n        data_for_range = [d for d in comparison_results \n                         if d['Momentum Range'] == momentum_range['name']]\n        \n        if not data_for_range:\n            ax.text(0.5, 0.5, 'No data', ha='center', va='center', transform=ax.transAxes)\n            ax.set_title(momentum_range['name'])\n            continue\n        \n        modes = [d['Detector Mode'] for d in data_for_range]\n        std_accs = [d['Std FSE'] for d in data_for_range]\n        aware_accs = [d['Aware FSE'] for d in data_for_range]\n        \n        x = np.arange(len(modes))\n        width = 0.35\n        \n        bars1 = ax.bar(x - width/2, std_accs, width, \n                      label='Standard FSE', color='#3B82F6',\n                      alpha=0.8, edgecolor='black', linewidth=1.5)\n        bars2 = ax.bar(x + width/2, aware_accs, width,\n                      label='Detector-Aware FSE', color='#22C55E',\n                      alpha=0.8, edgecolor='black', linewidth=1.5)\n        \n        # Add value labels on bars\n        for bars in [bars1, bars2]:\n            for bar in bars:\n                height = bar.get_height()\n                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n                       f'{height:.4f}', ha='center', va='bottom',\n                       fontsize=8, fontweight='bold')\n        \n        ax.set_ylabel('Accuracy', fontsize=11, fontweight='bold')\n        ax.set_title(f'{momentum_range[\"name\"]}', fontsize=12, fontweight='bold')\n        ax.set_xticks(x)\n        ax.set_xticklabels(modes, fontsize=10, rotation=45, ha='right')\n        ax.set_ylim([0.5, 1.05])\n        ax.legend(fontsize=9)\n        ax.grid(axis='y', alpha=0.3)\n    \n    plt.suptitle('Phase 1: Standard FSE vs Detector-Aware FSE (by Detector Mode)', \n                 fontsize=14, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.show()\n    \n    print(\"✓ Comparison bar plots generated\")\n\n# ============================================================================\n# PART 3: SUMMARY TABLE\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"SUMMARY TABLE: PHASE 1 DETECTOR-AWARE FSE COMPARISON\")\nprint(f\"{'='*80}\\n\")\n\nif comparison_results:\n    comparison_df = pd.DataFrame(comparison_results)\n    \n    # Format for display\n    pd.set_option('display.max_rows', None)\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.width', None)\n    \n    print(comparison_df.to_string(index=False))\n    \n    # Summary by momentum range\n    print(f\"\\n{'─'*80}\")\n    print(\"IMPROVEMENT SUMMARY BY MOMENTUM RANGE:\")\n    print(f\"{'─'*80}\\n\")\n    \n    for mr_key, momentum_range in MOMENTUM_RANGES.items():\n        \n        # Find all results for this range\n        range_data = [d for d in comparison_results if d['Momentum Range'] == momentum_range['name']]\n        \n        if not range_data:\n            continue\n        \n        # Calculate overall improvement\n        total_tracks = sum(d['Tracks'] for d in range_data)\n        weighted_std = sum(d['Std FSE'] * d['Tracks'] for d in range_data) / total_tracks\n        weighted_aware = sum(d['Aware FSE'] * d['Tracks'] for d in range_data) / total_tracks\n        overall_improvement = weighted_aware - weighted_std\n        overall_improvement_pct = (overall_improvement / weighted_std * 100)\n        \n        print(f\"{momentum_range['name']:30s}:\")\n        print(f\"  Weighted Standard FSE:    {weighted_std:.4f}\")\n        print(f\"  Weighted Aware FSE:       {weighted_aware:.4f}\")\n        print(f\"  Overall Improvement:      {overall_improvement:+.4f} ({overall_improvement_pct:+.2f}%)\")\n        \n        # Find best improvement\n        best_mode = max(range_data, key=lambda x: x['Delta'])\n        print(f\"  Best improvement:         {best_mode['Detector Mode']:15s}: {best_mode['Delta']:+.4f}\")\n        print()\n\n# ============================================================================\n# PART 4: DETECTOR MODE IMPACT ANALYSIS\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"DETECTOR MODE IMPACT ANALYSIS\")\nprint(f\"{'='*80}\\n\")\n\nif comparison_results:\n    # Group by detector mode\n    mode_improvements = {}\n    \n    for result in comparison_results:\n        mode = result['Detector Mode']\n        if mode not in mode_improvements:\n            mode_improvements[mode] = []\n        mode_improvements[mode].append(result['Delta'])\n    \n    print(\"Average improvement by detector mode:\\n\")\n    for mode in ['TPC_ONLY', 'TPC_TOF', 'TOF_ONLY']:\n        if mode in mode_improvements:\n            improvements = mode_improvements[mode]\n            avg_improvement = np.mean(improvements)\n            std_improvement = np.std(improvements)\n            print(f\"  {mode:15s}: {avg_improvement:+.4f} ± {std_improvement:.4f}\")\n\nprint(f\"\\n{'='*80}\")\nprint(\"✓ SECTION 5D COMPLETE: Phase 1 Detector-Aware Analysis Finished\")\nprint(f\"{'='*80}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:46.901026Z","iopub.status.idle":"2026-01-20T14:34:46.901231Z","shell.execute_reply.started":"2026-01-20T14:34:46.901134Z","shell.execute_reply":"2026-01-20T14:34:46.901143Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 6: Bayesian PID Availability & Comparison with ML Models","metadata":{}},{"cell_type":"code","source":"print(f\"\\n{'#'*80}\")\nprint(\"SECTION 6: BAYESIAN PID AVAILABILITY & ALL MODELS VS BAYESIAN COMPARISON\")\nprint(f\"{'#'*80}\\n\")\n\n# ============================================================================\n# PART 1: BAYESIAN PID AVAILABILITY ANALYSIS\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"PART 1: BAYESIAN PID AVAILABILITY ANALYSIS\")\nprint(f\"{'='*80}\\n\")\n\nbayes_features = ['bayes_prob_pi', 'bayes_prob_ka', 'bayes_prob_pr', 'bayes_prob_el']\n\nprint(f\"Dataset info:\")\nprint(f\"  Total rows: {len(df):,}\\n\")\n\nprint(f\"Bayesian PID availability per feature:\")\nfor feat in bayes_features:\n    available = (df[feat] != 0).sum()\n    missing = len(df) - available\n    pct_available = available / len(df) * 100\n    print(f\"  {feat:<20} Available: {available:>8} ({pct_available:>5.2f}%)  Missing: {missing:>8} ({100-pct_available:>5.2f}%)\")\n\nprint(f\"\\n{'─'*80}\")\nprint(f\"COMPLETE BAYESIAN PID (all 4 features non-zero):\")\nbayes_complete = (df[bayes_features] != 0).all(axis=1)\ncomplete_count = bayes_complete.sum()\ncomplete_pct = complete_count / len(df) * 100\nprint(f\"  Complete rows: {complete_count:>8} ({complete_pct:>5.2f}%)\")\nprint(f\"  Incomplete:    {len(df) - complete_count:>8} ({100-complete_pct:>5.2f}%)\")\n\n# ============================================================================\n# PART 2: BAYESIAN AVAILABILITY BY MOMENTUM RANGE\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"BAYESIAN AVAILABILITY BY MOMENTUM RANGE\")\nprint(f\"{'='*80}\\n\")\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    df_range = df[(df['p'] >= momentum_range['min']) & (df['p'] < momentum_range['max'])]\n    bayes_complete_range = (df_range[bayes_features] != 0).all(axis=1)\n    complete_count_range = bayes_complete_range.sum()\n    complete_pct_range = complete_count_range / len(df_range) * 100 if len(df_range) > 0 else 0\n    \n    print(f\"{momentum_range['name']:<30}\")\n    print(f\"  Total tracks:       {len(df_range):>8}\")\n    print(f\"  Complete Bayesian:  {complete_count_range:>8} ({complete_pct_range:>5.2f}%)\")\n    print()\n\n# ============================================================================\n# PART 3: ALL MODELS VS BAYESIAN PID COMPARISON\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"PART 3: ALL MODELS VS BAYESIAN PID COMPARISON\")\nprint(f\"  Models: SimpleNN, DNN, FSE Phase 0, FSE Phase 1, Random Forest, XGBoost\")\nprint(f\"{'='*80}\\n\")\n\nprint(\"All model architectures available!\")\nprint(\"Running comprehensive comparison...\\n\")\n\nfor mr_key, momentum_range in MOMENTUM_RANGES.items():\n    mr_data = all_results_by_model_and_range[mr_key]\n    \n    print(f\"\\n{'─'*80}\")\n    print(f\"COMPARISON: {momentum_range['name']}\")\n    print(f\"{'─'*80}\\n\")\n    \n    preprocessing = mr_data.get('preprocessing', {})\n    \n    if 'bayes_availability_test' not in preprocessing or 'models' not in mr_data:\n        print(f\"Bayesian data not found in preprocessing, skipping...\")\n        continue\n    \n    if 'JAX_SimpleNN' not in mr_data['models']:\n        print(f\"SimpleNN not available for this range, skipping...\")\n        continue\n    \n    # Get reference y_test and masks (use SimpleNN as reference)\n    reference_results = mr_data['models']['JAX_SimpleNN']\n    y_test = np.array(reference_results['y_test'])\n    bayes_mask = preprocessing['bayes_availability_test']\n    bayes_pred_original = preprocessing['bayes_pred_original_test']\n    \n    # Get predictions from all models\n    model_predictions = {}\n    for model_type in MODEL_TYPES:\n        if model_type in mr_data['models']:\n            model_predictions[model_type] = np.array(mr_data['models'][model_type]['y_pred_test'])\n    \n    # Track breakdown\n    has_real_bayes = bayes_mask.astype(bool)\n    is_filled = ~has_real_bayes\n    n_real = np.sum(has_real_bayes)\n    n_filled = np.sum(is_filled)\n    pct_real = n_real / len(bayes_mask) * 100\n    \n    print(f\"Track breakdown:\")\n    print(f\"  Tracks with REAL Bayesian data:  {n_real:>8} ({pct_real:>5.2f}%)\")\n    print(f\"  Tracks with FILLED Bayesian:    {n_filled:>8} ({100-pct_real:>5.2f}%)\")\n    \n    # Results on all tracks\n    acc_bayes_all = accuracy_score(y_test, bayes_pred_original)\n    \n    print(f\"\\n{'─'*40}\")\n    print(f\"RESULTS ON ALL TRACKS\")\n    print(f\"{'─'*40}\")\n    print(f\"  Bayesian PID Accuracy:  {acc_bayes_all:.4f}\")\n    \n    for model_type in MODEL_TYPES:\n        if model_type in model_predictions:\n            y_pred = model_predictions[model_type]\n            acc = accuracy_score(y_test, y_pred)\n            improvement = acc - acc_bayes_all\n            improvement_pct = improvement / acc_bayes_all * 100 if acc_bayes_all > 0 else 0\n            print(f\"  {model_display_names.get(model_type, model_type):<30} {acc:.4f}  Δ {improvement:+.4f} ({improvement_pct:+.2f}%)\")\n    \n    # Results on real Bayesian data\n    if n_real > 0:\n        y_test_real = y_test[has_real_bayes]\n        y_pred_bayes_real = bayes_pred_original[has_real_bayes]\n        acc_bayes_real = accuracy_score(y_test_real, y_pred_bayes_real)\n        \n        print(f\"\\n{'─'*40}\")\n        print(f\"RESULTS ON TRACKS WITH REAL BAYESIAN DATA\")\n        print(f\"{'─'*40}\")\n        print(f\"  Bayesian PID Accuracy:  {acc_bayes_real:.4f}\")\n        \n        for model_type in MODEL_TYPES:\n            if model_type in model_predictions:\n                y_pred = model_predictions[model_type]\n                y_pred_real = y_pred[has_real_bayes]\n                acc = accuracy_score(y_test_real, y_pred_real)\n                improvement = acc - acc_bayes_real\n                improvement_pct = improvement / acc_bayes_real * 100 if acc_bayes_real > 0 else 0\n                print(f\"  {model_display_names.get(model_type, model_type):<30} {acc:.4f}  Δ {improvement:+.4f} ({improvement_pct:+.2f}%)\")\n\n# ============================================================================\n# PLOT 1: ACCURACY COMPARISON - ALL MODELS VS BAYESIAN PID\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"VISUAL COMPARISON: ALL MODELS VS BAYESIAN PID\")\nprint(f\"{'='*80}\\n\")\n\nfig, axes = plt.subplots(1, 3, figsize=(28, 9))\ncomparison_data = []\n\nfor mr_idx, (mr_key, momentum_range) in enumerate(MOMENTUM_RANGES.items()):\n    mr_data = all_results_by_model_and_range[mr_key]\n    ax = axes[mr_idx]\n    \n    preprocessing = mr_data.get('preprocessing', {})\n    \n    if 'bayes_availability_test' not in preprocessing or 'models' not in mr_data:\n        continue\n    \n    if 'JAX_SimpleNN' not in mr_data['models']:\n        continue\n    \n    y_test = np.array(mr_data['models']['JAX_SimpleNN']['y_test'])\n    bayes_mask = preprocessing['bayes_availability_test']\n    bayes_pred_original = preprocessing['bayes_pred_original_test']\n    \n    acc_bayes_all = accuracy_score(y_test, bayes_pred_original)\n    has_real_bayes = bayes_mask.astype(bool)\n    \n    if np.sum(has_real_bayes) > 0:\n        acc_bayes_real = accuracy_score(y_test[has_real_bayes], bayes_pred_original[has_real_bayes])\n    else:\n        acc_bayes_real = 0\n    \n    categories = ['All Tracks', 'Real Bayes Only']\n    x = np.arange(len(categories))\n    width = 0.11\n    \n    model_accs_all = {}\n    model_accs_real = {}\n    \n    for model_type in MODEL_TYPES:\n        if model_type in mr_data['models']:\n            y_pred = np.array(mr_data['models'][model_type]['y_pred_test'])\n            model_accs_all[model_type] = accuracy_score(y_test, y_pred)\n            \n            if np.sum(has_real_bayes) > 0:\n                model_accs_real[model_type] = accuracy_score(y_test[has_real_bayes], y_pred[has_real_bayes])\n            else:\n                model_accs_real[model_type] = 0\n    \n    # Position offset for 6 models + 1 Bayesian = 7 groups\n    position_offset = -3.0 * width\n    \n    # Plot each model\n    for idx, model_type in enumerate(MODEL_TYPES):\n        if model_type in model_accs_all:\n            accs = [model_accs_all[model_type], model_accs_real[model_type]]\n            bars = ax.bar(x + position_offset, accs, width, \n                         label=model_display_names.get(model_type, model_type),\n                         color=model_colors_dict.get(model_type, '#999999'),\n                         alpha=0.85, edgecolor='black', linewidth=1.2)\n            \n            for bar in bars:\n                height = bar.get_height()\n                if height > 0:\n                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.012,\n                           f'{height:.3f}', ha='center', va='bottom',\n                           fontsize=10, fontweight='bold', rotation=0)\n            \n            position_offset += width\n    \n    # Plot Bayesian (last bar)\n    bayes_accs = [acc_bayes_all, acc_bayes_real]\n    bars_bayes = ax.bar(x + position_offset, bayes_accs, width,\n                       label='Bayesian PID',\n                       color='#06B6D4', alpha=0.85, edgecolor='black', linewidth=1.2)\n    \n    for bar in bars_bayes:\n        height = bar.get_height()\n        if height > 0:\n            ax.text(bar.get_x() + bar.get_width()/2., height + 0.012,\n                   f'{height:.3f}', ha='center', va='bottom',\n                   fontsize=10, fontweight='bold', rotation=0)\n    \n    ax.set_ylabel('Accuracy', fontsize=13, fontweight='bold')\n    ax.set_title(f'{momentum_range[\"name\"]}', fontsize=14, fontweight='bold')\n    ax.set_xticks(x)\n    ax.set_xticklabels(categories, fontsize=12, fontweight='bold')\n    ax.set_ylim([0, 1.1])\n    ax.legend(fontsize=10, loc='upper left', ncol=1, framealpha=0.95)\n    ax.grid(axis='y', alpha=0.3, linestyle='--')\n    ax.tick_params(axis='y', labelsize=11)\n    \n    comparison_data.append({\n        'Range': momentum_range['name'],\n        'Models': model_accs_all,\n        'ModelsReal': model_accs_real,\n        'BayesAll': acc_bayes_all,\n        'BayesReal': acc_bayes_real\n    })\n\nplt.suptitle('Accuracy Comparison: All Models vs Bayesian PID (All Tracks & Real Bayesian Only)', \n             fontsize=15, fontweight='bold', y=0.98)\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ All models vs Bayesian comparison plot generated\")\n\n# ============================================================================\n# PLOT 2: IMPROVEMENT OVER BAYESIAN PID\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"IMPROVEMENT OVER BAYESIAN PID\")\nprint(f\"{'='*80}\\n\")\n\nfig, ax = plt.subplots(figsize=(20, 9))\n\nranges = [d['Range'] for d in comparison_data]\nx = np.arange(len(ranges))\nwidth = 0.11\nposition_offset = -3.0 * width\n\nfor model_type in MODEL_TYPES:\n    improvements_all = []\n    improvements_real = []\n    \n    for d in comparison_data:\n        if model_type in d['Models']:\n            imp_all = (d['Models'][model_type] - d['BayesAll']) / d['BayesAll'] * 100\n            improvements_all.append(imp_all)\n            \n            if d['BayesReal'] > 0:\n                imp_real = (d['ModelsReal'][model_type] - d['BayesReal']) / d['BayesReal'] * 100\n            else:\n                imp_real = 0\n            improvements_real.append(imp_real)\n    \n    if improvements_all:\n        # All tracks bars\n        bars_all = ax.bar(x + position_offset - width/2, improvements_all, width/2,\n                         label=f'{model_display_names.get(model_type, model_type)} (All)',\n                         color=model_colors_dict.get(model_type, '#999999'),\n                         alpha=0.85, edgecolor='black', linewidth=1.2)\n        \n        for bar in bars_all:\n            height = bar.get_height()\n            ax.text(bar.get_x() + bar.get_width()/2., height + 0.3,\n                   f'{height:.1f}%', ha='center', va='bottom',\n                   fontsize=9, fontweight='bold', rotation=0)\n    \n    if improvements_real:\n        # Real Bayesian bars\n        bars_real = ax.bar(x + position_offset + width/2, improvements_real, width/2,\n                          label=f'{model_display_names.get(model_type, model_type)} (Real)',\n                          color=model_colors_dict.get(model_type, '#999999'),\n                          alpha=0.5, edgecolor='black', linewidth=1.2, hatch='///')\n        \n        for bar in bars_real:\n            height = bar.get_height()\n            ax.text(bar.get_x() + bar.get_width()/2., height + 0.3,\n                   f'{height:.1f}%', ha='center', va='bottom',\n                   fontsize=9, fontweight='bold', rotation=0)\n    \n    position_offset += width\n\nax.axhline(y=0, color='k', linestyle='--', linewidth=2, alpha=0.6)\nax.set_ylabel('Improvement over Bayesian (%)', fontsize=13, fontweight='bold')\nax.set_xlabel('Momentum Range', fontsize=13, fontweight='bold')\nax.set_title('Improvement over Bayesian PID (All Tracks vs Real Bayesian Only)', \n             fontsize=15, fontweight='bold')\nax.set_xticks(x)\nax.set_xticklabels(ranges, fontsize=12, fontweight='bold')\nax.legend(fontsize=10, loc='best', ncol=2, framealpha=0.95)\nax.grid(axis='y', alpha=0.3, linestyle='--')\nax.tick_params(axis='y', labelsize=11)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Improvement percentage comparison generated\")\n\n# ============================================================================\n# PLOT 3: PER-PARTICLE ACCURACY - ALL MODELS VS BAYESIAN PID\n# ============================================================================\n\nprint(f\"\\n{'='*80}\")\nprint(\"PER-PARTICLE ACCURACY: ALL MODELS VS BAYESIAN PID\")\nprint(f\"{'='*80}\\n\")\n\nfig, axes = plt.subplots(1, 3, figsize=(28, 9))\n\nfor mr_idx, (mr_key, momentum_range) in enumerate(MOMENTUM_RANGES.items()):\n    mr_data = all_results_by_model_and_range[mr_key]\n    ax = axes[mr_idx]\n    \n    preprocessing = mr_data.get('preprocessing', {})\n    \n    if 'bayes_availability_test' not in preprocessing or 'models' not in mr_data:\n        continue\n    \n    if 'JAX_SimpleNN' not in mr_data['models']:\n        continue\n    \n    y_test = np.array(mr_data['models']['JAX_SimpleNN']['y_test'])\n    bayes_pred_original = preprocessing['bayes_pred_original_test']\n    \n    particles = []\n    model_particle_accs = {model_type: [] for model_type in MODEL_TYPES}\n    bayes_particle_accs = []\n    \n    for i, particle_name in enumerate(PARTICLE_NAMES):\n        mask = y_test == i\n        \n        if np.sum(mask) > 0:\n            particles.append(particle_name)\n            \n            for model_type in MODEL_TYPES:\n                if model_type in mr_data['models']:\n                    y_pred = np.array(mr_data['models'][model_type]['y_pred_test'])\n                    model_particle_accs[model_type].append(accuracy_score(y_test[mask], y_pred[mask]))\n                else:\n                    model_particle_accs[model_type].append(0)\n            \n            bayes_particle_accs.append(accuracy_score(y_test[mask], bayes_pred_original[mask]))\n    \n    x = np.arange(len(particles))\n    width = 0.11\n    position_offset = -3.0 * width\n    \n    # Plot each model\n    for model_type in MODEL_TYPES:\n        if model_particle_accs[model_type]:\n            bars = ax.bar(x + position_offset, model_particle_accs[model_type], width,\n                         label=model_display_names.get(model_type, model_type),\n                         color=model_colors_dict.get(model_type, '#999999'),\n                         alpha=0.85, edgecolor='black', linewidth=1.2)\n            \n            for bar in bars:\n                height = bar.get_height()\n                if height > 0:\n                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.015,\n                           f'{height:.2f}', ha='center', va='bottom',\n                           fontsize=9, fontweight='bold', rotation=0)\n            \n            position_offset += width\n    \n    # Plot Bayesian\n    bars_bayes = ax.bar(x + position_offset, bayes_particle_accs, width,\n                       label='Bayesian PID',\n                       color='#06B6D4', alpha=0.85, edgecolor='black', linewidth=1.2)\n    \n    for bar in bars_bayes:\n        height = bar.get_height()\n        if height > 0:\n            ax.text(bar.get_x() + bar.get_width()/2., height + 0.015,\n                   f'{height:.2f}', ha='center', va='bottom',\n                   fontsize=9, fontweight='bold', rotation=0)\n    \n    ax.set_ylabel('Accuracy', fontsize=13, fontweight='bold')\n    ax.set_title(f'{momentum_range[\"name\"]}', fontsize=14, fontweight='bold')\n    ax.set_xticks(x)\n    ax.set_xticklabels(particles, fontsize=12, fontweight='bold', rotation=45, ha='right')\n    ax.set_ylim([0, 1.1])\n    ax.legend(fontsize=10, loc='upper right', ncol=1, framealpha=0.95)\n    ax.grid(axis='y', alpha=0.3, linestyle='--')\n    ax.tick_params(axis='y', labelsize=11)\n\nplt.suptitle('Per-Particle Accuracy: All Models vs Bayesian PID', \n             fontsize=15, fontweight='bold', y=0.98)\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Per-particle accuracy comparison generated\")\n\nprint(f\"\\n{'='*80}\")\nprint(\"✓ SECTION 6 COMPLETE: All Models vs Bayesian Comparison Analysis\")\nprint(f\"{'='*80}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:46.902320Z","iopub.status.idle":"2026-01-20T14:34:46.902543Z","shell.execute_reply.started":"2026-01-20T14:34:46.902441Z","shell.execute_reply":"2026-01-20T14:34:46.902450Z"}},"outputs":[],"execution_count":null}]}